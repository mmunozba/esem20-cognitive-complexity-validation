[1] G. Canfora and A. Cimitile, Handbook of Software Engineering and Knowledge Engineering. River Edge NJ: World Scientific, 2001, ch. Software maintenance, pp. 91-120.
[2] B. Curtis, S. B. Sheppard, P. Milliman, M. A. Borst, and T. Love, "Measuring the psychological complexity of software maintenance tasks with the halstead and mccabe metrics,"IEEE Transactions on software engineering, vol. 5, no. 2, pp. 96--104, September 1979.
[3] M. P. Robillard, W. Coelho, and G. C. Murphy, "How effective developers investigate source code: an exploratory study," IEEE Transactions on software engineering, vol. 30, pp. 889-903, December 2004.
[4] H. C. Benestad, A. Bente, and A. Erik, "Understanding cost drivers of software evolution: a quantitative and qualitative investigation of change effort in two evolving software systems," EMPIRICAL SOFTWARE ENGINEERING, vol. 15, pp. 166-203, April 2010.
[5] c. L. Corritore, "An exploratory study of program comprehension strategies of procedural and object-oriented programmers," International Journal of Human-Computer Studies, vol. 54, pp. 1-23, 2001.
[6] A. J. Ko, B. A. Myers, M. J. Coblenz, and H. H. Aung, "An exploratory study of how developers seek, relate, and collect relevant information during software maintenance tasks," IEEE Transactions on software engineering, vol. 32, no. 12, pp. 971-987, December 2006.
[7] F. Fioravanti and P. Nesi, "Estimation and prediction metrics for adaptive maintenance effort of object-oriented systems," IEEE Transactions on software engineering, vol. 27, no. 12, pp. 1062-1084, December 2001.
[8] M. Jorgensen, "Experience with the accuracy of software maintenance task effort prediction models," IEEE Transactions on software engineering, vol. 21, no. 8, pp. 674-681, August 1995.
[9] V. Basili, L. Briand, S. Condon, Y.-M. Kim, W. L. Melo, and J. D. Valett, ''Understanding and predicting the process of software maintenance releases," in Proceedings of the 18th international conference on Software engineering, 1996, pp. 464-474.
[10] V. Nguyen, B. Boehm, and P. Danphitsanuphan, "Assessing and estimating corrective, enhancive, and reductive maintenance tasks: A controlled experiment," in Proceedings of the 16th Asia-Pacific Software Engineering, 2009, pp. 381-388.
[11] J. Buckley, T. Mens, M. Zenger, A. Rashid, and G. Kniesel, "Towards a taxonomy of software change," Journal of Software Maintenance and Evolution: Research and Practice, vol. 17, pp. 309-332, 2005.
[12] E. B. Swanson, ''The dimensions of maintenance," in Proceedings of the 2nd international conference on Software engineering, 1976, pp. 492-497.
[13] A. De Lucia, E. P ompella, and S. Stefanucci, "Assessing effort estimation models for corrective maintenance through empirical studies," Information and Software Technology, vol. 47, pp. 3-15, January 2005.
[14] B. Henderson-Sellers, Object-Oriented Metrics: Measures of Complexity. Prentice Hall, December 1995.
[15] R. Martin, "00 design quality metrics - an analysis of dependencies," in Proceedings of the Workshop Pragmatic and Theoretical Directions in Object-Oriented Software Metrics, October 1994. 481
[16] S. Bellon, R. Koschke, G. Antoniol, J. Krinke, and E. Merlo, "Comparison and evaluation of clone detection tools," IEEE Transactions on software engineering, vol. 33, no. 9, pp. 804-818, September 2007.
[17] S. Bellon, "Detection of software clones," Institute for Software Technology, University of Stuttgart, http:// www. bauhaus-stuttgart. de/clones/. Tech. Rep. , 2003.

[1] T. Anderson and J. Finn. The New Statistical Analysis of Data. Springer, 1996.
[2] I. Bertoncello et al. Explicit Exception Handling Variability in Component-based Product Line Architectures. In Proc. Int’l Workshop Exception Handling, pages 47–54. ACM Press, 2008.
[3] J. Boysen. Factors Affecting Computer Program Comprehension. PhD thesis, Iowa State University, 1977.
[4] R. Brooks. Using a Behavioral Theory of Program Comprehension in Software Engineering. In Proc. Int’l Conf. Software Engineering, pages 196–201. IEEE CS, 1978.
[5] A. Bryant et al. Composing Design Patterns: A Scalability Study of Aspect-Oriented Programming. In Proc. Int’l Conf. Aspect-Oriented Software Development, pages 109–121. ACM Press, 2006.
[6] P. Clements and L. Northrop. Software Product Lines: Practice and Patterns. Addison Wesley, 2001.
[7] J. Daly et al. The Effect of Inheritance on the Maintainability of Object-Oriented Software: An Empirical Study. In Proc. Int’l Conf. Software Maintenance, pages 20–29. IEEE CS, 1995.
[8] A. Dunsmore and M. Roper. A Comparative Evaluation of Program Comprehension Measures. Technical Report EFoCS 35-2000, Department of Computer Science, University of Strathclyde, 2000.
[9] R. Dyer et al. A Preliminary Study of Quantified, Typed Events. In AOSD Workshop Empirical Evaluation of Software Composition Techniques, 2010.
[10] J. Feigenspan et al. How to Compare Program Comprehension in FOSD Empirically - An Experience Report. In Proc. Int’l Workshop on Feature-Oriented Software Development, pages 55–62. ACM Press, 2009.
[11] J. Feigenspan et al. Using Background Colors to Support Program Comprehension in Software Product Lines. In Proc. Int’l Conf. Evaluation and Assessment in Software Engineering, pages 66–75. Institution of Engineering and Technology, 2011.
[12] J. Feigenspan, N. Siegmund, and J. Fruth. On the Role of Program Comprehension in Embedded Systems. In Workshop Software-Reengineering, pages 34–35, 2011.
[13] E. Figueiredo et al. Assessing Aspect-Oriented Artifacts: Towards a Tool-Supported Quantitative Method. In ECOOP Workshop Quantitative Approaches in Object-Oriented Software Engineering, pages 58–69, 2005.
[14] E. Figueiredo et al. Evolving Software Product Lines with Aspects: An Empirical Study on Design Stability. In Proc. Int’l Conf. Software Engineering, pages 261–270. ACM Press, 2008.
[15] E. Figueiredo et al. On the Maintainability of Aspect-Oriented Software: A Concern-Oriented Measurement Framework. In Proc. Europ. Conf. Software Maintenance and Reengineering, pages 183–192. IEEE CS, 2008.
[16] E. Figueiredo, J. Whittle, and A. Garcia. ConcernMorph: Metrics-based Detection of Crosscutting Patterns. In Proc. Europ. Software Engineering Conf./Foundations of Software Engineering, pages 299–300. ACM Press, 2009.
[17] I. Galvˆao, P. van den Broek, and M. Aks¸it. A Model for Variability Design Rationale in SPL. In Proc. Europ. Conf. Software Architecture, pages 332–335. ACM Press, 2010.
[18] A. Garcia et al. Modularizing Design Patterns with Aspects: A Quantitative Study. In Proc. Int’l Conf. Aspect-Oriented Software Development , pages 3–14. ACM Press, 2005.
[19] P. Greenwood et al. On the Impact of Aspectual Decompositions on Design Stability: An Empirical Study. In Proc. Europ. Conf. Object-Oriented Programming, pages 176–200. Springer, 2007.
[20] B. Henderson-Sellers. Object-Oriented Metrics: Measures of Complexity. Prentice Hall, 1995.
[21] S. Henry, M. Humphrey, and J. Lewis. Evaluation of the Maintainability of Object-Oriented Software. In IEEE Region 10 Conf. Computer and Comm. Systems, pages 404–409. IEEE CS, 1990.
[22] K. Kang et al. Feature-Oriented Domain Analysis (FODA) Feasibility Study. Technical Report CMU/SEI-90-TR-021, Software Engineering Institute, 1990.
[23] G. Kiczales, E. Hilsdale, J. Hugunin, M. Kersten, J. Palm, and W. Griswold. An Overview of AspectJ. pages 327–353. Springer, 2001.
[24] J. Koenemann and S. Robertson. Expert Problem Solving Strategies for Program Comprehension. In Proc. Conf. Human Factors in Computing Systems, pages 125–130. ACM Press, 1991.
[25] U. Kulesza et al. Quantifying the Effects of Aspect-Oriented Programming: A Maintenance Study. In Proc. Int’l Conf. Software Maintenance, pages 223–233. IEEE CS, 2006.
[26] B. Lientz and B. Swanson. Software Maintenance Management. Addison-Wesley, 1980.
[27] R. Likert. A Technique for the Measurement of Attitudes. Archives of Psychology, 22(140):1–55, 1932.
[28] S. McConnell. Code Complete. Microsoft Press, second edition, 2004.
[29] A. Molesini et al. On the Quantitative Analysis of Architecture Stability in Aspectual Decompositions. In Proc. Working IEEE/IFIP Conf. on Software Architecture, pages 29–38. IEEE CS, 2008.
[30] D. Mook. Motivation: The Organization of Action. W.W. Norton & Co., second edition, 1996.
[31] B. Morin et al. Taming Dynamically Adaptive Systems using Models and Aspects. In Proc. Int’l Conf. Software Engineering, pages 122–132. IEEE CS, 2009.
[32] D. Parnas. On the Criteria To Be Used in Decomposing Systems into Modules. Commun. ACM, 15(12):1053–1058, 1972.
[33] N. Pennington. Stimulus Structures and Mental Representations in Expert Comprehension of Computer Programs. Cognitive Psychologys, 19(3):295–341, 1987.
[34] L. Prechelt et al. Two Controlled Experiments Assessing the Usefulness of Design Pattern Documentation in Program Maintenance. IEEE Trans. Softw. Eng., 28(6):595–606, 2002.
[35] M. Robillard and G. Murphy. Representing Concerns in Source Code. ACM Trans. Softw. Eng. & Methodology, 16(1):1–38, 2007.
[36] B. Sharif and J. Maletic. An Eye Tracking Study on camelCase and under score Identifier Styles. In Proc. Int’l Conf. Program Comprehension, pages 196–205. IEEE CS, 2010.
[37] B. Shneiderman and R. Mayer. Syntactic/Semantic Interactions in Programmer Behavior: A Model and Experimental Results. International Journal of Parallel Programming, 8(3):219–238, 1979.
[38] E. Soloway and K. Ehrlich. Empirical Studies of Programming Knowledge. IEEE Trans. Softw. Eng., 10(5):595–609, 1984.
[39] A. von Mayrhauser and M. Vans. Program Comprehension During Software Maintenance and Evolution. Computer, 28(8):44–55, 1995.
[40] J. Yellott. Correction for Fast Guessing and the Speed Accuracy Trade-off in Choice Reaction Time. Journal of Mathematical Psychology, 8:159–199, 1971.

[1] M. H. Halstead, Elements of Software Science. Elsevier, 1977.
[2] T. J. McCabe, “A complexity measure,” IEEE Transactions on Software Engineering, vol. 2, pp. 308–320, 1976.
[3] B. A. Nejmeh, “Npath: a measure of execution path complexity and its applications,” Commun. ACM, vol. 31, pp. 188–200, Feb. 1988.
[4] D. Beyer and A. Fararooy, “A simple and effective measure for complex low-level dependencies,” in International Conference on Program Comprehension, 2010, pp. 80–83.
[5] J. Elshoff, “An analysis of some commercial PL/I programs,” IEEE Transactions on Software Engineering, vol. SE-2, no. 2, pp. 113–120, Jun. 1976.
[6] J. Shao and Y. Wang, “A new measure of software complexity based on cognitive weights,” Canadian Journal of Electrical and Computer Engineering, vol. 28, no. 2, pp. 69 –74, Apr. 2003.
[7] D. Posnett, A. Hindle, and P. T. Devanbu, “A simpler model of software readability,” in Working Conference on Mining Software Repositories, 2011, pp. 73–82.
[8] R. P. L. Buse and W. R. Weimer, “Learning a metric for code readability,” IEEE Transactions on Software Engineering, vol. 36, no. 4, pp. 546 –558, july-aug. 2010.
[9] J. Boysen, “Factors affecting computer program comprehension,” PhD thesis, Iowa State University, 1977.
[10] J. P. Boysen and R. F. Keller, “Measuring computer program comprehension,” in Proceedings of the eleventh SIGCSE technical symposium on Computer science education. ACM Press, 1980, pp. 92–102.
[11] A. Ko, B. Myers, M. Coblenz, and H. Aung, “An exploratory study of how developers seek, relate, and collect relevant information during software maintenance tasks,” IEEE Transactions on Software Engineering, vol. 32, no. 12, pp. 971–987, Dec. 2006.
[12] A. J. Ko, R. DeLine, and G. Venolia, “Information needs in collocated software development teams,” International Conference on Software Engineering, pp. 344–353, 2007.
[13] T. Roehm, R. Tiarks, R. Koschke, and W. Maalej, “How do industry developers comprehend software?” in International Conference on Software Engineering. ACM Press, 2012.
[14] G. C. Murphy, M. Kersten, and L. Findlater, “How are Java software developers using the Eclipse IDE?” IEEE Software, vol. 23, no. 4, pp. 76–83, 2006.
[15] T. Menzies, J. Greenwald, and A. Frank, “Data mining static code attributes to learn defect predictors,” IEEE Transactions on Software Engineering, vol. 33, no. 1, pp. 2–13, 2007.
[16] A. E. Hassan, “Predicting faults using the complexity of code changes,” in Proc. of the 31st ICSE. Washington, DC, USA: IEEE Computer Society, 2009, pp. 78–88.
[17] T. Gyim´othy, R. Ferenc, and I. Siket, “Empirical validation of objectoriented metrics on open source software for fault prediction,” IEEE Transactions on Software Engineering, vol. 31, pp. 897–910, 2005.
[18] T. Zimmermann, N. Nagappan, and A. Zeller, Predicting Bugs from History. Springer, Mar. 2008, ch. 4, pp. 69–88.
[19] T. Zimmermann and N. Nagappan, “Predicting defects using network analysis on dependency graphs,” in Proc. of the 30th ICSE. New York, NY, USA: ACM, 2008, pp. 531–540.
[20] C. Bird, N. Nagappan, P. T. Devanbu, H. Gall, and B. Murphy, “Does distributed development affect software quality? an empirical case study of Windows Vista,” in Proc. of the 31st ICSE, 2009, pp. 518–528.
[21] P. Knab, M. Pinzger, and A. Bernstein, “Predicting defect densities in source code files with decision tree learners,” in Proc. of the Workshop on Mining software repositories. New York, NY, USA: ACM, 2006, pp. 119–125.
[22] T. Ostrand, E. Weyuker, and R. Bell, “Predicting the location and number of faults in large software systems,” IEEE Transactions on Software Engineering, vol. 31, no. 4, pp. 340–355, 2005.
[23] N. Nagappan and T. Ball, “Use of relative code churn measures to predict system defect density,” in International Conference on Software Engineering, 2005, pp. 284–292.
[24] ——, “Static analysis tools as early indicators of pre-release defectdensity,” in International  Conference on Software Engineering. ACM, 2005, pp. 580–586.
[25] T. Mende, “On the evaluation of defect prediction models,” PhD Dissertation, University of Bremen, Germany, 2011.
[26] C. Kemerer, “Software complexity and software maintenance: A survey of empirical research,” Annals of Software Engineering, vol. 1, no. 1, pp. 1–22, Dec. 1995.
[27] V. Basili and B. Perricone, “Software errors and complexity: An empirical investigation,” Communications of the ACM, vol. 27, no. 1, pp. 42–52, 1984.
[28] V. Shen, T.-J. Yu, S. Thebaut, and L. Paulsen, “Identifying errorprone software - an empirical study,” IEEE Transactions on Software Engineering, vol. 11, no. 4, pp. 317–323, 1985.
[29] B. Compton and C. Withrow, “Prediction and control of ada software defects,” Journal of Systems and Software, vol. 12, no. 3, pp. 199–207, 1990.
[30] K. An, D. Gustafson, and A. Melton, “A model for software maintenance,” in International Conference on Software Maintenance, 1987, pp. 57–62.
[31] B. A. Benander, N. Gorla, and A. C. Benander, “An empirical study of the use of the goto statement,” Journal of Systems and Software, vol. 11, no. 3, pp. 217–223, 1990.
[32] T. D. Korson and V. K. Vaishnavi, “An empirical study of modularity on program modifiability,” in workshop on empirical studies of programmers on Empirical studies of programmers, 1986, pp. 168–186.
[33] D. Troy and S. Zweben, “Measuring the quality of structured designs,” Journal of Systems and Software, vol. 2, no. 2, pp. 113–120, 1981.
[34] R. Selby and V. Basili, “Error localization during software maintenance: Generating hierarchical system descriptions from the source code alone,” in International Conference on Software Maintenance. IEEE Computer Society Press, 1988, pp. 192–197.
[35] S. Yau and P. Chang, “A metric of modifiability for software maintenance,” in International Conference on Software Maintenance. IEEE Computer Society Press, 1988, pp. 374–381.
[36] R. Lind and K. Vairavan, “An experimental investigation of software metrics and their relationship to software development effort,” IEEE Transactions on Software Engineering, vol. 15, no. 5, pp. 649–653, 1989.
[37] G. Gill and C. Kemerer, “Cyclomatic complexity density and software maintenance productivity,” IEEE Transactions on Software Engineering, vol. 17, no. 12, pp. 1284–1288, 1991.
[38] J. D. et al, “The effect of inheritance on the maintainability of objectoriented software: An empirical study,” in International Conference on Software Maintenance. IEEE Computer Society Press, 1995, pp. 20–29.
[39] T. Kamiya, S. Kusumoto, K. Inoue, and Y. Mohri, “Empirical evaluation of reuse sensitiveness of complexity metrics,” Information and Software Technology, vol. 41, no. 5, pp. 297 – 305, 1999.
[40] J. Feigenspan, S. Apel, J. Liebig, and C. Kastner, “Exploring software measures to assess program comprehension,” in International Symposium on Empirical Software Engineering and Measurement. IEEE Computer Society Press, 2011, pp. 127–136.
[41] L. P. et al., “Two controlled experiments assessing the usefulness of design pattern documentation in program maintenance,” IEEE Transactions on Software Engineering, vol. 28, no. 6, pp. 595–606, 2002.
[42] B. Sharif and J. Maletic, “An eye tracking study on camelcase and under score identifier styles,” in International Conference on Program Comprehension. IEEE Computer Society Press, 2010, pp. 196–205.
[43] D. Lawrie, C. Morrell, H. Feild, and D. Binkley, “What´s in a name? A study of identifiers,” in International Conference on Program Comprehension. IEEE Computer Society Press, 2006, pp. 3–12.
[44] ——, “Effective identifier names for comprehension and memory,” Journal Innovations in Systems and Software Engineering, vol. 3, no. 4, pp. 303–318, 2007.
[45] J. Rilling and T. Klemola, “Identifying comprehension bottlenecks using program slicing and cognitive complexity metrics,” in International Workshop on Program Comprehension. IEEE Computer Society Press, 2003, pp. 115–124.
[46] I. Deligiannis, I. Stamelos, L. Angelis, M. Roumeliotis, and M. Shepperd, “Controlled experiment investigation of an object oriented design heuristic for maintainability,” Journal of Systems and Software, vol. 65, no. 2, pp. 127–139, Feb. 2003.
[47] I. Deligiannis, M. Shepperd, M. Roumeliotis, and I. Stamelos, “An empirical investigation of an object-oriented design heuristic for maintainability,” Journal of Systems and Software, vol. 72, no. 2, pp. 129–143, 2004.
[48] B. D. Bois, S. Demeyer, J. Verelst, T. Mens, and M. Temmerman, “Does god class decomposition affect comprehensibility?” in IASTED. IASTED/ACTA Press, 2006, pp. 346–355.
[49] M. Abbes, F. Khomh, Y.-G. Gu´eh´eneuc, and G. Antoniol, “An empirical study of the impact of antipatterns on program comprehension,” in European Conference on Software Maintenance and Reengineering. IEEE Computer Society Press, 2011, pp. 181–190.
[50] W. Li and R. Shatnawi, “An empirical study of the bad smells and class error probability in the post-release object-oriented system evolution,” Journal of Systems and Software, vol. 80, no. 7, pp. 1120 – 1128, 2007.
[51] S. Jeanmart, Y.-G. Gueheneuc, H. Sahraoui, and N. Habra, “Impact of the visitor pattern on program comprehension and maintenance,” in International Symposium on Empirical Software Engineering and Measurement, 2009, pp. 69–78.
[52] M. G. Kendall, Rank correlation methods, 4th ed. London: Griffin, 1970.
[53] L. Thurstone, “A law of comparative judgement,” Psychological Review, vol. 101/2, p. 273286, 1994.
[54] J. Fleiss, “Measuring nominal scale agreement among many raters,” Psychological Bulletin, vol. 76, no. 5, pp. 378–382, 1971.
[55] J. Sim and C. C. Wright, “The kappa statistic in reliability studies: Use, interpretation, and sample size requirements,” Physical Therapy, vol. 85, no. 3, pp. 257–268, March 2005.
[56] J. R. Landis and G. G. Koch, “The measurement of observer agreement for categorical data,” Biometrics, vol. 33, no. 1, pp. pp. 159–174, 1977.
[57] E. J. Weyuker, “Evaluating software complexity measures,” IEEE Transactions on Software Engineering, vol. 14, pp. 1357–1365, 1988.
[58] D. Beyer and A. Fararooy, “Depdigger: A tool for detecting complex low-level dependencies,” in Program Comprehension (ICPC), 2010 IEEE 18th International Conference on, 30 2010-july 2 2010, pp. 40 –41.

[1] Burkhardt, J. M., Détienne, F., & Wiedenbeck, S. (2006). Mental representations constructed by experts and novices in object-oriented program comprehension. Arxiv Preprint cs/0612018,
[2] Pfleeger, S. L., & Atlee, J. M. (2006). Software engineering: Theory and practice prentice hall.
[3] Meyer, B. (1988). Object-oriented software construction. Series in computer science. International.Prentice-Hall International, Englewood Cli􀆡s,
[4] Détienne, F. (2006). Assessing the cognitive consequences of the objectoriented approach: A survey of empirical research on object-oriented design by individuals and teams. Arxiv Preprint cs/0611154,
[5] Brooks, R. (1978). Using a behavioral theory of program comprehension in software engineering. Proceedings of the 3rd International Conference on Software Engineering, 196-201.
[6] Kintsch, W., & Van Dijk, T. A. (1978). Toward a model of text comprehension and production. Psychological Review, 85(5), 363.
[7] Johnson-Laird, P. N. (1986). Mental models: Towards a cognitive science of language, inference, and consciousness Harvard University Press.
[8] Van Dijk, T. A., & Kintsch, W. (1983). Strategies of discourse comprehension.
[9] Pennington, N. (1987a). Comprehension strategies in programming. Empirical Studies of Programmers: Second Workshop, 100-113.
[10] Pennington, N. (1987b). Stimulus structures and mental representations in expert comprehension of computer programs* 1. Cognitive Psychology, 19(3), 295-341
[11] Von Mayrhauser, A., & Vans, A. M. (2005). Program comprehension during software maintenance and evolution. Computer, 28(8), 44-55.
[12] Ramalingam, V., & Wiedenbeck, S. (1997). An empirical study of novice program comprehension in the imperative and object-oriented styles. Papers Presented at the Seventh Workshop on Empirical Studies of Programmers, 124-139.
[13] Wiedenbeck, S., Ramalingam, V., Sarasamma, S., & Corritore, C. L. (1999). A comparison of the comprehension of object-oriented and procedural programs by novice programmers. Interacting with Computers, 11(3), 255- 282.
[14] Wiedenbeck, S., & Ramalingam, V. (1999). Novice comprehension of small programs written in the procedural and object-oriented styles. International Journal of Human-Computer Studies, 51(1), 71-87.
[15] Harrison, R., Counsell, S., & Nithi, R. (2000). Experimental assessment of the effect of inheritance on the maintainability of object-oriented systems. Journal of Systems and Software, 52(2-3), 173-179.
[16] Khazaei, B., & Jackson, M. (2002). Is there any difference in novice comprehension of a small program written in the event-driven and objectoriented styles? Human Centric Computing Languages and Environments, 2002. Proceedings. IEEE 2002 Symposia on, 19-26.
[17] Fleury, A. E. (2001). Encapsulation and reuse as viewed by java students. ACM SIGCSE Bulletin, , 33(1) 189-193.
[18] Holland, S., Griffiths, R., & Woodman, M. (1997). Avoiding object misconceptions. ACM SIGCSE Bulletin, 29(1), 131-134.
[19] Voigt, J., Irwin, W., & Churcher, N. (2009). Intuitiveness of class and object encapsulation. Hanoi, Vietnam: 6th International Conference on Information Technology and Applications, 9-12.
[20] Ragonis, N., & Ben-Ari, M. (2005). A long-term investigation of the comprehension of OOP concepts by novices. Computer Science Education, 15(3), 203-221.
[21] Chris, D. (2004). Calculating a nonparametric estimate and confidence interval using SAS softwareGlaxo Wellcome Inc., Research Triangle Park, NC.

[1] R. C. Martin, Clean Code: A Handbook of Agile Sofware Craftsmanship. Prentice Hall, 2009.
[2] A. Oram and G. Wilson, Eds., Beautiful Code: Leading Programmers Explain How They Think. O’reilly, 2007.
[3] K. Beck, Implementation Patterns. Addison Wesley, 2007.
[4] L. Erlikh, “Leveraging legacy system dollars for e-business,” IT Professional, vol. 2, no. 3, pp. 17–23, May 2000.
[5] K. H. Bennett and V. T. Rajlich, “Software maintenance and evolution: A roadmap,” in Proceedings of the Conference on The Future of Software Engineering, 2000, pp. 73–87.
[6] V. Rajlich and P. Gosavi, “Incremental change in object-oriented programming,” IEEE Softw., vol. 21, no. 4, pp. 62–69, Jul. 2004.
[7] D. Poshyvanyk and D. Marcus, “Combining formal concept analysis with information retrieval for concept location in source code,” in ICPC’07, 2007.
[8] R. P. L. Buse and W. Weimer, “Learning a metric for code readability,” IEEE TSE, vol. 36, no. 4, pp. 546–558, 2010.
[9] D. Posnett, A. Hindle, and P. T. Devanbu, “A simpler model of software readability.” in MSR’11, 2011, pp. 73–82.
[10] J. Dorn, “A general software readability model,” Master’s thesis, University of Virginia, Department of Computer Science, https://www.cs.virginia.edu/˜weimer/students/dorn-mcs-paper.pdf, 2012.
[11] D. Lawrie, C. Morrell, H. Feild, and D. Binkley, “Effective identifier names for comprehension and memory.” ISSE, vol. 3, no. 4, pp. 303– 318, 2007.
[12] ——, “What’s in a name? a study of identifiers,” in ICPC’06, 2006.
[13] B. Caprile and P. Tonella, “Restructuring program identifier names,” in ICSM, 2000, pp. 97–107.
[14] F. Deissenbock and M. Pizka, “Concise and consistent naming,” 2005.
[15] D. Lawrie, H. Feild, and D. Binkley, “Syntactic identifier conciseness and consistency,” in SCAM’06, 2006, pp. 139–148.
[16] E. Enslen, E. Hill, L. L. Pollock, and K. Vijay-Shanker, “Mining source code to automatically split identifiers for software analysis,” in MSR’09.
[17] A. Takang, P. Grubb, and R. Macredie, “The effects of comments and identifier names on program comprehensibility: an experiential study,” Journal of Program Languages, vol. 4, no. 3, pp. 143–167, 1996.
[18] S. Scalabrino, M. Linares-V´asquez, D. Poshyvanyk, and R. Oliveto, “Appendix: Improving code readability models with textual features.” [Online]. Available: https://dibt.unimol.it/icpc2016/appendix.html
[19] E. Daka, J. Campos, G. Fraser, J. Dorn, and W. Weimer, “Modeling readability to improve unit tests,” in ESEC/FSE’15, 2015, pp. 107–118.
[20] A. Marcus, D. Poshyvanyk, and R. Ferenc, “Using the conceptual cohesion of classes for fault prediction in object-oriented systems,” vol. 34, no. 2, pp. 287–300, 2008.
[21] D. Poshyvanyk and A. Marcus, “The conceptual coupling metrics for object-oriented systems,” in ICSM’06, 2006, pp. 469–478.
[22] G. Antoniol, G. Canfora, G. Casazza, A. De Lucia, and E. Merlo, “Recovering traceability links between code and documentation,” IEEE TSE, vol. 28, no. 10, pp. 970–983, 2002.
[23] J. L. Elshoff and M. Marcotty, “Improving computer program readability to aid modification,” CACM, vol. 25, no. 8, pp. 512–521, 1982.
[24] T. Tenny, “Program readability: procedures versus comments,” IEEE TSE, vol. 14, no. 9, pp. 1271–1279, 1988.
[25] D. Spinellis, Code Quality: The Open Source Perspective. Adobe Press.
[26] D. Binkley, H. Feild, D. J. Lawrie, and M. Pighin, “Increasing diversity: Natural language measures for software fault prediction.” Journal of Systems and Software, vol. 82, no. 11, pp. 1793–1803, 2009.
[27] W. M. Ibrahim, N. Bettenburg, B. Adams, and A. E. Hassan, “On the relationship between comment update practices and software bugs,” Journal of Systems and Software, vol. 85, no. 10, pp. 2293–2304, 2012.
[28] B. Fluri, M.W¨ursch, and H. Gall, “Do code and comments co-evolve? on the relation between source code and comment changes,” in WCRE’07.
[29] M. Linares-V´asquez, B. Li, C. Vendome, and D. Poshyvanyk, “How do developers document database usages in source code?” in ASE’15, 2015.
[30] B. Li, C. Vendome, M. Linares-V´asquez, D. Poshyvanyk, and N. Kraft, “Automatically documenting unit test cases,” in ICST’16, 2016.
[31] F. Deissenboeck and M. Pizka, “Concise and consistent naming,” Software Quality Journal, vol. 14, no. 3, pp. 261–282, 2006.
[32] S. Haiduc and A. Marcus, “On the use of domain terms in source code,” in ICPC’08, 2008, pp. 113–122.
[33] D. Binkley, M. Davis, D. Lawrie, and C. Morrell, “To CamelCase or Under score,” in ICPC’09, 2009.
[34] A. D. Lucia, M. D. Penta, R. Oliveto, A. Panichella, and S. Panichella, “Labeling source code with information retrieval methods: an empirical study,” EMSE, vol. 19, no. 5, pp. 1383–1420, 2014.
[35] V. Arnaoudova, L. M. Eshkevari, R. Oliveto, Y. Gu´eh´eneuc, and G. Antoniol, “Physical and conceptual identifier dispersion: Measures and relation to fault proneness,” in ICSM’10, 2010, pp. 1–5.
[36] G. A. Miller, “Wordnet: A lexical database for english,” vol. 38, no. 11, pp. 39–41, 1995.
[37] R. Flesch, “A new readability yardstick.” Journal of applied psychology, vol. 32, no. 3, p. 221, 1948.
[38] Collins american dictionary. [Online]. Available: http://www. collinsdictionary.com/dictionary/american/syllable
[39] J. Kleinberg and ´ E. Tardos, Algorithm design. Pearson Education India.
[40] M. G¨utlein, E. Frank, M. Hall, and A. Karwath, “Large-scale attribute selection using wrappers,” in CIDM’09, 2009, pp. 332–339.
[41] S. D.J., Handbook of Parametric and Nonparametric Statistical Procedures (fourth edition). Chapman & All, 2007.
[42] S. Holm, “A simple sequentially rejective Bonferroni test procedure,” Scandinavian Journal on Statistics, vol. 6, pp. 65–70, 1979.
[43] R. J. Grissom and J. J. Kim, Effect sizes for research: A broad practical approach, 2nd ed. Lawrence Earlbaum Associates, 2005.
[44] J. Cohen, “The earth is round (p<.05),” American Psychologist, vol. 49, no. 12, pp. 997–1003, 1994.
[45] L. L. Harlow, S. A. Mulaik, and J. H. Steiger, What if there were no significance tests? Psychology Press, 1997.
[46] S. Kim, E. J. Whitehead Jr, and Y. Zhang, “Classifying software changes: Clean or buggy?” TSE, vol. 34, no. 2, pp. 181–196, 2008.

[1] R. Minelli, A. Mocci, and M. Lanza, “I know what you did last summer - an investigation of how developers spend their time,” in 23rd IEEE International Conference on Program Comprehension, 2015, pp. 25–35.
[2] K. K. Aggarwal, Y. Singh, and J. K. Chhabra, “An integrated measure of software maintainability,” in Annual Reliability and Maintainability Symposium., 2002, pp. 235–241.
[3] M. Thongmak and P. Muenchaisri, Measuring Understandability of Aspect-Oriented Code. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011, pp. 43–54.
[4] J. c. Lin and K. c. Wu, “A model for measuring software understandability,” in 6th IEEE International Conference on Computer and Information Technology, 2006, pp. 192–192.
[5] T. Roehm, R. Tiarks, R. Koschke, and W. Maalej, “How do professional developers comprehend software?” in 34th International Conference on Software Engineering (ICSE), 2012, pp. 255–265.
[6] D. Srinivasulu, A. Sridhar, and D. P. Mohapatra, Evaluation of Software Understandability Using Rough Sets. New Delhi: Springer India, 2014, pp. 939–946.
[7] C. Chen, R. Alfayez, K. Srisopha, L. Shi, and B. Boehm, Evaluating Human-Assessed Software Maintainability Metrics. Singapore: Springer Singapore, 2016, pp. 120–132.
[8] M. A. Storey, “Theories, methods and tools in program comprehension: past, present and future,” in 13th International Workshop on Program Comprehension, 2005, pp. 181–191.
[9] M. A. D. Storey, K. Wong, and H. A. Muller, “How do program understanding tools affect how programmers understand programs?” in 4th Working Conference on Reverse Engineering, 1997, pp. 12–21.
[10] R. P. L. Buse and W. Weimer, “Learning a metric for code readability,” IEEE Transactions on Software Engineering, vol. 36, no. 4, pp. 546–558, 2010.
[11] D. Posnett, A. Hindle, and P. T. Devanbu, “A simpler model of software readability.” in 8th Working Conference on Mining Software Repositories, 2011, pp. 73–82.
[12] J. Dorn, “A general software readability model,” Master’s thesis, University of Virginia, Department of Computer Science, https://www.cs.virginia.edu/~weimer/students/dorn-mcs-paper.pdf, 2012.
[13] E. Daka, J. Campos, G. Fraser, J. Dorn, and W. Weimer, “Modeling readability to improve unit tests,” in 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, 2015, pp. 107–118.
[14] S. Scalabrino, M. Linares-Vásquez, D. Poshyvanyk, and R. Oliveto, “Improving code readability models with textual features,” in 24th IEEE International Conference on Program Comprehension, 2016.
[15] J.-C. Lin and K.-C. Wu, “Evaluation of software understandability based on fuzzy matrix,” in IEEE International Conference on Fuzzy Systems, 2008, pp. 887–892.
[16] M. Bartsch and R. Harrison, “An exploratory study of the effect of aspect-oriented programming on maintainability,” Software Quality Journal, vol. 16, no. 1, pp. 23–44, 2008.
[17] A. Capiluppi, M. Morisio, and P. Lago, “Evolution of understandability in oss projects,” in 8th European Conference on Software Maintenance and Reengineering, 2004, pp. 58–66.
[18] D. Lawrie, C. Morrell, H. Feild, and D. Binkley, “Effective identifier names for comprehension and memory.” Innovations in Systems and Software Engineering, vol. 3, no. 4, pp. 303–318, 2007.
[19] ——, “What’s in a name? a study of identifiers,” in 14th International Conference on Program Comprehension, 2006.
[20] B. Caprile and P. Tonella, “Restructuring program identifier names,” in International Conference on Software Maintenance, 2000, pp. 97–107.
[21] D. Lawrie, H. Feild, and D. Binkley, “Syntactic identifier conciseness and consistency,” in 6th International Working Conference on Source Code Analysis and Manipulation, 2006, pp. 139–148.
[22] E. Enslen, E. Hill, L. L. Pollock, and K. Vijay-Shanker, “Mining source code to automatically split identifiers for software analysis,” in 6th Working Conference on Mining Software Repositories, 2009.
[23] V. Arnaoudova, M. Di Penta, and G. Antoniol, “Linguistic antipatterns: What they are and how developers perceive them,” Empirical Software Engineering, vol. 21, no. 1, pp. 104–158, 2015.
[24] S. Misra and I. Akman, “Comparative study of cognitive complexity measures,” in 23rd International Symposium on Computer and Information Sciences, Oct 2008, pp. 1–4.
[25] E. J. Weyuker, “Evaluating software complexity measures,” IEEE Transactions on Software Engineering, vol. 14, no. 9, pp. 1357–1365, 1988.
[26] J. Bansiya and C. G. Davis, “A hierarchical model for object-oriented design quality assessment,” IEEE Transactions on Software Engineering, vol. 28, no. 1, pp. 4–17, Jan 2002.
[27] N. Kasto and J. Whalley, “Measuring the difficulty of code comprehension tasks using software metrics,” in 15th Australasian Computing Education Conference. Australian Computer Society, Inc., 2013, pp. 59–65.
[28] K. Shima, Y. Takemura, and K. Matsumoto, “An approach to experimental evaluation of software understandability,” in International Symposium on Empirical Software Engineering, 2002, pp. 48–55.
[29] ISO/IEC. Iso/iec 9126 software engineering — product quality — part 1: Quality model.
[30] T. J. McCabe, “A complexity measure,” IEEE Transactions on software Engineering, no. 4, pp. 308–320, 1976.
[31] S. Scalabrino, G. Bavota, C. Vendome, M. Linares-Vásquez, D. Poshyvanyk, and R. Oliveto, “Replication package.” https://dibt.unimol.it/report/understandability.
[32] R. F. Flesch, How to write plain English: A book for lawyers and consumers. Harpercollins, 1979.
[33] D. Schreck, V. Dallmeier, and T. Zimmermann, “How documentation evolves over time,” in Ninth International Workshop on Principles of Software Evolution. ACM, 2007, pp. 4–10.
[34] J. Kleinberg and É. Tardos, Algorithm design. Pearson Education India.
[35] J. W. Tukey, “Exploratory data analysis,” 1977.
[36] M. G. Kendall, “A new measure of rank correlation,” Biometrika, vol. 30, no. 1-2, p. 81, 1938.
[37] J. Cohen, Statistical power analysis for the behavioral sciences, 2nd ed. Lawrence Earlbaum Associates, 1988.

[1] D. Gopstein et al., “Understanding Misunderstandings in Source Code,” in Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, 2017.
[2] R. Stern, W. Ray, and K. Quigley, “Brain: Electroencephalography and imaging,” in Psychophysiological recording, 2001, pp. 79–105.
[3] F. Lopes da Silva, “EEG: Origin and Measurement,” in EEG-fMRI: Physiological Basis, Technique and Applications, C. Mulert and L. Lemieux, Eds. Berlin: Springer-Verlag, 2010.
[4] D. Millet, “The Origins of EEG,” in 7th Annual Meeting of the International Society for the History of the Neurosciences (ISHN), 2002.
[5] S. Raghavachari et al., “Gating of human theta oscillations by a working memory task,” J. Neurosci., vol. 21, no. 9, pp. 3175–3183, 2001.
[6] C. Tesche and J. Karhu, “Theta oscillations index human hippocampal activation during a working memory task,” Proc. Natl. Acad. Sci., vol. 97, no. 2, pp. 919–924, 2000.
[7] W. Klimesch, “EEG alpha and theta oscillations reflect cognitive and memory performance: a review and analysis,” Brain Res. Rev., vol. 29, no. 2, pp. 169–195, 1999.
[8] W. Klimesch, “EEG-alpha rhythms and memory processes,” Int. J. Psychophysiol., vol. 26, no. 1, pp. 319–340, 1997.
[9] P. L. Nunez, L. Reid, and R. G. Bickford, “The relationship of head size to alpha frequency with implications to a brain wave model,” Electroencephalogr. Clin. Neurophysiol., vol. 44, no. 3, pp. 344–352, 1978.
[10] G. Pfurtscheller and F. Lopes da Silva, “Event-Related EEG/MEG Synchronization and Desynchronization: Basic Principles,” Clin. Neurophysiol., vol. 110, no. 11, pp. 1842–1857, 1999.
[11] G. Pfurtscheller, “Graphical display and statistical evaluation of event-related desynchronization (ERD),” Electroencephalogr. Clin. Neurophysiol., vol. 43, no. 5, pp. 757–760, 1977.
[12] I. Crk, T. Kluthe, and A. Stefik, “Understanding programming expertise: an empirical study of phasic brain wave changes,” ACM Trans. Comput.-Hum. Interact. TOCHI, vol. 23, no. 1, p. 2, 2016.
[13] J. Sweller, P. Ayres, and S. Kalyuga, Cognitive Load Theory. New York, NY: Springer New York, 2011.
[14] P. D. Antonenko, F. Paas, R. Grabner, and T. van Gog, “Using Electroencephalography to Measure Cognitive Load,” Educ. Psychol. Rev., vol. 22, no. 4, pp. 425–438, Dec. 2010.
[15] P. D. Antonenko and D. S. Niederhauser, “The influence of leads on cognitive load and learning in a hypertext environment,” Comput. Hum. Behav., vol. 26, no. 2, pp. 140–150, Mar. 2010.
[16] I. Gerě and N. Jaušcvec, “Multimedia: Differences in cognitive processes observed with EEG,” Educ. Technol. Res. Dev., vol. 47, no. 3, pp. 5–14, 1999.
[17] F. C. Galán and C. R. Beal, “EEG estimates of engagement and cognitive workload predict math problem solving outcomes,” in User Modeling, Adaptation, and Personalization, Springer, 2012, pp. 51– 62.
[18] C.-M. Chen and S.-H. Huang, “Web-based reading annotation system with an attention-based self-regulated learning mechanism for promoting reading performance: Attention-based self-regulated learning mechanism,” Br. J. Educ. Technol., vol. 45, no. 5, pp. 959– 980, Sep. 2014.
[19] J. R. De Leeuw, “jsPsych: A JavaScript library for creating behavioral experiments in a Web browser,” Behav. Res. Methods, vol. 47, no. 1, pp. 1–12, 2015.
[20] W. Klimesch, “Memory processes, brain oscillations and EEG synchronization,” Int. J. Psychophysiol., vol. 24, no. 1, pp. 61–100, 1996.

[1] A. Agresti and M. Kateri, Categorical Data Analysis. Springer, 2011.
[2] M. Ali and M. O. Elish, “A comparative literature survey of design patterns impact on software quality”. In Intl. Conf. Inf. Sci. & App., Jun 2013, DOI: 10.1109/ICISA.2013.6579460.
[3] V. Arunachalam and W. Sasso, “Cognitive processes in program comprehension: An empirical analysis in the context of software reengineering”. J. Syst. & Softw. 34(3), pp. 177–189, Sep 1996, DOI: 10.1016/0164-1212(95)00074-7.
[4] T. Ball and J. R. Larus, “Using paths to measure, explain, and enhance program behavior”. Computer 33(7), pp. 57–65, Jul 2000, DOI: 10.1109/2.869371.
[5] G. R. Bergersen, D. I. K. Sjøberg, and T. Dybå, “Construction and validation of an instrument for measuring programming skill”. IEEE Trans. Softw. Eng. 40(12), pp. 1163–1184, Dec 2014, DOI: 10.1109/TSE.2014.2348997.
[6] R. Brooks, “Towards a theory of the comprehension of computer programs”. Intl. J. Man-Machine Studies 18(6), pp. 543–554, Jun 1983, DOI: 10.1016/S0020-7373(83)80031-5.
[7] R. P. L. Buse and W. R. Weimer, “A metric for software readability”. In Intl. Symp. Softw. Testing & Analysis, pp. 121– 130, Jul 2008, DOI: 10.1145/1390630.1390647.
[8] S. Butler, M. Wermelinger, Y. Yu, and H. Sharp, “Exploring the influence of identifier names on code quality: An empirical study”. In 14th European Conf. Softw. Maintenance & Reengineering, pp. 156–165, Mar 2010, DOI: 10.1109/CSMR.2010.27.
[9] B. Curtis, “Substantiating programmer variability”. Proc. IEEE 69(7), p. 846, Jul 1981, DOI: 10.1109/PROC.1981.12088.
[10] B. Curtis, J. Sappidi, and J. Subramanyam, “An evaluation of the internal quality of business applications: Does size matter?” In 33rd Intl. Conf. Softw. Eng., pp. 711–715, May 2011, DOI: 10.1145/1985793.1985893.
[11] B. Curtis, S. B. Sheppard, and P. Milliman, “Third time charm: Stronger prediction of programmer performance by software complexity metrics”. In 4th Intl. Conf. Softw. Eng., pp. 356– 360, Sep 1979.
[12] G. Denaro and M. Pezzè, “An empirical evaluation of faultproneness models”. In 24th Intl. Conf. Softw. Eng., pp. 241–251, May 2002, DOI: 10.1145/581339.581371.
[13] S. Deterding, D. Dixon, R. Khaled, and L. Nacke, “From game design elements to gamefulness: Defining “gamification””. In 15th Intl. Academic MindTrek Conf.: Envisioning Future Media Environments, pp. 9–15, 2011, DOI: 10.1145/2181037.2181040.
[14] E. W. Dijkstra, “Go To statement considered harmful”. Comm. ACM 11(3), pp. 147–148, Mar 1968, DOI: 10.1145/362929.362947.
[15] J. Feigenspan, S. Apel, J. Liebig, and C. Kästner, “Exploring software measures to assess program comprehension”. In Intl. Symp. Empirical Softw. Eng. & Measurement, pp. 127–136, Sep 2011, DOI: 10.1109/ESEM.2011.21.
[16] E. Gamma, R. Helm, R. Johnson, and J. Vlissides, Design Patterns: Elementsof Reusable Object-Oriented Software. Addison- Wesley, 1994.
[17] G. K. Gill and C. F. Kemerer, “Cyclomatic complexity density and software maintenance productivity”. IEEE Trans. Softw. Eng. 17(12), pp. 1284–1288, Dec 1991, DOI: 10.1109/32.106988.
[18] V. Gruhn and R. Laue, “On experiments for measuring cognitive weights for software control structures”. In 6th Intl. Conf. Cognitive Informatics, pp. 116–119, Aug 2007, DOI: 10.1109/COGINF.2007.4341880.
[19] S. Henry and D. Kafura, “Software structure metrics based on information flow”. IEEE Trans. Softw. Eng. SE-7(5), pp. 510– 518, Sep 1981, DOI: 10.1109/TSE.1981.231113.
[20] I. Herraiz and A. E. Hassan, “Beyond lines of code: Do we need more complexity metrics?” In Making Software: What Really Works, and Why We Believe It, A. Oram and G. Wilson (eds.), pp. 125–141, O’Reilly Media Inc., 2011.
[21] K. Huotari and J. Hamari, “Defining gamification: A service marketing perspective”. In 16th Intl. Academic MindTrek Conf., pp. 17–22, 2012, DOI: 10.1145/2393132.2393137.
[22] E. R. Iselin, “Conditional statements, looping constructs, and program comprehension: An experimental study”. Intl. J. Man-Machine Studies 28(1), pp. 45–66, Jan 1988, DOI: 10.1016/S0020-7373(88)80052-X.
[23] A. Jbara and D. G. Feitelson, “How programmer read regular code: A controlled experiment using eye tracking”. Empirical Softw. Eng. DOI: 10.1007/s10664-016-9477-x. (to appear).
[24] A. Jbara and D. G. Feitelson, “On the effect of code regularity on comprehension”. In 22nd Intl. Conf. Program Comprehension, pp. 189–200, Jun 2014, DOI: 10.1145/2597008.2597140.
[25] B. Katzmarski and R. Koschke, “Program complexity metrics and programmer opinions”. In 20th Intl. Conf. Program Comprehension, pp. 17–26, Jun 2012, DOI: 10.1109/ICPC.2012.6240486.
[26] M. Klerer, “Experimental study of a two-dimensional language vs Fortran for first-course programmers”. Intl. J. Man-Machine Studies 20(5), pp. 445–467, May 1984, DOI: 10.1016/S0020- 7373(84)80021-8.
[27] S. Letovsky, “Cognitive processes in program comprehension”. J. Syst. & Softw. 7(4), pp. 325–339, Dec 1987, DOI: 10.1016/0164- 1212(87)90032-X.
[28] P. Mair and R. Hatzinger, “Extended Rasch modeling: The eRm package for the application of IRT models in R”. J. Stat. Softw. 20(9), May 2007, DOI: 10.18637/jss.v020.i09.
[29] T. McCabe, “A complexity measure”. IEEE Trans. Softw. Eng. SE-2(4), pp. 308–320, Dec 1976, DOI: 10.1109/TSE.1976.233837.
[30] J. C. Munson and T. M. Khoshgoftaar, “Applications of a relative complexity metric for software project management”. J. Syst. & Softw. 12(3), pp. 283–291, Jul 1990, DOI: 10.1016/0164- 1212(90)90051-M.
[31] G. J. Myers, “An extension to the cyclomatic measure of program complexity”. SIGPLAN Notices 12(10), pp. 61–64, Oct 1977, DOI: 10.1145/954627.954633.
[32] B. T. Mynatt, “The effect of semantic complexity on the comprehension of program modules”. Intl. J. Man-Machine Studies 21(2), pp. 91–103, Aug 1984, DOI: 10.1016/S0020- 7373(84)80060-7.
[33] N. Ohlsson and H. Alberg, “Predicting fault-prone software modules in telephone switches”. IEEE Trans. Softw. Eng. 22(12), pp. 886–894, Dec 1996, DOI: 10.1109/32.553637.
[34] P. Piwowarski, “A nesting level complexity measure”. SIGPLAN Notices 17(9), pp. 44–50, Sep 1982, DOI: 10.1145/947955.947960.
[35] J. Rilling and T. Klemola, “Identifying comprehension bottlenecks using program slicing and cognitive complexity metrics”. In 11th IEEE Intl. Workshop Program Comprehension, pp. 115– 124, May 2003.
[36] H. Sackman, W. J. Erikson, and E. E. Grant, “Exploratory experimental studies comparing online and offline programming performance”. Comm. ACM 11(1), pp. 3–11, Jan 1968, DOI: 10.1145/362851.362858.
[37] N. Schneidewind and M. Hinchey, “A complexity reliability model”. In 20th Intl. Symp. Software Reliability Eng., pp. 1–10, Nov 2009, DOI: 10.1109/ISSRE.2009.10.
[38] J. Shao and Y. Wang, “A new measure of software complexity based on cognitive weights”. Canadian J. Elect. Comput. Eng. 28(2), pp. 69–74, Apr 2003, DOI: 10.1109/CJECE.2003.1532511.
[39] M. Shepperd, “A critique of cyclomatic complexity as a software metric”. Software Engineering J. 3(2), pp. 30–36, Mar 1988, DOI: 10.1049/sej.1988.0003.
[40] B. Shneiderman and R. Mayer, “Syntactic/semantic interactions in programmer behavior: A model and experimental results”. Intl. J. Comput. & Inf. Syst. 8(3), pp. 219–238, Jun 1979, DOI: 10.1007/BF00977789.
[41] E. Soloway and K. Ehrlich, “Empirical studies of programming knowledge”. IEEE Trans. Softw. Eng. SE-10(5), pp. 595–609, Sep 1984, DOI: 10.1109/TSE.1984.5010283.
[42] J. J. Vinju and M. W. Godfrey, “What does control flow really look like? Eyeballing the cyclomatic complexity metric”. In 12th IEEE Intl. Working Conf. Source Code Analysis & Manipulation, Sep 2012.
[43] A. von Mayrhauser and A. M. Vans, “Program comprehension during software maintenance and evolution”. Computer 28(8), pp. 44–55, Aug 1995, DOI: 10.1109/2.402076.
[44] E. J. Weyuker, “Evaluating software complexity measures”. IEEE Trans. Softw. Eng. 14(9), pp. 1357–1365, Sep 1988, DOI: 10.1109/32.6178. 76

[1] Krishan K Aggarwal, Yogesh Singh, and Jitender Kumar Chhabra. 2002. An integrated measure of software maintainability. In Proc. Annual Reliability and Maintainability Symposium. IEEE, 235–241.
[2] Paul D Allison. 1999. Multiple regression: A primer. Pine Forge Press.
[3] Marc Bartsch and Rachel Harrison. 2008. An exploratory study of the effect of aspect-oriented programming on maintainability. Software Quality Journal 16, 1 (2008), 23–44.
[4] Douglas M. Bates. 2010. lme4: Mixed-effects modeling with R. http://lme4.r-forge. r-project.org/book/
[5] Richard Berk, Lawrence Brown, and Linda Zhao. 2010. Statistical inference after model selection. Journal of Quantitative Criminology 26, 2 (2010), 217–236.
[6] Raymond PL Buse and Westley R Weimer. 2010. Learning a metric for code readability. IEEE Transactions on Software Engineering 36, 4 (2010), 546–558.
[7] Andrea Capiluppi, Maurizio Morisio, and Patricia Lago. 2004. Evolution of understandability in OSS projects. In Proc. European Conference on Software Maintenance and Reengineering (CSMR). IEEE, 58–66.
[8] Ermira Daka, José Campos, Gordon Fraser, Jonathan Dorn, and Westley Weimer. 2015. Modeling readability to improve unit tests. In Proc. Joint Meeting on Foundations of Software Engineering (ESEC/FSE). ACM, 107–118.
[9] Jonathan Dorn. 2012. A general software readability model. MCS Thesis available from (http://www. cs. virginia. edu/˜ weimer/students/dorn-mcs-paper. pdf) (2012).
[10] Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2017. An Introduction to Statistical Learning with Applications in R. Springer.
[11] Natalia Juristo and Omar S Gómez. 2012. Replication of software engineering experiments. In Empirical Software Engineering and Verification. Springer, 60–88.
[12] Jin-Cherng Lin and Kuo-Chiang Wu. 2006. A model for measuring software understandability. In Proc. International Conference on Computer and Information Technology (CIT). IEEE, 192–192.
[13] Jin-Cherng Lin and Kuo-Chiang Wu. 2008. Evaluation of software understandability based on fuzzy matrix. In Proc. International Conference on Fuzzy Systems. IEEE, 887–892.
[14] Roberto Minelli, Andrea Mocci, and Michele Lanza. 2015. I know what you did last summer: an investigation of how developers spend their time. In Proc. International Conference on Program Comprehension (ICPC). IEEE, 25–35.
[15] Shinichi Nakagawa and Holger Schielzeth. 2013. A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods in Ecology and Evolution 4, 2 (2013), 133–142.
[16] Daryl Posnett, Abram Hindle, and Premkumar Devanbu. 2011. A simpler model of software readability. In Proc. International Conference on Mining Software Repositories. ACM, 73–82.
[17] Simone Scalabrino, Gabriele Bavota, Christopher Vendome, Mario Linares- Vásquez, Denys Poshyvanyk, and Rocco Oliveto. 2017. Automatically Assessing Code Understandability: How Far Are We?. In Proc. International Conference on Automated Software Engineering (ASE). IEEE.
[18] Simone Scalabrino, Mario Linares-Vásquez, Denys Poshyvanyk, and Rocco Oliveto. 2016. Improving code readability models with textual features. In Proc. International Conference on Program Comprehension (ICPC). IEEE, 1–10.
[19] D Srinivasulu, Adepu Sridhar, and Durga Prasad Mohapatra. 2014. Evaluation of Software Understandability Using Rough Sets. In Intelligent Computing, Networking, and Informatics. Springer, 939–946.
[20] M-A Storey. 2005. Theories, methods and tools in program comprehension: Past, present and future. In Proc. International Conference on Program Comprehension (ICPC). IEEE, 181–191.
[21] M-AD Storey, Kenny Wong, and Hausi A Müller. 2000. How do program understanding tools affect how programmers understand programs? Science of Computer Programming 36, 2-3 (2000), 183–207.
[22] Asher Trockman, Shurui Zhou, Christian Kästner, and Bogdan Vasilescu. 2018. Adding Sparkle to Social Coding: An Empirical Study of Repository Badges in the npm Ecosystem. In Proc. International Conference on Software Engineering (ICSE). ACM. 318

[1] R. Minelli, A. Mocci, and M. Lanza, “I know what you did last summer - an investigation of how developers spend their time,” in 23rd IEEE International Conference on Program Comprehension, 2015, pp. 25–35.
[2] K. K. Aggarwal, Y. Singh, and J. K. Chhabra, “An integrated measure of software maintainability,” in Annual Reliability and Maintainability Symposium., 2002, pp. 235–241.
[3] M. Thongmak and P. Muenchaisri, Measuring Understandability of Aspect-Oriented Code. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011, pp. 43–54.
[4] J. c. Lin and K. c. Wu, “A model for measuring software understandability,” in 6th IEEE International Conference on Computer and Information Technology, 2006, pp. 192–192.
[5] T. Roehm, R. Tiarks, R. Koschke, and W. Maalej, “How do professional developers comprehend software?” in 34th International Conference on Software Engineering (ICSE), 2012, pp. 255–265.
[6] D. Srinivasulu, A. Sridhar, and D. P. Mohapatra, Evaluation of Software Understandability Using Rough Sets. New Delhi: Springer India, 2014, pp. 939–946.
[7] C. Chen, R. Alfayez, K. Srisopha, L. Shi, and B. Boehm, Evaluating Human-Assessed Software Maintainability Metrics. Singapore: Springer Singapore, 2016, pp. 120–132.
[8] M. A. Storey, “Theories, methods and tools in program comprehension: past, present and future,” in 13th International Workshop on Program Comprehension, 2005, pp. 181–191.
[9] M. A. D. Storey, K. Wong, and H. A. Muller, “How do program understanding tools affect how programmers understand programs?” in 4th Working Conference on Reverse Engineering, 1997, pp. 12–21.
[10] R. P. L. Buse and W. Weimer, “Learning a metric for code readability,” IEEE Transactions on Software Engineering, vol. 36, no. 4, pp. 546–558, 2010.
[11] D. Posnett, A. Hindle, and P. T. Devanbu, “A simpler model of software readability.” in 8th Working Conference on Mining Software Repositories, 2011, pp. 73–82.
[12] J. Dorn, “A general software readability model,” Master’s thesis, University of Virginia, Department of Computer Science, https://www.cs.virginia.edu/~weimer/students/dornmcs- paper.pdf, 2012.
[13] E. Daka, J. Campos, G. Fraser, J. Dorn, and W. Weimer, “Modeling readability to improve unit tests,” in 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, 2015, pp. 107– 118.
[14] S. Scalabrino, M. Linares-Vásquez, D. Poshyvanyk, and R. Oliveto, “Improving code readability models with textual features,” in 24th IEEE International Conference on Program Comprehension, 2016.
[15] ——, “A comprehensive model for code readability,” Journal of Software: Evolution and Process, vol. 30, no. 6, June 2018.
[16] J.-C. Lin and K.-C. Wu, “Evaluation of software understandability based on fuzzy matrix,” in IEEE International Conference on Fuzzy Systems, 2008, pp. 887–892.
[17] M. Bartsch and R. Harrison, “An exploratory study of the effect of aspect-oriented programming on maintainability,” Software Quality Journal, vol. 16, no. 1, pp. 23–44, 2008.
[18] A. Capiluppi, M. Morisio, and P. Lago, “Evolution of understandability in oss projects,” in 8th European Conference on Software Maintenance and Reengineering, 2004, pp. 58–66.
[19] S. Scalabrino, G. Bavota, C. Vendome, M. Linares-Vásquez, D. Poshyvanyk, and R. Oliveto, “Automatically assessing code understandability: how far are we?” in Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering. IEEE Press, 2017, pp. 417–427.
[20] D. Lawrie, C. Morrell, H. Feild, and D. Binkley, “Effective identifier names for comprehension and memory.” Innovations in Systems and Software Engineering, vol. 3, no. 4, pp. 303–318, 2007.
[21] ——, “What’s in a name? a study of identifiers,” in 14th International Conference on Program Comprehension, 2006.
[22] B. Caprile and P. Tonella, “Restructuring program identifier names,” in International Conference on Software Maintenance, 2000, pp. 97–107.
[23] D. Lawrie, H. Feild, and D. Binkley, “Syntactic identifier conciseness and consistency,” in 6th International Working Conference on Source Code Analysis and Manipulation, 2006, pp. 139–148.
[24] E. Enslen, E. Hill, L. L. Pollock, and K. Vijay-Shanker, “Mining source code to automatically split identifiers for software analysis,” in 6th Working Conference on Mining Software Repositories, 2009.
[25] V. Arnaoudova, M. Di Penta, and G. Antoniol, “Linguistic antipatterns: What they are and how developers perceive them,” Empirical Software Engineering, vol. 21, no. 1, pp. 104–158, 2015.
[26] S. Misra and I. Akman, “Comparative study of cognitive complexity measures,” in 23rd International Symposium on Computer and Information Sciences, Oct 2008, pp. 1–4.
[27] E. J. Weyuker, “Evaluating software complexity measures,” IEEE Transactions on Software Engineering, vol. 14, no. 9, pp. 1357–1365, 1988.
[28] J. Bansiya and C. G. Davis, “A hierarchical model for objectoriented design quality assessment,” IEEE Transactions on Software Engineering, vol. 28, no. 1, pp. 4–17, Jan 2002.
[29] N. Kasto and J. Whalley, “Measuring the difficulty of code comprehension tasks using software metrics,” in 15th Australasian Computing Education Conference. Australian Computer Society, Inc., 2013, pp. 59–65.
[30] K. Shima, Y. Takemura, and K. Matsumoto, “An approach to experimental evaluation of software understandability,” in International Symposium on Empirical Software Engineering, 2002, pp. 48– 55.
[31] ISO/IEC. Iso/iec 9126 software engineering — product quality — part 1: Quality model.
[32] A. Trockman, K. Cates, M. Mozina, T. Nguyen, C. Kästner, and B. Vasilescu, “"automatically assessing code understandability" reanalyzed: Combined metrics matter,” 2018.
[33] S. Scalabrino, G. Bavota, C. Vendome, M. Linares-Vásquez, D. Poshyvanyk, and R. Oliveto, “Replication package.” https://dibt.unimol.it/report/understandability-tse.
[34] T. J. McCabe, “A complexity measure,” IEEE Transactions on software Engineering, no. 4, pp. 308–320, 1976.
[35] R. F. Flesch, How to write plain English: A book for lawyers and consumers. Harpercollins, 1979.
[36] D. Schreck, V. Dallmeier, and T. Zimmermann, “How documentation evolves over time,” in Ninth International Workshop on Principles of Software Evolution. ACM, 2007, pp. 4–10.
[37] J. Kleinberg and É. Tardos, Algorithm design. Pearson Education India.
[38] J. W. Tukey, “Exploratory data analysis,” 1977.
[39] M. G. Kendall, “A new measure of rank correlation,” Biometrika, vol. 30, no. 1-2, p. 81, 1938.
[40] J. Cohen, Statistical power analysis for the behavioral sciences, 2nd ed. Lawrence Earlbaum Associates, 1988.
[41] S. Le Cessie and J. C. Van Houwelingen, “Ridge estimators in logistic regression,” Applied statistics, pp. 191–201, 1992.
[42] G. H. John and P. Langley, “Estimating continuous distributions in bayesian classifiers,” in Proceedings of the Eleventh conference on Uncertainty in artificial intelligence. Morgan Kaufmann Publishers Inc., 1995, pp. 338–345.
[43] J. Platt, “Fast training of support vector machines using sequential minimal optimization. advances in kernel methods—support vector learning (pp. 185–208),” AJ, MIT Press, Cambridge, MA, 1999.
[44] D. W. Aha, D. Kibler, and M. K. Albert, “Instance-based learning algorithms,” Machine learning, vol. 6, no. 1, pp. 37–66, 1991.
[45] L. Breiman, “Random forests,” Machine learning, vol. 45, no. 1, pp. 5–32, 2001.
[46] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, “Smote: synthetic minority over-sampling technique,” Journal of artificial intelligence research, vol. 16, pp. 321–357, 2002.
[47] S. K. Shevade, S. S. Keerthi, C. Bhattacharyya, and K. R. K. Murthy, “Improvements to the smo algorithm for svm regression,” IEEE transactions on neural networks, vol. 11, no. 5, pp. 1188–1193, 2000.
[48] M. A. Bowles, The think-aloud controversy in second language research. Routledge, 2010.
[49] S. F. Biggs, A. J. Rosman, and G. K. Sergenian, “Methodological issues in judgment and decision-making research: Concurrent verbal protocol validity and simultaneous traces of process,” Journal of Behavioral Decision Making, vol. 6, no. 3, pp. 187–206, 1993.
[50] J. A. Brinkman, “Verbal protocol accuracy in fault diagnosis,” Ergonomics, vol. 36, no. 11, pp. 1381–1397, 1993.
[51] U. Lass, W. Klettke, G. Lüer, and P. Ruhlender, “Does thinking aloud influence the structure of cognitive processes,” Oculomotor control and cognitive processes, pp. 385–396, 1991.
[52] D. Rhenius and G. Deffner, “Evaluation of concurrent thinking aloud using eye-tracking data,” in Proceedings of the human factors society annual meeting, vol. 34, no. 17. SAGE Publications Sage CA: Los Angeles, CA, 1990, pp. 1265–1269.
[53] A. Williams and K. Davids, “Assessing cue usage in performance contexts: A comparison between eye-movement and concurrent verbal report methods,” Behavior Research Methods, Instruments, & Computers, vol. 29, no. 3, pp. 364–375, 1997.
[54] J. F. Stratman and L. Hamp-Lyons, “Reactivity in concurrent think-aloud protocols: Issues for research,” Speaking about writing: Reflections on research methodology, vol. 8, pp. 89–111, 1994.
[55] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten, “The weka data mining software: an update,” ACM SIGKDD explorations newsletter, vol. 11, no. 1, pp. 10–18, 2009.

[1] L. Erlikh, “Leveraging legacy system dollars for e-business,” IT Professional, vol. 2, no. 3, pp. 17–23, 2000.
[2] S. W. Yip and T. Lam, “A software maintenance survey,” in Proc. 1st Asia-Pacific Softw. Eng. Conf., 1994, pp. 70–79.
[3] J. R. Foster, “Cost factors in software maintenance,” Ph.D. dissertation, School Eng. Comput. Sci., Univ. Durham, Durham, U.K., 1993.
[4] V. Nguyen, “Improved size and effort estimation models for software maintenance,” in Proc. 26th Int. Conf. Softw. Maintenance, 2010, pp. 1–2.
[5] T. D. LaToza, G. Venolia, and R. DeLine, “Maintaining mental models: A study of developer work habits,” in Proc. 28th Int. Conf. Softw. Eng., 2006, pp. 492–501.
[6] J.-C. Chen and S.-J. Huang, “An empirical analysis of the impact of software development problem factors on software maintainability,” J. Syst. Softw., vol. 82, no. 6, pp. 981–992, 2009.
[7] E. Arisholm, L. C. Briand, S. E. Hove, and Y. Labiche, “The impact of UML documentation on software maintenance: An experimental evaluation,” IEEE Trans. Softw. Eng., vol. 32, no. 6, pp. 365–381, Jun. 2006.
[8] T. C. Lethbridge, J. Singer, and A. Forward, “How software engineers use documentation: The state of the practice,” IEEE Softw., vol. 20, no. 6, pp. 35–39, Nov./Dec. 2003.
[9] B. W. Kernighan and P. J. Plauger, The Elements of Programming Style. New York, NY, USA: McGraw-Hill, 1978.
[10] D. Spinellis, “Code documentation,” IEEE Softw., vol. 27, no. 4, pp. 18–19, Jul./Aug. 2010.
[11] K. Petersen, “Implementing lean and agile software development in industry,” Ph.D. dissertation, School Comput., Blekinge Inst. Technol., Karlskrona, Sweden, 2010.
[12] P. W. Oman and C. R. Cook, “A programming style taxonomy,” J. Syst. Softw., vol. 15, no. 3, pp. 287–301, 1991.
[13] H. Sutter and A. Alexandrescu, C++ Coding Standards: 101 Rules, Guidelines, and Best Practices. New York, NY, USA: Pearson Education, 2004.
[14] A. Vermeulen, S. W. Ambler, G. Bumgardner, E. Metz, T. Misfeldt, J. Shur, and P. Thompson, The Elements of Java (TM) Style. Cambridge, U.K.: Cambridge Univ. Press, 2000.
[15] F. Buschmann, R. Meunier, H. Rohnert, P. Sommerlad, and M. Stal, Pattern-Oriented Software Architecture: A System of Patterns. New York, NY, USA: Wiley, 1996.
[16] E. Gamma, R. Helm, R. Johnson, and J. Vlissides, Design Patterns: Elements of Reusable Object-Oriented Software. Reading, MA, USA: Addison-Wesley, 1995.
[17] K. J. Lieberherr and I. M. Holland, “Assuring good style for objectoriented programs,” IEEE Softw., vol. 6, no. 5, pp. 38–48, Sep. 1989.
[18] A. J. Riel, Object-Oriented Design Heuristics. Reading, MA, USA: Addison-Wesley, 1996.
[19] M. Fowler, Refactoring: Improving the Design of Existing Code. Reading, MA, USA: Addison-Wesley, 1999.
[20] M. Kim, T. Zimmermann, and N. Nagappan, “An empirical study of refactoring challenges and benefits at Microsoft,” IEEE Trans. Softw. Eng., vol. 40, no. 7, pp. 633–649, Jul. 2014.
[21] J. Kerievsky, Refactoring to Patterns. Reading, MA, USA: Addison- Wesley, 2005.
[22] D. Posnett, A. Hindle, and P. Devanbu, “A simpler model of software readability,” in Proc. 8th Working Conf. Mining Softw. Repositories, 2011, pp. 73–82.
[23] M. Fowler, Domain-Specific Languages. Reading, MA, USA: Addison- Wesley, 2010.
[24] Y. E. Keskin. (2014, Mar.). Fluent interface for more readable code. [Online]. Available: http://java.dzone.com/articles/fluentinterface- more-readable-0
[25] Y. Guo, M. W€ursch, E. Giger, and H. C. Gall, “An empirical validation of the benefits of adhering to the law of Demter,” in Proc. 18th Working Conf. Reverse Eng., 2011, pp. 239–243.
[26] R. Green and H. Ledgard, “Coding guidelines: Finding the art in the science,” Commun. ACM, vol. 54, no. 12, pp. 57–63, 2011.
[27] A. Jedlitschka, M. Ciolkowski, and D. Pfahl, “Reporting experiments in software engineering,” in Guide to Advanced Empirical Software Engineering. New York, NY, USA: Springer, 2008, pp. 201–228.
[28] C. Wohlin, P. Runeson, M. H€ost, M. C. Ohlsson, B. Regnell, and A. Wesslen, Experimentation in Software Engineering. New York, NY, USA: Springer, 2012.
[29] M.-A. Storey, “Theories, tools and research methods in program comprehension: Past, present and future,” Softw. Quality J., vol. 14, no. 3, pp. 187–208, 2006.
[30] M. Smith and R. Taffler, “Readability and understandability: Different measures of the textual complexity of accounting narrative,” Accounting, Auditing Accountability J., vol. 5, no. 4, pp. 84–98, 1992.
[31] G. R. Klare, “Readable computer documentation,” J. Comput. Documentation, vol. 24, no. 3, pp. 148–168, 2000.
[32] W. H. DuBay, The Principles of Readability. Costa Mesa, CA, USA: Impact Inf., 2004.
[33] G. Hargis, “Readability and computer documentation,” J. Comput. Documentation, vol. 24, no. 3, pp. 122–131, 2000.
[34] D. E. Knuth, “Literate programming,” Comput. J., vol. 27, no. 2, pp. 97–111, 1984.
[35] J. L. Elshoff and M. Marcotty, “Improving computer program readability to aid modification,” Commun. ACM, vol. 25, no. 8, pp. 512–521, 1982.
[36] L. E. Deimel and J. F. Naveda, “Reading computer programs: Instructor’s guide and exercises,” Softw. Eng. Inst., Pittsburgh, PA, USA, Tech. Rep. CMU/SEI-90-EM-3, 1990.
[37] J. B€orstler, M. E. Caspersen, and M. Nordstr€om, “Beauty and the beast—Toward a measurement framework for example program quality,” Dept. Comput. Sci., Umea  Univ., Umea  , Sweden, Tech. Rep. UMINF-07.23, 2007.
[38] R. P. Buse and W. R. Weimer, “Learning a metric for code readability,” IEEE Trans. Softw. Eng., vol. 36, no. 4, pp. 546–558, Jul./Aug. 2010.
[39] J. B€orstler, M. E. Caspersen, and M. Nordstr€om. (2015). Beauty and the beast: On the readability of object-oriented example programs, Softw. Quality J.. [Online]. Available: http://link.springer. com/article/10.1007/s11219-015-9267-5
[40] D. Lawrie, H. Feild, and D. Binkley, “Quantifying identifier quality: An analysis of trends,” Empirical Softw. Eng., vol. 12, no. 4, pp. 359–388, 2007.
[41] D. Binkley, M. Davis, D. Lawrie, J. I. Maletic, C. Morrell, and B. Sharif, “The impact of identifier style on effort and comprehension,” Empirical Softw. Eng., vol. 18, no. 2, pp. 219–276, 2013.
[42] S. Butler, M. Wermelinger, Y. Yu, and H. Sharp, “Exploring the influence of identifier names on code quality: An empirical study,” in Proc. 14th Eur. Conf. Softw. Maintenance Reeng., 2010, pp. 156–165.
[43] A. von Mayrhauser and A. M. Vans, “Program comprehension during software maintenance and evolution,” IEEE Comput., vol. 28, no. 8, pp. 44–55, Aug. 1995.
[44] F. Detienne, Software Design–Cognitive Aspects. New York, NY, USA: Springer, 2002.
[45] R. Marinescu and C. Marinescu, “Are the clients of flawed classes (also) defect prone?” in Proc. 11th IEEE Int. Working Conf. Source Code Anal. Manipulation, 2011, pp. 65–74.
[46] S. W. Ambler, A. Vermeulen, and G. Bumgardner, The Elements of Java Style. New York, NY, USA: Cambridge Univ. Press, 1999.
[47] R. C. Martin, Clean Code: A Handbook of Agile Software Craftsmanship. Boston, MA, USA: Prentice-Hall, 2008.
[48] S. N. Woodfield, H. E. Dunsmore, and V. Y. Shen, “The effect of modularization and comments on program comprehension,” in Proc. 5th Int. Conf. Softw. Eng., 1981, pp. 215–223.
[49] T. Tenny, “Program readability: Procedures versus comments,” IEEE Trans. Softw. Eng., vol. 14, no. 9, pp. 1271–1279, Sep. 1988.
[50] A. Norcio, “Indentation, documentation and programmer comprehension,” in Proc. Conf. Human Factors Comput. Syst., 1982, pp. 118–120.
[51] A. A. Takang, P. A. Grubb, and R. D. Macredie, “The effects of comments and identifier names on program comprehensibility: An experimental investigation,” J. Program. Lang., vol. 4, no. 3, pp. 143–167, 1996.
[52] E. Nurvitadhi, W. W. Leung, and C. Cook, “Do class comments aid Java program understanding?” in Proc. 33rd Annu. Frontiers Educ., vol. 1, 2003, p. T3C-13.
[53] B. W. Kernighan and D. M. Ritchie, The C Programming Language, vol. 2. Englewood Cliffs, NJ, USA: Prentice-Hall, 1988.
[54] C. Cook, W. Bregar, and D. Foote, “A preliminary investigation of the use of the cloze procedure as a measure of program understanding,” Inf. Process. Manage., vol. 20, no. 1, pp. 199–208, 1984.
[55] W. E. Hall and S. H. Zweben, “The cloze procedure and software comprehensibility measurement,” IEEE Trans. Softw. Eng., vol. SE- 12, no. 5, pp. 608–623, May 1986.
[56] J. Siegmund, C. K€astner, J. Liebig, S. Apel, and S. Hanenberg, “Measuring and modeling programming experience,” Empirical Softw. Eng., vol. 19, pp. 1299–1334, 2014.
[57] W. Kintsch and D. Vipond, “Reading comprehension and readability in educational practice and psychological theory,” in Perspectives on Memory Research, L.-G. Nilss, Ed., Mahwah NJ, USA: Lawrence Erlbaum Assoc., 1979.

[1] W. J. Brown, R. C. Malveau, W. H. Brown, H. W. McCormick III, and T. J. Mowbray, Anti Patterns: Refactoring Software, Architectures, and Projects in Crisis, 1𝑠𝑡 ed. John Wiley and Sons, March 1998. [Online]. Available: www.amazon.com/exec/obidos/tg/detail/-/0471197130/ref=ase∖ theantipatterngr/103-4749445-6141457
[2] J. O. Coplien and N. B. Harrison, Organizational Patterns of Agile Software Development, 1𝑠𝑡 ed. Prentice-Hall, Upper Saddle River, NJ (2005), 2005.
[3] M. Fowler, Refactoring – Improving the Design of Existing Code, 1𝑠𝑡 ed. Addison-Wesley, June 1999.
[4] A. von Mayrhauser and A. M. Vans, “Program comprehension during software maintenance and evolution,” Computer, vol. 28, no. 8, pp. 44–55, 1995.
[5] F. Khomh and Y.-G. Gu´eh´eneuc, “Do design patterns impact software quality positively?” in Proceedings of the 12𝑡ℎ Conference on Software Maintenance and Reengineering, C. Tjortjis and A. Winter, Eds. IEEE Computer Society Press, April 2008.
[6] Foutse Khomh, M. Di Penta, and Y.-G. Gu´eh´eneuc, “An exploratory study of the impact of code smells on software change-proneness,” in Proceedings of the 16𝑡ℎ Working Conference on Reverse Engineering (WCRE). IEEE CS Press, October 2009. [Online]. Available: http://www-etud.iro.umontreal. ca/∼ptidej/Publications/Documents/WCRE09a.doc.pdf
[7] J. Sillito, “Asking and answering questions during a programming change task,” Ph.D. dissertation, Vancouver, BC, Canada, Canada, 2007.
[8] D. L. Parnas, “Software aging,” in ICSE ’94: Proceedings of the 16th international conference on Software engineering. Los Alamitos, CA, USA: IEEE Computer Society Press, 1994, pp. 279–287.
[9] B. F. Webster, Pitfalls of Object Oriented Development, 1𝑠𝑡 ed. M & T Books, February 1995. [Online]. Available: www.amazon.com/exec/obidos/ ASIN/1558513973
[10] A. J. Riel, Object-Oriented Design Heuristics. Addison-Wesley, 1996.
[11] M. Mantyla, “Bad smells in software - a taxonomy and an empirical study.” Ph.D. dissertation, Helsinki University of Technology, 2003.
[12] W. C. Wake, Refactoring Workbook. Boston, MA, USA: Addison-Wesley Longman Publishing Co., Inc., 2003.
[13] G. Travassos, F. Shull, M. Fredericks, and V. R. Basili, “Detecting defects in object-oriented designs: using reading techniques to increase software quality,” in Proceedings of the 14𝑡ℎ Conference on Object-Oriented Programming, Systems, Languages, and Applications. ACM Press, 1999, pp. 47–56.
[14] R. Marinescu, “Detection strategies: Metrics-based rules for detecting design flaws,” in Proceedings of the 20𝑡ℎ International Conference on Software Maintenance. IEEE CS Press, 2004, pp. 350–359.
[15] M. J. Munro, “Product metrics for automatic identification of “bad smell” design problems in java source-code,” in Proceedings of the 11𝑡ℎ International Software Metrics Symposium. IEEE Computer Society Press, September 2005. [Online]. Available: http://doi.ieeecomputersociety.org/10. 1109/METRICS.2005.38
[16] R. Oliveto, F. Khomh, G. Antoniol, and Y.-G. Gu´eh´eneuc, “Numerical signatures of antipatterns: An approach based on b-splines,” in Proceedings of the 14𝑡ℎ Conference on Software Maintenance and Reengineering, R. F. Rafael Capilla and J. C. Dueas, Eds. IEEE Computer Society Press, March 2010.
[17] Naouel Moha, Y.-G. Gu´eh´eneuc, L. Duchien, and A.-F. L. Meur, “DECOR: A method for the specification and detection of code and design smells,” Transactions on Software Engineering (TSE), 2009. [Online]. Available: http://www-etud.iro.umontreal.ca/∼ptidej/Publications/ Documents/TSE09.doc.pdf
[18] Foutse Khomh, St´ephane Vaucher, Y.-G. Gu´eh´eneuc, and H. Sahraoui, “A bayesian approach for the detection of code and design smells,” in Proceedings of the 9𝑡ℎ International Conference on Quality Software (QSIC). IEEE CS Press, August 2009, 10 pages. [Online]. Available: http://www-etud.iro.umontreal.ca/∼ptidej/Publications/ Documents/QSIC09.doc.pdf
[19] S. Olbrich, D. S. Cruzes, V. Basili, and N. Zazworka, “The evolution and impact of code smells: A case study of two open source systems,” in Third International Symposium on Empirical Software Engineering and Measurement, 2009.
[20] A. Chatzigeorgiou and A. Manakos, “Investigating the evolution of bad smells in object-oriented code,” in QUATIC ’10: Proceedings of the 7𝑡ℎ International Conference on the Quality of Information and Communications Technology. IEEE Computer Society Press, 2010.
[21] D. Ignatios, S. Ioannis, A. Lefteris, R. Manos, and S. Martin, “A controlled experiment investigation of an object oriented design heuristic for maintainability,” Journal of Systems and Software, vol. 65, no. 2, February 2003.
[22] D. Ignatios, S. Martin, R. Manos, and S. Ioannis, “An empirical investigation of an object-oriented design heuristic for maintainability,” Journal of Systems and Software, vol. 72, no. 2, 2004.
[23] B. D. Bois, S. Demeyer, J. Verelst, T. Mens, and M. Temmerman, “Does god class decomposition affect comprehensibility?” in Proceedings of the IASTED International Conference on Software Engineering. IASTED/ ACTA Press, 2006, pp. 346–355.
[24] N. Moha and Y.-G. Gu´eh´eneuc, “On the automatic detection and correction of software architectural defects in object-oriented designs,” in In Proceedings of the 6 th ECOOP Workshop on Object-Oriented Reengineering. Universities of Glasgow and Strathclyde, 2005.
[25] S. Vaucher, F. Khomh, N. Moha, and Y.-G. Gueheneuc, “Tracking design smells: Lessons from a study of god classes,” Reverse Engineering, Working Conference on, vol. 0, pp. 145–154, 2009.
[26] N. Moha, Y. G. Gu´eh´eneuc, L. Duchien, and A. F. Le Meur, “Decor: A method for the specification and detection of code and design smells,” IEEE Transactions on Software Engineering, vol. 36, no. 1, pp. 20–36, 2010.
[27] C. Wohlin, P. Runeson, M. H¨ost, M. C. Ohlsson, B. Regnell, and A. Wessl´en, Experimentation in software engineering: an introduction. Norwell, MA, USA: Kluwer Academic Publishers, 2000.
[28] J. Tant´eri, “Eyes of darwin : une fenˆetre ouverte sur l’´evolution du logiciel,” Master’s thesis, Universit´e de Montr´eal, septembre 2009, master’s thesis.
[29] W. Wu, Y.-G. Gu´eh´eneuc, G. Antoniol, and M. Kim, “Aura: a hybrid approach to identify framework evolution,” in ICSE ’10: Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering. New York, NY, USA: ACM, 2010, pp. 325–334.
[30] M. Fowler, Refactoring: Improving the Design of Existing Code. Boston, MA, USA: Addison-Wesley, 1999.
[31] S. G. Hart and L. E. Stavenland, “Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research,” pp. 139–183, 1988.
[32] “Nasa task load index (tlx) v. 1.0,” p. 1.
[33] A. T. Duchowski, Eye Tracking Methodology: Theory and Practice. Secaucus, NJ, USA: Springer-Verlag New York, Inc., 2007.
[34] S. D.J., Handbook of Parametric and Nonparametric Statistical Procedures (fourth edition). Chapman & All, 2007. 
[35] D. W. Zimmerman, “Comparative power of student t test and mann-whitney u test for unequal sample sizes and variances,” IEEE Trans. Softw. Eng., vol. 55, 1987.
[36] G. Cepeda Porras and Y.-G. Gu´eh´eneuc, “An empirical study on the efficiency of different design pattern representations in uml class diagrams,” Empirical Softw. Engg., vol. 15, no. 5, pp. 493–522, 2010.
[37] M. D’Ambros, A. Bacchelli, and M. Lanza, “On the impact of design flaws on software defects,” in QSIC ’10: Proceedings of the 2010 10th International Conference on Quality Software. Washington, DC, USA: IEEE Computer Society, 2010, pp. 23–31.

[1] F. P. Brooks Jr., The mythical man-month. Addison-Wesley, 1975.
[2] Computer Science Curriculum 2008: An Interim Revision of CS 2001. ACM and the IEEE Computer Society, 2008.
[3] P. Bourque and R. Dupuis, Guide to the software engineering body of knowledge. IEEE Computer Society Press, 2004.
[4] A. Pyster and et al, Graduate Software Engineering (GSwE2009) Curriculum Guidelines for Graduate Degree Programs in Software Engineering. Stevens Institute, 2009.
[5] B. W. Kernighan and P. J. Plauger, The Elements of Programming Style, 1982.
[6] G. M. Weinberg, Understanding the Professional Programmer. Dorset House, 1982.
[7] A. Hunt and D. Thomas, The pragmatic programmer: from journeyman to master. Addison-Wesley Longman Publishing Co., Inc., 2000.
[8] R. C. Martin, Clean Code: A Handbook of Agile Software Craftsmanship. Prentice Hall PTR, 2008.
[9] K. Beck, Implementation Patterns. Addison-Wesley Professional, 2006.
[10] X. Wang, L. Pollock, and K. Vijay-Shanker, “Automatic segmentation of method code into meaningful blocks to improve readability,” in Proceedings of the 2011 18th Working Conference on Reverse Engineering.
[11] Y. Sasaki, Y. Higo, and S. Kusumoto, “Reordering program statements for improving readability,” in Software Maintenance and Reengineering (CSMR), 2013 17th European Conference on, March 2013.
[12] D. Binkley, D. Lawrie, S. Maex, and C. Morrell, “Identifier length and limited programmer memory,” Science of Computer Programming, 2009.
[13] S. Butler, M. Wermelinger, Y. Yu, and H. Sharp, “Exploring the influence of identifier names on code quality: An empirical study,” in Proceedings of the 2010 14th European Conference on Software Maintenance and Reengineering. IEEE Computer Society, Conference Proceedings.
[14] B. Liblit, A. Begel, and E. Sweeser, “Cognitive perspectives on the role of naming in computer programs,” in Proceedings of the 18th Annual Psychology of Programming Workshop, Conference Proceedings.
[15] P. A. Relf, “Tool assisted identifier naming for improved software readability: an empirical study,” in 2005 International Symposium on Empirical Software Engineering.
[16] D. Binkley, M. Davis, D. Lawrie, and C. Morrell, “To camelcase or under score,” in ICPC ’09. IEEE 17th International Conference on Program Comprehension, Conference Proceedings, pp. 158–167.
[17] D. M. Jones, “Operand names influence operator precedence decisions,” CVu, 2008.
[18] R. P. Buse and W. R. Weimer, “Learning a metric for code readability,” IEEE Computer Society, 2010.
[19] J. Dorn, “A general software readability model,” 2012.
[20] D. Posnett, A. Hindle, and P. Devanbu, “A simpler model of software readability,” in Proceedings of the 8th Working Conference on Mining Software Repositories.
[21] M. E. Fagan, “Advances in software inspections,” IEEE Transactions in Software Engineering, 1986.
[22] J. Cohen, S. Teleki, and E. Brown, Best Kept Secrets of Peer Code Review. Smart Bear, 2006.
[23] A. Bacchelli and C. Bird, “Expectations, outcomes, and challenges of modern code review,” in Proceedings of the 2013 International Conference on Software Engineering. IEEE Press, Conference Proceedings.
[24] J. Cohen. (2013) Does pair programming obviate the need for code review? [Online]. Available: http://blog.smartbear.com/programming/doespair- programming-obviate-the-need-for-code-review/
[25] V. R. Basili, S. Green, O. Laitenberger, F. Lanubile, F. Shull, S. Sørumg˚ard, and M. V. Zelkowitz, “The empirical investigation of perspective-based reading,” Empirical Software Engineering, 1996.
[26] T. Sedano. (2011) Code readability testing process. [Online]. Available: http://sedano.org/journal/2011/3/30/code-readability-process.html
[27] J. Nielsen, Usability Engineering. Morgan Kaufmann Publishers Inc., 1993.
[28] M. Hansen, R. L. Goldstone, and A. Lumsdaine, “What makes code hard to understand?” 2013.
[29] D. Crookes, “Generating readable software,” Software Engineering Journal, vol. 2, no. 3, pp. 64–70, 1987.
[30] D. E. Knuth, “Computer programming as an art,” Communications of the ACM, vol. 17, no. 12, pp. 667–673, 1974.

[1] “A personal computer for children of all ages,” ACM National Conference,August 1972, history-computer.com/Library/Kay72.pdf.
[2] B. L. Cox, “The object oriented pre-compiler: programming smalltalk 80 methods in c language,” ACM Sigplan Notices, vol. 18, no. 1, pp. 15–22, 1983.
[3] B. Stroustrup, The C++ Programming Language (1st Ed.). Addison- Wesley Longman Publishing Co., Inc., 1985.
[4] S. Keene, Object-Oriented Programming in Common Lisp: A Programmer’s Guide to CLOS. Addison-Wesley, 1988.
[5] T. Reenskaug and J. O. Coplien, The DCI Paradigm: Taking Object Orientation into the Architecture World, 2012, http://fulloo.info/Documents/ CoplienReenskaugASA2012.pdf.
[6] ——, “The dci architecture: A new vision of object-oriented programming,” An article starting a new blog:(14pp) http://www. artima. com/articles/dci vision. html, 2009.
[7] S. Metz, Practical Object-Oriented Design in Ruby: An Agile Primer. Pearson Education, 2012.
[8] R. Conradi and A. I. Wang, Empirical Methods and Studies in Software Engineering: Experiences from Esernet. Secaucus, NJ, USA: Springer- Verlag New York, Inc., 2003.
[9] J. Quante, “Do dynamic object process graphs support program understanding? - a controlled experiment.” in 2008 16th IEEE International Conference on Program Comprehension, June 2008, pp. 73–82.
[10] J.-M. Burkhardt, F. D´etienne, and S. Wiedenbeck, “Mental representations constructed by experts and novices in object-oriented program comprehension,” in Human-Computer Interaction INTERACT’97. Springer, 1997, pp. 339–346.
[11] C. L. Corritore and S. Wiedenbeck, “Mental representations of expert procedural and object-oriented programmers in a software maintenance task,” International Journal of Human-Computer Studies, vol. 50, no. 1, pp. 61–83, 1999.
[12] ——, “An exploratory study of program comprehension strategies of procedural and object-oriented programmers,” International Journal of Human-Computer Studies, vol. 54, no. 1, pp. 1–23, 2001.
[13] M. Abbes, F. Khomh, Y.-G. Gueheneuc, and G. Antoniol, “An empirical study of the impact of two antipatterns, blob and spaghetti code, on program comprehension,” in Software Maintenance and Reengineering (CSMR), 2011 15th European Conference on. IEEE, 2011, pp. 181– 190.
[14] G. Salvaneschi, S. Amann, S. Proksch, and M. Mezini, “An empirical study on program comprehension with reactive programming,” in Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 2014, pp. 564–575.
[15] T. D. LaToza, D. Garlan, J. D. Herbsleb, and B. A. Myers, “Program comprehension as fact finding,” in Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering. ACM, 2007, pp. 361–370.
[16] J. Feigenspan, S. Apel, J. Liebig, and C. Kastner, “Exploring software measures to assess program comprehension,” in 2011 International Symposium on Empirical Software Engineering and Measurement, Sept 2011, pp. 127–136.
[17] S. D. Fleming, E. Kraemer, R. E. K. Stirewalt, S. Xie, and L. K. Dillon, “A study of student strategies for the corrective maintenance of concurrent software,” in Proceedings of the 30th International Conference on Software Engineering, ser. ICSE ’08. New York, NY, USA: ACM, 2008, pp. 759–768. [Online]. Available: http://doi.acm.org/10.1145/1368088.1368195
[18] R. F. Burton and D. J. Miller, “Statistical modelling of multiplechoice and true/false tests: ways of considering, and of reducing, the uncertainties attributable to guessing,” Assessment & Evaluation in Higher Education, vol. 24, no. 4, pp. 399–411, 1999.
[19] H. van Mameren, C. van der Vleuten et al., “The effect of a ‘don’t know’option on test scores: number-right and formula scoring compared,” Medical Education, vol. 33, no. 4, pp. 267–275, 1999.
[20] R. F. Burton, “Quantifying the effects of chance in multiple choice and true/false tests: question selection and guessing of answers,” Assessment & Evaluation in Higher Education, vol. 26, no. 1, pp. 41–50, 2001.
[21] P. J. Denning, “The locality principle,” Communications of the ACM, vol. 48, no. 7, pp. 19–24, 2005.
[22] R. Zafarani, M. A. Abbasi, and H. Liu, Social media mining: an introduction. Cambridge University Press, 2014.
[23] R. Schumacker and S. Tomek, Understanding statistics using R. Springer Science & Business Media, 2013.
[24] B. Boehm, H. D. Rombach, and M. V. Zelkowitz, Foundations of empirical software engineering: the legacy of Victor R. Basili. Springer Science & Business Media, 2005.
[25] J. Siegmund, “Framework for measuring program comprehension,” Ph.D. dissertation, Magdeburg, Universit¨at, Diss., 2012, 2012.
[26] D. I. Sjøberg, J. E. Hannay, O. Hansen, V. B. Kampenes, A. Karahasanovic, N.-K. Liborg, and A. C. Rekdal, “A survey of controlled experiments in software engineering,” Software Engineering, IEEE Transactions on, vol. 31, no. 9, pp. 733–753, 2005.
[27] J. O. Coplien and G. Bjørnvig, Lean architecture: for agile software development. John Wiley & Sons, 2011.
[28] A. Lee and N. Pennington, “The effects of paradigm on cognitive activities in design,” International Journal of Human-Computer Studies, vol. 40, no. 4, pp. 577–601, 1994.
[29] S. Wiedenbeck, V. Ramalingam, S. Sarasamma, and C. Corritore, “A comparison of the comprehension of object-oriented and procedural programs by novice programmers,” Interacting with Computers, vol. 11, no. 3, pp. 255–282, 1999.
[30] R. J. Walker, E. L. Baniassad, and G. C. Murphy, “An initial assessment of aspect-oriented programming,” in Software Engineering, 1999. Proceedings of the 1999 International Conference on. IEEE, 1999, pp. 120–130.
[31] V. Ramalingam and S. Wiedenbeck, “An empirical study of novice program comprehension in the imperative and object-oriented styles,” in Papers presented at the seventh workshop on Empirical studies of programmers. ACM, 1997, pp. 124–139.
[32] N. Pennington, “Stimulus structures and mental representations in expert comprehension of computer programs,” Cognitive psychology, vol. 19, no. 3, pp. 295–341, 1987.
[33] A. Von Mayrhauser and A. M. Vans, “Program comprehension during software maintenance and evolution,” Computer, vol. 28, no. 8, pp. 44– 55, 1995.
[34] J.-M. Burkhardt, F. D´etienne, and S. Wiedenbeck, “Object-oriented program comprehension: Effect of expertise, task and phase,” Empirical Software Engineering, vol. 7, no. 2, pp. 115–156, 2002.
[35] R. C. Martin, Clean code: a handbook of agile software craftsmanship. Pearson Education, 2009.
[36] R. S. Rist, “Program structure and design,” Cognitive Science, vol. 19, no. 4, pp. 507–562, 1995.
[37] J. O. Coplien, “Objects of the people, by the people, and for the people,” in Proceedings of the 11th annual international conference on Aspectoriented Software Development Companion. ACM, 2012, pp. 3–4.
[38] A. Dunsmore, “Comprehension and visualisation of object-oriented code for inspections,” Empirical Foundations of Computer Science (EFoCS), University of Strathclyde Livingstone Tower, Glasgow G1 1XH, UK, 1998.
[39] N. Wilde and R. Huitt, “Maintenance support for object oriented programs,” in Software Maintenance, 1991., Proceedings. Conference on. IEEE, 1991, pp. 162–170. 285

[1] K. Aggarwal, Y. Singh, and J.K. Chhabra, “An Integrated Measure of Software Maintainability,” Proc. Reliability and Maintainability Symp., pp. 235-241, Sept. 2002.
[2] S. Ambler, “Java Coding Standards,” Software Development, vol. 5, no. 8, pp. 67-71, 1997.
[3] B.B. Bederson, B. Shneiderman, and M. Wattenberg, “Ordered and Quantum Treemaps: Making Effective Use of 2D Space to Display Hierarchies,” ACM Trans. Graphics, vol. 21, no. 4, pp. 833-854, 2002.
[4] B. Boehm and V.R. Basili, “Software Defect Reduction Top 10 List,” Computer, vol. 34, no. 1, pp. 135-137, Jan. 2001.
[5] R.P.L. Buse and W.R. Weimer, “A Metric for Software Readability,” Proc. Int’l Symp. Software Testing and Analysis, pp. 121-130, 2008.
[6] L.W. Cannon, R.A. Elliott, L.W. Kirchhoff, J.H. Miller, J.M. Milner, R.W. Mitze, E.P. Schan, N.O. Whittington, H. Spencer, D. Keppel, and M. Brader, Recommended C Style and Coding Standards: Revision 6.0, Specialized Systems Consultants, June 1990.
[7] T.Y. Chen, F.-C. Kuo, and R. Merkel, “On the Statistical Properties of the F-Measure,” Proc. Int’l Conf. Quality Software, pp. 146-153, 2004.
[8] L.E. Deimel, Jr., “The Uses of Program Reading,” ACM SIGCSE Bull., vol. 17, no. 2, pp. 5-14, 1985.
[9] E.W. Dijkstra, A Discipline of Programming. Prentice Hall PTR, 1976.
[10] J.L. Elshoff and M. Marcotty, “Improving Computer Program Readability to Aid Modification,” Comm. ACM, vol. 25, no. 8, pp. 512-521, 1982.
[11] R.F. Flesch, “A New Readability Yardstick,” J. Applied Psychology, vol. 32, pp. 221-233, 1948.
[12] F.P. Brooks, Jr., “No Silver Bullet: Essence and Accidents of Software Engineering,” Computer, vol. 20, no. 4, pp. 10-19, Apr. 1987.
[13] L.L. Giventer, Statistical Analysis in Public Administration. Jones and Bartlett, 2007.
[14] J. Gosling, B. Joy, and G.L. Steele, The Java Language Specification. Addison-Wesley, 1996.
[15] R. Gunning, The Technique of Clear Writing. McGraw-Hill, 1952.
[16] N.J. Haneef, “Software Documentation and Readability: A Proposed Process Improvement,” ACM SIGSOFT Software Eng. Notes, vol. 23, no. 3, pp. 75-77, 1998.
[17] A.E. Hatzimanikatis, C.T. Tsalidis, and D. Christodoulakis, “Measuring the Readability and Maintainability of Hyperdocuments,” J. Software Maintenance, vol. 7, no. 2, pp. 77-90, 1995.
[18] G. Holmes, A. Donkin, and I. Witten, “WEKA: A Machine Learning Workbench,” Proc. Australia and New Zealand Conf. Intelligent Information Systems, 1994.
[19] D. Hovemeyer and W. Pugh, “Finding Bugs Is Easy,” ACM SIGPLAN Notices, vol. 39, no. 12, pp. 92-106, 2004.
[20] jUnit.org, “jUnit 4.0 Now Available,” http://sourceforge.net/ forum/forum.php?forum_id=541181, Feb. 2006.
[21] J.P. Kinciad and E.A. Smith, “Derivation and Validation of the Automated Readability Index for Use with Technical Materials,” Human Factors, vol. 12, pp. 457-464, 1970.
[22] J.C. Knight and E.A. Myers, “Phased Inspections and Their Implementation,” ACM SIGSOFT Software Eng. Notes, vol. 16, no. 3, pp. 29-35, 1991.
[23] R. Kohavi, “A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection,” Proc. Int’l Joint Conf. Artificial Intelligence, vol. 14, no. 2, pp. 1137-1145, 1995.
[24] C. Le Goues and W. Weimer, “Specification Mining with Few False Positives,” Proc. 15th Int’l Conf. Tools and Algorithms for the Construction and Analysis of Systems, 2009.
[25] R. Likert, “A Technique for the Measurement of Attitudes,” Archives of Psychology, vol. 140, pp. 44-53, 1932.
[26] S. MacHaffie, R. McLeod, B. Roberts, P. Todd, and L. Anderson, “A Readability Metric for Computer-Generated Mathematics,” technical report, Saltire Software, http://www.saltire.com/ equation.html, 2007.
[27] T.J. McCabe, “A Complexity Measure,” IEEE Trans. Software Eng., vol. 2, no. 4, pp. 308-320, Dec. 1976.
[28] G.H. McLaughlin, “Smog Grading—A New Readability,” J. Reading, vol. 12, no. 8, pp. 639-646, May 1969.
[29] R.J. Miara, J.A. Musselman, J.A. Navarro, and B. Shneiderman, “Program Indentation and Comprehensibility,” Comm. ACM, vol. 26, no. 11, pp. 861-867, 1983.
[30] T. Mitchell, Machine Learning. McGraw Hill, 1997.
[31] N. Nagappan and T. Ball, “Use of Relative Code Churn Measures to Predict System Defect Density,” Proc. 27th Int’l Conf. Software Eng., pp. 284-292, 2005.
[32] C.V. Ramamoorthy and W.-T. Tsai, “Advances in Software Engineering,” Computer, vol. 29, no. 10, pp. 47-58, Oct. 1996.
[33] D.R. Raymond, “Reading Source Code,” Proc. Conf. Center for Advanced Studies on Collaborative Research, pp. 3-16, 1991.
[34] P.A. Relf, “Tool Assisted Identifier Naming for Improved Software Readability: An Empirical Study,” Proc. Int’l Symp. Empirical Software Eng., Nov. 2005.
[35] S. Rugaber, “The Use of Domain Knowledge in Program Understanding,” Ann. Software Eng., vol. 9, nos. 1-4, pp. 143-192, 2000.
[36] C. Simonyi, “Hungarian Notation,” MSDN Library, Nov. 1999.
[37] S.E. Stemler, “A Comparison of Consensus, Consistency, and Measurement Approaches to Estimating Interrater Reliability,” Practical Assessment, Research and Evaluation, vol. 9, no. 4, 2004.
[38] H. Sutter and A. Alexandrescu, C++ Coding Standards: 101 Rules, Guidelines, and Best Practices. Addison-Wesley Professional, 2004.
[39] T. Tenny, “Program Readability: Procedures versus Comments,” IEEE Trans. Software Eng., vol. 14, no. 9, pp. 1271-1279, Sept. 1988.
[40] A. Watters, G. van Rossum, and J.C. Ahlstrom, Internet Programming with Python. MIS Press/Henry Holt, 1996.
[41] E.J. Weyuker, “Evaluating Software Complexity Measures,” IEEE Trans. Software Eng., vol. 14, no. 9, pp. 1357-1365, 1988.

[1] C. Elliott, “Functional implementations of continuous modeled animation,” in Proc. Int. Symp. Principles Declarative Program., 1998, pp. 284–299.
[2] C. Elliott and P. Hudak, “Functional reactive animation,” in Proc. Int. Conf. Functional Program., 1997, pp. 263–273.
[3] G. H. Cooper and S. Krishnamurthi, “Embedding dynamic dataflow in a call-by-value language,” in Proc. Eur. Conf. Program. Languages Syst., 2006, pp. 294–308.
[4] L. A. Meyerovich, et al., “Flapjax: A programming language for Ajax applications,” in Proc. Conf. Object-Oriented Program. Syst. Languages Appl., 2009, pp. 1–20.
[5] G. Salvaneschi, G. Hintz, and M. Mezini, “REScala: Bridging between object-oriented and functional style in reactive applications,” in Proc. Int. Conf. Modularity, 2014, pp. 25–36.
[6] I. Maier and M. Odersky, “Higher-order reactive programming with incremental lists,” in Proc. Eur. Conf. Object-Oriented Program., 2013, pp. 707–731.
[7] J. Liberty and P. Betts, Programming Reactive Extensions and LINQ. New York, NY, USA: Apress, 2011.
[8] E. Gamma, R. Helm, R. Johnson, and J. Vlissides, Design Patterns Elements of Reusable Object-Oriented Software. Boston, MA, USA: Addison-Wesley, 2000.
[9] G. Salvaneschi, P. Eugster, and M. Mezini, “Programming with implicit flows.” IEEE Softw., vol. 31, no. 5, pp. 52–59, Sep./Oct. 2014.
[10] I. Maier and M. Odersky, “Deprecating the Observer Pattern with Scala.React,” EPFL, 2012. [Online]. Available: http://infoscience. epfl.ch/record/176887
[11] E. Bainomugisha, A. L. Carreton, T. v. Cutsem, S. Mostinckx, and W. d. Meuter, “A survey on reactive programming,” ACM Comput. Surveys, vol. 45, 2013, Art. no. 52.
[12] G. Salvaneschi, S.Amann, S. Proksch, andM.Mezini, “An empirical study on program comprehension with reactive programming,” in Proc. Int. Symp. Foundations Softw. Eng., 2014, pp. 564–575.
[13] Baconjs. [Online]. Available: https://baconjs.github.io.
[14] H. Abelson and G. J. Sussman, Structure and Interpretation of Computer Programs, 2nd ed. Cambridge, MA, USA: MIT Press, 1996.
[15] J. W. Creswell, Qualitative Inquiry and Research Design: Choosing Among Five Approaches. Thousand Oaks, CA, USA: Sage, 2012.
[16] F. Olivero, M. Lanza, M. D’ambros, and R. Robbes, “Tracking human-centric controlled experiments with biscuit,” in Proc. Workshop Eval. Usability Program. Languages Tools, 2012, pp. 1–6.
[17] S. Hanenberg, “An experiment about static and dynamic type systems: Doubts about the positive impact of static type systems on development time,” in Proc. Int. Conf. Object Oriented Program. Syst. Languages Appl., 2010.
[18] WebLab Site. [Online]. Available: http://department.st.ewi. tudelft.nl/weblab/
[19] S. D. Fleming, E. Kraemer, R. E. K. Stirewalt, S. Xie, and L. K. Dillon, “A study of student strategies for the corrective maintenance of concurrent software,” in Proc. Int. Conf. Softw. Eng., 2008, pp. 759–768.
[20] T. D. LaToza, D. Garlan, J. D. Herbsleb, and B. A. Myers, “Program comprehension as fact finding,” in Proc. Joint Meet. Eur. Softw. Eng. Conf. Symp. Foundations Softw. Eng., 2007, pp. 361–370.
[21] T. Roehm, R. Tiarks, R. Koschke, and W. Maalej, “How do professional developers comprehend software?” in Proc. Int. Conf. Softw. Eng., 2012, pp. 255–265.
[22] J. Quante, “Do dynamic object process graphs support program understanding? - A controlled experiment,” in Proc. Int. Conf. Program Comprehension, 2008, pp. 73–82.
[23] N. Juristo and A. M. Moreno, Basics of Software Engineering Experimentation. Berlin, Germany: Springer-Verlag, 2010.
[24] S. Hanenberg, “An experiment about static and dynamic type systems: Doubts about the positive impact of static type systems on development time,” in Proc. Int. Conf. Object Oriented Program. Syst. Languages Appl., 2010, pp. 22–35.
[25] C. Mayer, S. Hanenberg, R. Robbes, E. Tanter, and A. Stefik, “An empirical study of the influence of static type systems on the usability of undocumented software,” in Proc. Int. Conf. Object Oriented Program. Syst. Languages Appl., 2012, pp. 683–702.
[26] S. Kleinschmager and S. Hanenberg, “How to rate programming skills in programming experiments?: A preliminary, exploratory, study based on university marks, pretests, and self-estimation,” in Proc. Workshop Eval. Usability Program. Languages Tools, 2011, pp. 15–24.
[27] IBM SPSS website. [Online]. Available: http://www.ibm.com/ analytics/us/en/technology/spss/
[28] F. Detienne, Software Design—Cognitive Aspects, F. Bott, Ed. Berlin, Germany: Springer-Verlag, 2002.
[29] N. Pennington, “Stimulus structures and mental representations in expert comprehension of computer programs,” Cognitive Psychology, vol. 19, pp. 295–341, 1987.
[30] T. D. LaToza and B. A. Myers, “Developers ask reachability questions,” in Proc. Int. Conf. Softw. Eng., 2010, pp. 185–194.
[31] Rx operators. [Online]. Available: http://reactivex.io/ documentation/operators.html
[32] G. Salvaneschi and M. Mezini, “Debugging for reactive programming,” in Proc. Int. Conf. Softw. Eng., 2016, pp. 796–807.
[33] T. D. LaToza, G. Venolia, and R. DeLine, “Maintaining mental models: A study of developer work habits,” in Proc. Int. Conf. Softw. Eng., 2006, pp. 492–501.
[34] R. Turner, M. Falcone, B. Sharif, and A. Lazar, “An eye-tracking study assessing the comprehension of C++ and Python source code,” in Proc. Symp. Eye Tracking Res. Appl., 2014, pp. 231–234.
[35] Y.-T. Lin, C.-C. Wu, Y.-C. Lin, T.-Y. Hou, F.-Y. Yang, and C.-H. Chang, “Cognitive processes during program debugging: An eyemovement approach,” IEEE Trans. Edu., vol. 59, no. 3, pp. 175– 186, Aug. 2016.
[36] T. Busjahn, et al., “Eye tracking in computing education,” in Proc. Conf. Int. Comput. Edu. Res., 2014, pp. 3–10.
[37] A. Jbara and D. Feitelson, “How programmers read regular code: A controlled experiment using eye tracking,” in Proc. Int. Conf. Program Comprehension, 2015, pp. 244–254.
[38] K. Kevic, et al., “Tracing software developers’ eyes and interactions for change tasks,” in Proc. Joint Meet. Eur. Softw. Eng. Conf. Symp. Foundations Softw. Eng., 2015, pp. 836–847.
[39] E. Soloway and K. Ehrlich, “Empirical studies of programming knowledge,” in Software Reusability. New York, NY, USA: ACM, 1989.
[40] S. Letovsky, “Cognitive processes in program comprehension,” presented at 1st Workshop Empirical Stud. Programmers Empirical Stud. Programmers, Washington, D.C., USA, 1986.
[41] A. von Mayrhauser and A. M. Vans, “Comprehension processes during large scale maintenance,” in Proc. Int. Conf. Softw. Eng., 1994, pp. 39–48.
[42] A. J. Ko, H. Aung, and B. A. Myers, “Eliciting design requirements for maintenance-oriented IDEs: A detailed study of corrective and perfective maintenance Tasks,” in Proc. Int. Conf. Softw. Eng., 2005, pp. 126–135.
[43] Demo for the internals of the ELM debugger. [Online]. Available: http://www.youtube.com/watch?v=FSdXiBLpErU
[44] Labview interacting debugger. [Online]. Available: http://www. ni.com/getting-started/labview-basics/debug
[45] Dependency graph visualization in the unreal engine 4, tools demonstration GDC 2014, minutes 6:46 and 8:45. [Online]. Available: http://www.youtube.com/watch?v=9hwhH7upYFE#t=384
[46] M. Ali, “An introduction tomicrosoft SQL server streamInsight,” in Proc. Int. Conf. Exhib. Comput. Geospatial Res. Appl., 2010, Art. no. 66.
[47] B. Gedik, et al., “Tools and strategies for debugging distributed stream processing applications,” Softw.: Practice Experience, vol. 39, pp. 1347–1376, 2009.
[48] S. Endrikat and S. Hanenberg, “Is aspect-oriented programming a rewarding investment into future code changes? A socio-technical study on development and maintenance time,” in Proc. Int. Conf. Program Comprehension, 2011, pp. 51–60.
[49] M. Hoppe and S. Hanenberg, “Do developers benefit from generic types?: An empirical comparison of generic and raw types in Java,” in Proc. Int. Conf. Object Oriented Program. Syst. Languages and Appl., 2013, pp. 457–474.
[50] M. Di Penta , R. E. K. Stirewalt, and E. Kraemer, “Designing your next empirical study on program comprehension,” in Proc. Int. Conf. Program Comprehension, 2007, pp. 281–285.
[51] I. Salman, A. Misirli, and N. Juristo, “Are students representatives of professionals in software engineering experiments?” in Proc. Int. Conf. Softw. Eng., 2015, pp. 666–676.
[52] P. Hudak, A. Courtney, H. Nilsson, and J. Peterson, “Arrows, robots, and functional reactive programming,” in Proc. 4th Int. Summer School Adv. Functional Program., 2003, pp. 159–187.
[53] R. Newton, G. Morrisett, and M. Welsh, “The regiment macroprogramming system,” in Proc. Int. Conf. Inform. Process. Sensor Netw., 2007, pp. 489–498.
[54] B. A. Myers, et al., “The amulet environment: New models for effective user interface software development,” IEEE Trans. Softw. Eng., vol. 23, no. 6, pp. 347–365, Jun. 1997.
[55] B. N. Freeman-Benson, “Kaleidoscope: Mixing objects, constraints, and imperative programming,” in Proc. Eur. Conf. Object- Oriented Program. Object-Oriented Program. Syst. Languages Appl., 1990, pp. 77–88.
[56] T. Felgentreff, et al., “Babelsberg/JS,” in Proc. Eur. Conf. Object- Oriented Program., 2014, pp. 411–436.
[57] T. Felgentreff, T. Millstein, A. Borning, and R. Hirschfeld, “Checks and balances: Constraint solving without surprises in object-constraint programming languages,” in Proc. Int. Conf. Object-Oriented Program. Syst., Languages Appl., 2015, pp. 767–782.
[58] G. Salvaneschi, J. Drechsler, and M. Mezini, “Towards distributed reactive programming,” in Coordination Models and Languages. Berlin, Germany: Springer-Verlag, 2013.
[59] A. Margara and G. Salvaneschi, “We have a dream: Distributed reactive programming with consistency guarantees,” in Proc. Int. Conf. Distrib. Event-Based Syst., 2014, pp. 142–153.
[60] G. Salvaneschi and M. Mezini, “Towards reactive programming for object-oriented applications, ” in Transactions on Aspect-Oriented Software Development. Berlin, Germany: Springer-Verlag, 2014.
[61] N. R. Krishnaswami, N. Benton, and J. Hoffmann, “Higher-order functional reactive programming in bounded space,” in Proc. Symp. Principles Program. Languages, 2012, pp. 45–58.
[62] M.-A. Storey, “Theories, tools and research methods in program comprehension: Past, present and future,” Softw. Quality Control, vol. 14, pp. 187–208, 2006.
[63] V. Ramalingam and S. Wiedenbeck, “An empirical study of novice program comprehension in the imperative and objectoriented styles,” in Proc. Workshop Empirical Stud. Programmers, 1997, pp. 124–139.
[64] C. L.Corritore and S.Wiedenbeck,“Mental representations of expert procedural and object-oriented programmers in a software maintenance task,” Int. J. Human-Comput. Stud., vol. 50, pp. 61–83, 1999.
[65] R. Wettel, M. Lanza, and R. Robbes, “Software systems as cities: A controlled experiment,” in Proc. Int. Conf. Softw. Eng., 2011, pp. 551–560.
[66] B. Cornelissen, A. Zaidman, and A. van Deursen, “A controlled experiment for program comprehension through trace visualization,” IEEE Trans. Softw. Eng., vol. 37, no. 3, pp. 341–355, May/ Jun. 2011.
[67] V. Pankratius, F. Schmidt, and G. Garreton, “Combining functional and imperative programming for multicore software: An empirical study evaluating scala and Java,” in Proc. Int. Conf. Softw. Eng., 2012, pp. 123–133.
[68] L. Prechelt, “An empirical comparison of seven programming languages,” IEEE Comput., vol. 33, no. 10, pp. 23–29, Oct. 2000.
[69] G. Salvaneschi, “What do we really know about data flow languages?” in Proc. Int. Workshop Eval. Usability Program. Languages Tools, 2016, pp. 30–31.
[70] J. Stylos and S. Clarke, “Usability implications of requiring parameters in objects’ constructors,” in Proc. Int. Conf. Softw. Eng., 2007, pp. 529–539.
[71] J. Stylos and B. A. Myers, “The implications of method placement on API learnability,” in Proc. Int. Symp. Foundations Softw. Eng., 2008, pp. 105–112.
[72] B. Ellis, J. Stylos, and B. Myers, “The factory pattern in API design: A usability evaluation,” in Proc. Int. Conf. Softw. Eng., 2007, pp. 302–312.

[1] 1999. IEC 9899: 1999: Programming languages C. International Organization for Standardization (1999), 243ś245.
[2] Eran Avidan and Dror G Feitelson. 2015. From obfuscation to comprehension. In Program Comprehension (ICPC), 2015 IEEE 23rd International Conference on. IEEE, 178ś181.
[3] Alberto Bacchelli and Christian Bird. 2013. Expectations, outcomes, and challenges of modern code review. In Proceedings of the 2013 International Conference on Software Engineering. IEEE Press, 712ś721.
[4] Mike Bland. 2014. Finding more than one worm in the apple. Commun. ACM 57, 7 (2014), 58ś64.
[5] Maarten AS Boksem, Theo F Meijman, and Monicque M Lorist. 2005. Efects of mental fatigue on attention: an ERP study. Cognitive Brain Research 25, 1 (2005), 107ś116.
[6] Dennis Burke. 1995. All circuits are busy now: The 1990 AT&T long distance network collapse. California Polytechnic State University (1995).
[7] Raymond PL Buse andWestley RWeimer. 2008. A metric for software readability. In Proceedings of the 2008 international symposium on Software testing and analysis. ACM, 121ś130.
[8] LW Cannon, RA Elliott, LW Kirchhof, JH Miller, JM Milner, RW Mitze, EP Schan, NO Whittington, Henry Spencer, David Keppel, and others. 1991. Recommended C style and coding standards. Pocket reference guide. Specialized Systems Consultants.
[9] LW Cannon, RA Elliott, LW Kirchhof, JH Miller, JM Milner, RW Mitze, EP Schan, NO Whittington, Henry Spencer, David Keppel, and others. 1991. Recommended C style and coding standards. Pocket reference guide. Specialized Systems Consultants.
[10] Jacob Cohen. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd edn. Hillsdale, New Jersey. (1988).
[11] Christian Collberg, Clark Thomborson, and Douglas Low. 1997. A taxonomy of obfuscating transformations. Technical Report. Department of Computer Science, The University of Auckland, New Zealand.
[12] Thomas A Corbi. 1989. Program understanding: Challenge for the 1990s. IBM Systems Journal 28, 2 (1989), 294ś306.
[13] EdsgerWDijkstra. 1968. Letters to the editor: go to statement considered harmful. Commun. ACM 11, 3 (1968), 147ś148.
[14] José Javier Dolado, Mark Harman, Mari Carmen Otero, and Lin Hu. 2003. An empirical investigation of the inluence of a type of side efects on program comprehension. Software Engineering, IEEE Transactions on 29, 7 (2003), 665ś670.
[15] Jerry Doland and Jon Valett. 1994. C Style Guide. (1994). NASA.
[16] Valerie L Durkalski, Yuko Y Palesch, Stuart R Lipsitz, and Philip F Rust. 2003. Analysis of clustered matched-pair data. Statistics in Medicine 22, 15 (2003), 2417ś2428.
[17] James L Elshof and Michael Marcotty. 1982. Improving computer program readability to aid modiication. Commun. ACM 25, 8 (1982), 512ś521.
[18] Paul M Fitts. 1954. The information capacity of the human motor system in controlling the amplitude of movement. Journal of experimental psychology 47, 6 (1954), 381.
[19] Martin Fowler. 2009. Refactoring: improving the design of existing code. Pearson Education India.
[20] Dan Gopstein. 2016. clust.bin.pair: Statistical Methods for Analyzing Clustered Matched Pair Data. https://CRAN.R-project.org/package=clust.bin.pair R package version 0.0.6.
[21] John Graham-Cumming. 2017. Incident report on memory leak caused by Cloudlare parser bug. (2017). https://blog.cloudlare.com/ incident-report-on-memory-leak-caused-by-cloudlare-parser-bug/ [Online; accessed 2017-02-23].
[22] Maurice Howard Halstead. 1977. Elements of software science. Vol. 7. Elsevier New York.
[23] J-M Jazequel and Bertrand Meyer. 1997. Design by contract: The lessons of Ariane. Computer 30, 1 (1997), 129ś130.
[24] Stephen C Johnson. 1977. Lint, a C program checker.
[25] Derek M. Jones. 2006. Developer beliefs about binary operator precedence. (2006).
[26] Brian W Kernighan and Rob Pike. 1999. The practice of programming. Addison- Wesley Professional.
[27] Bennet P Lientz, E. Burton Swanson, and Gail E Tompkins. 1978. Characteristics of application software maintenance. Commun. ACM 21, 6 (1978), 466ś471.
[28] Jacques-Louis Lions and others. 1996. Ariane 5 light 501 failure. (1996).
[29] Lindsay Marshall and James Webber. Gotos considered harmful and other programmers taboos.
[30] Thomas J McCabe. 1976. A complexity measure. Software Engineering, IEEE Transactions on 4 (1976), 308ś320.
[31] Quinn McNemar. 1947. Note on the sampling error of the diference between correlated proportions or percentages. Psychometrika 12, 2 (1947), 153ś157.
[32] James H Neely. 1991. Semantic priming efects in visual word recognition: A selective review of current indings and theories. Basic processes in reading: Visual word recognition 11 (1991), 264ś336.
[33] Landon Curt Noll, Simon Cooper, Peter Seebach, and A Broukhis Leonid. 1984. Rules. (Mar 1984). http://www.ioccc.org/1984/rules
[34] Rob Pike. 1989. Notes on Programming in C. URL http://www. lysator. liu. se/c/pikestyle. html 2 (1989), 4.
[35] Jarrett Rosenberg. 1997. Some misconceptions about lines of code. In Software Metrics Symposium, 1997. Proceedings, Fourth International. IEEE, 137ś142.
[36] Jingqiu Shao and Yingxu Wang. 2003. A new measure of software complexity based on cognitive weights. Electrical and Computer Engineering, Canadian Journal of 28, 2 (2003), 69ś74.
[37] Forrest J Shull, Jefrey C Carver, Sira Vegas, and Natalia Juristo. 2008. The role of replications in empirical software engineering. Empirical Software Engineering 13, 2 (2008), 211ś218.
[38] Janet Siegmund, Christian Kästner, Sven Apel, Chris Parnin, Anja Bethmann, Thomas Leich, Gunter Saake, and André Brechmann. 2014. Understanding understanding source code with functional magnetic resonance imaging. In Proceedings of the 36th International Conference on Software Engineering. ACM, 378ś389.
[39] Richard Stallman and others. 1992. GNU coding standards. (1992).
[40] Yahya Tashtoush, Zeinab Odat, Izzat Alsmadi, and Maryan Yatim. 2013. Impact of programming features on code readability. (2013).
[41] Linus Torvalds. 2001. Linux kernel coding style. https://www.kernel.org/doc/Documentation/CodingStyle (2001).
[42] William Wulf and Mary Shaw. 1973. Global variable considered harmful. ACM Sigplan notices 8, 2 (1973), 28ś34.
[43] Sheng Yu and Shijie Zhou. 2010. A survey on metric of software complexity. In Information Management and Engineering (ICIME), 2010 The 2nd IEEE International Conference on. IEEE, 352ś356.

[1] V. Arunachalam and W. Sasso, “Cognitive processes in program comprehension: An empirical analysis in the context of software reengineering”. J. Syst. & Softw. 34(3), pp. 177–189, Sep 1996, DOI:10.1016/0164-1212(95)00074-7.
[2] P. Bame, “McCabe-style function complexity ”. URL http://parisc-linux.org/ bame/pmccabe/overview.html.
[3] V. Basili and R. Selby, “Comparing the effectiveness of software testing strategies ”. IEEE Trans. Softw. Eng. SE-13(12), pp. 1278–1296, 1987, DOI:10.1109/TSE.1987.232881.
[4] N. Bettenburg, M. Nagappan, and A. E. Hassan, “Think locally, act globally: Improving defect and effort prediction models ”. In 9th Intl. Workshop Mining Softw. Repositories, pp. 60–69, Jun 2012, DOI:10.1109/MSR.2012.6224300.
[5] D. Beyer and A. Fararooy, “A simple and effective measure for complex low-level dependencies ”. In 18th IEEE Intl. Conf. Program Comprehension, pp. 80–83, 2010, DOI:10.1109/ICPC.2010.49.
[6] B. Chaudhary and H. Sahasrabuddhe, “Two dimensions of program comprehension”. Intl. J. Man-Machine Studies 18(5), pp. 505–511, 1983.
[7] B. Cornelissen, A. Zaidman, and A. van Deursen, “A controlled experiment for program comprehension through trace visualization”. IEEE Trans. Softw. Eng. 37(3), pp. 341 –355, May-June 2011, DOI:10.1109/TSE.2010.47.
[8] B. Curtis, J. Sappidi, and J. Subramanyam, “An evaluation of the internal quality of business applications: Does size matter? ” In 33rd Intl. Conf. Softw. Eng., pp. 711–715, May 2011, DOI:10.1145/1985793.1985893.
[9] G. Denaro and M. Pezzè, “An empirical evaluation of fault-proneness models ”. In 24th Intl. Conf. Softw. Eng., pp. 241–251, May 2002, DOI:10.1145/581339.581371.
[10] J. Elshoff, “An analysis of some commercial PL/I programs ”. IEEE Trans. Softw. Eng. SE-2(2), pp. 113–120, 1976, DOI:10.1109/TSE.1976.233538.
[11] J. Feigenspan, S. Apel, J. Liebig, and C. Kastner, “Exploring software measures to assess program comprehension”. In Empirical Software Engineering and Measurement (ESEM), 2011 International Symposium on, pp. 127–136, Sept 2011, DOI:10.1109/ESEM.2011.21.
[12] N. E. Fenton and S. L. Pfleeger, Software Metrics: A Rigorous and Practical Approach. Course Technology, 2nd ed., 1998.
[13] M. Fisher, A. Cox, and L. Zhao, “Using sex differences to link spatial cognition and program comprehension”. In 22nd Intl. Conf. Softw. Maintenance, pp. 289–298, 2006, DOI:10.1109/ICSM.2006.72.
[14] M. Halstead, Elements of Software Science. Elsevier Science Inc., 1977.
[15] J. Harder and R. Tiarks, “A controlled experiment on software clones ”. In 20th IEEE Intl. Conf. Program Comprehension, pp. 219–228, 2012, DOI:10.1109/ICPC.2012.6240491.
[16] P. Jablonski and D. Hou, “Aiding software maintenance with copy-and-paste clone-awareness ”. In Program Comprehension (ICPC), 2010 IEEE 18th International Conference on, pp. 170–179, June 2010, DOI:10.1109/ICPC.2010.22.
[17] A. Jbara and D. G. Feitelson, “Quantification of code regularity using preprocessing and compression”. manuscript, Jan 2014.
[18] A. Jbara, A. Matan, and D. G. Feitelson, “High-MCC functions in the Linux kernel ”. Empirical Softw. Eng. 2013, DOI:10.1007/s10664-013-9275-7. Accepted for publication.
[19] N. Juristo, S. Vegas, M. Solari, S. Abrahao, and I. Ramos, “Comparing the effectiveness of equivalence partitioning, branch testing and code reading by stepwise abstraction applied by subjects ”. In 5th IEEE Intl. Conf. Software Testing, Verification and Validation, pp. 330–339, 2012, DOI:10.1109/ICST.2012.113.
[20] C. J. Kasper and M. W. Godfrey, ““Cloning considered harmful” considered harmful: Patterns of cloning in software ”. Empirical Softw. Eng. 13(6), pp. 645–692, Dec 2008, DOI:10.1007/s10664-008-9076-6.
[21] B. Katzmarski and R. Koschke, “Program complexity metrics and programmer opinions ”. In 20th IEEE Intl. Conf. Program Comprehension, Jun 2012.
[22] J. L. Krein, L. Pratt, A. Swenson, A. MacLean, C. D. Knutson, and D. Eggett, “Design patterns in software maintenance: An experiment replication at brigham young university ”. In 2nd Intl. Workshop Replication in Empirical Software Engineering Research, pp. 25–34, 2011, DOI:10.1109/RESER.2011.10.
[23] Z. Li, S. Lu, S. Myagmar, and Y. Zhou, “CP-Miner: A tool for finding copy-paste and related bugs in operating system code ”. In 6th Symp. Operating Systems Design & Implementation, pp. 289–302, Dec 2004.
[24] H. Lipson, “Principles of modularity, regularity, and hierarchy for scalable systems ”. Journal of Biological Physics and Chemistry 7(4), pp. 125–128, 2007.
[25] A. Lozano, A. Kellens, K. Mens, and G. Arevalo, “Mining source code for structural regularities ”. In 17th Working Conf. Reverse Engineering, pp. 22–31, Washington, DC, USA, 2010, DOI:10.1109/WCRE.2010.12.
[26] J. Mayrand, C. Leblanc, and E. M. Merlo, “Experiment on the automatic detection of function clones in a software system using metrics ”. In Intl. Conf. Softw. Maintenance, pp. 244–253, Nov 1996, DOI:10.1109/ICSM.1996.565012.
[27] T. McCabe, “A complexity measure ”. IEEE Trans. Softw. Eng. 2(4), pp. 308–320, Dec 1976, DOI:10.1109/TSE.1976.233837.
[28] T. Menzies, A. Butcher, D. Cok, A. Marcus, L. Layman, F. Shull, B. Turhan, and T. Zimmermann, “Local versus global lessons for defect prediction and effort estimation”. IEEE Trans. Softw. Eng. 39(6), pp. 822–834, Jun 2013, DOI:10.1109/TSE.2012.83.
[29] T. Menzies, J. Greenwald, and A. Frank, “Data mining code attributes to learn defect predictors ”. IEEE Trans. Softw. Eng. 33(1), pp. 2–13, Jan 2007, DOI:10.1109/TSE.2007.256941.
[30] MSDN Visual Studio Team System 2008 Development Developer Center, “Avoid excessive complexity ”. URL msdn.microsoft.com/en-us/library/ms182212.aspx, undated. (Visited 23 Dec 2009).
[31] N. Nagappan and T. Ball, “Static analysis tools as early indicators of pre-release defect density ”. In 27th Intl. Conf. Softw. Eng., pp. 580–586, May 2005, DOI:10.1145/1062455.1062558.
[32] N. Nagappan, T. Ball, and A. Zeller, “Mining metrics to predict component failures ”. In 28th Intl. Conf. Softw. Eng., pp. 452–461, May 2006, DOI:10.1145/1134285.1134349.
[33] B. A. Nejmeh, “Npath: a measure of execution path complexity and its applications ”. Comm. ACM 31(2), pp. 188–200, Feb 1988.
[34] N. Ohlsson and H. Alberg, “Predicting fault-prone software modules in telephone switches ”. IEEE Trans. Softw. Eng. 22(12), pp. 886–894, Dec 1996, DOI:10.1109/32.553637.
[35] P. Oman and J. Hagemeister, “Construction and testing of polynomials predicting software maintainability ”. J. Syst. & Softw. 24(3), pp. 251–266, Mar 1994, DOI:10.1016/0164-1212(94)90067-1.
[36] M. Pacione, M. Roper, and M. Wood, “A novel software visualisation model to support software comprehension”. In 11th Working Conf. Reverse Engineering, pp. 70–79, 2004, DOI:10.1109/WCRE.2004.7.
[37] D. Pierret and D. Poshyvanyk, “An empirical exploration of regularities in open-source software lexicons ”. In 17th IEEE Intl. Conf. Program Comprehension, pp. 228–232, 2009, DOI:10.1109/ICPC.2009.5090047.
[38] J. Rilling and T. Klemola, “Identifying comprehension bottlenecks using program slicing and cognitive complexity metrics ”. In Program Comprehension, 2003. 11th IEEE International Workshop on, pp. 115 – 124, may 2003, DOI:10.1109/WPC.2003.1199195.
[39] J. Shao and Y. Wang, “A new measure of software complexity based on cognitive weights ”. Canadian J. Electrical and Comput. Eng. 28(2), pp. 69 –74, april 2003, DOI:10.1109/CJECE.2003.1532511.
[40] M. Shepperd, “A critique of cyclomatic complexity as a software metric ”. Software Engineering J. 3(2), pp. 30–36, Mar 1988.
[41] B. Shneiderman, “Measuring computer program quality and comprehension”. Intl. J. Man-Machine Studies 9(4), July 1977.
[42] E. Soloway and K. Ehrlich, “Empirical studies of programming knowledge ”. IEEE Trans. Softw. Eng. SE-10(5), pp. 595–609, Sep 1984, DOI:10.1109/TSE.1984.5010283.
[43] SRI, “Software technology roadmap: Cyclomatic complexity ”. In URL www.sei.cmu.edu/str/str.pdf, 1997. (Visited 28 Dec 2008).
[44] I. Stamelos, L. Angelis, A. Oikonomou, and G. L. Bleris, “Code quality analysis in open source software development ”. Inf. Syst. J. 12(1), pp. 43–60, Jan 2002, DOI:10.1046/j.1365-2575.2002.00117.x.
[45] VerifySoft Technology, “McCabe metrics ”. URL www.verifysoft.com/en_mccabe_metrics.html, Jan 2005. (Visited 23 Dec 2009).
[46] J. J. Vinju and M. W. Godfrey, “What does control flow really look like? Eyeballing the cyclomatic complexity metric ”. In 12th Working Conf. Source Code Analysis and Manipulation, Sep 2012.
[47] K. D. Welker, P. W. Oman, and G. G. Atkinson, “Development and application of an automated source code maintainability index”. J. Softw. Maintenance 9(3), pp. 127–159, May 1997.
[48] S. Xu, “A cognitive model for program comprehension”. In 3rd ACIS Intl. Conf. Softw. Eng. Research, Management, & Apps., pp. 392–398, Aug 2005, DOI:10.1109/SERA.2005.2.
[49] H. Zhang, “Exploring regularity in source code: Software science and Zipf’s law”. In 15th Working Conf. Reverse Engineering, pp. 101–110, 2008, DOI:10.1109/WCRE.2008.37.
[50] J. Zhao, N. Al-Aidroos, and N. B. Turk-Browne, “Attention is spontaneously biased toward regularities ”. Psychological Sci. 24(5), pp. 667–677, May 2013, DOI:10.1177/0956797612460407.
[51] J. Ziv and A. Lempel, “A universal algorithm for sequential data compression”. IEEE Trans. Information Theory IT-23(3), pp. 337–343, May 1977, DOI:10.1109/TIT.1977.1055714. 200

[1] H. Abelson and G. J. Sussman. Structure and Interpretation of Computer Programs. 2nd. Cambridge, MA, USA: MIT Press, 1996.
[2] E. Bainomugisha, A. L. Carreton, T. v. Cutsem, S. Mostinckx, and W. d. Meuter. “A survey on reactive programming.” In: ACM Comput. Surv. 45.4 (Aug. 2013), 52:1–52:34.
[3] G. H. Cooper and S. Krishnamurthi. “Embedding Dynamic Dataflow in a Call-by-value Language.” In: Proceedings of the 15th European Conference on Programming Languages and Systems. ESOP’06. Vienna, Austria: Springer-Verlag, 2006, pp. 294–308.
[4] B. Cornelissen, A. Zaidman, and A. van Deursen. “A Controlled Experiment for Program Comprehension Through Trace Visualization.” In: IEEE Trans. Softw. Eng. 37.3 (May 2011), pp. 341–355.
[5] C. L. Corritore and S. Wiedenbeck. “Mental Representations of Expert Procedural and Object-oriented Programmers in a Software Maintenance Task.” In: Int. J. Hum.-Comput. Stud. 50.1 (Jan. 1999), pp. 61–83.
[6] F. Détienne. Software Design—cognitive Aspects. Ed. by F. Bott. New York, NY, USA: Springer-Verlag New York, Inc., 2002.
[7] M. Di Penta, R. E. K. Stirewalt, and E. Kraemer. “Designing your Next Empirical Study on Program Comprehension.” In: Program Comprehension, 2007. ICPC ’07. 15th IEEE International Conference on. 2007, pp. 281–285.
[8] C. Elliott. “Functional Implementations of Continuous Modeled Animation.” In: Proceedings of the 10th International Symposium on Principles of Declarative Programming. PLILP ’98/ALP ’98. London, UK, UK: Springer-Verlag, 1998, pp. 284–299.
[9] C. Elliott and P. Hudak. “Functional reactive animation.” In: Proceedings of the second ACM SIGPLAN international conference on Functional programming. ICFP ’97. Amsterdam, The Netherlands: ACM, 1997, pp. 263–273.
[10] B. Ellis, J. Stylos, and B. Myers. “The Factory Pattern in API Design: A Usability Evaluation.” In: Proceedings of the 29th International Conference on Software Engineering. ICSE ’07. Washington, DC, USA: IEEE Computer Society, 2007, pp. 302–312.
[11] S. Endrikat and S. Hanenberg. “Is Aspect-Oriented Programming a Rewarding Investment into Future Code Changes? A Socio-technical Study on Development and Maintenance Time.” In: Program Comprehension (ICPC), 2011 IEEE 19th International Conference on. 2011, pp. 51–60.
[12] S. D. Fleming, E. Kraemer, R. E. K. Stirewalt, S. Xie, and L. K. Dillon. “A Study of Student Strategies for the Corrective Maintenance of Concurrent Software.” In: Proceedings of the 30th International Conference on Software Engineering. ICSE ’08. Leipzig, Germany: ACM, 2008, pp. 759–768.
[13] B. N. Freeman-Benson. “Kaleidoscope: mixing objects, constraints, and imperative programming.” In: OOPSLA/ECOOP ’90. Ottawa, Canada: ACM, 1990, pp. 77–88.
[14] Gamma, Helm, Johnson, and Vlissides. Design Patterns Elements of Reusable Object-Oriented Software. Addison- Wesley, 2000.
[15] S. Hanenberg. “An Experiment About Static and Dynamic Type Systems: Doubts About the Positive Impact of Static Type Systems on Development Time.” In: Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications. OOPSLA ’10. Reno/Tahoe, Nevada, USA: ACM, 2010, pp. 22–35.
[16] S. Hanenberg. “An Experiment About Static and Dynamic Type Systems: Doubts About the Positive Impact of Static Type Systems on Development Time.” In: SIGPLAN Not. 45.10 (Oct. 2010), pp. 22–35.
[17] S. Hanenberg, S. Kleinschmager, and M. Josupeit-Walter. “Does Aspect-oriented Programming Increase the Development Speed for Crosscutting Code? An Empirical Study.” In: Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement. ESEM ’09. Washington, DC, USA: IEEE Computer Society, 2009, pp. 156–167.
[18] M. Hoppe and S. Hanenberg. “Do Developers Benefit from Generic Types?: An Empirical Comparison of Generic and Raw Types in Java.” In: Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages and Applications. OOPSLA ’13. Indianapolis, Indiana, USA: ACM, 2013, pp. 457–474.
[19] P. Hudak, A. Courtney, H. Nilsson, and J. Peterson. “Arrows, Robots, and Functional Reactive Programming.” In: Summer School on Advanced Functional Programming 2002, Oxford University. Vol. 2638. Lecture Notes in Computer Science. Springer-Verlag, 2003, pp. 159–187.
[20] N. Juristo and A. M. Moreno. Basics of Software Engineering Experimentation. 1st. Springer Publishing Company, Incorporated, 2010.
[21] S. Kleinschmager and S. Hanenberg. “How to Rate Programming Skills in Programming Experiments?: A Preliminary, Exploratory, Study Based on University Marks, Pretests, and Self-estimation.” In: Proceedings of the 3rd ACM SIGPLAN Workshop on Evaluation and Usability of Programming Languages and Tools. PLATEAU ’11. Portland, Oregon, USA: ACM, 2011, pp. 15–24.
[22] T. D. LaToza, D. Garlan, J. D. Herbsleb, and B. A. Myers. “Program Comprehension As Fact Finding.” In: Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering. ESEC-FSE ’07. Dubrovnik, Croatia: ACM, 2007, pp. 361–370.
[23] T. D. LaToza and B. A. Myers. “Developers Ask Reachability Questions.” In: Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering - Volume 1. ICSE ’10. Cape Town, South Africa: ACM, 2010, pp. 185–194.
[24] T. D. LaToza, G. Venolia, and R. DeLine. “Maintaining Mental Models: A Study of Developer Work Habits.” In: Proceedings of the 28th International Conference on Software Engineering. ICSE ’06. Shanghai, China: ACM, 2006, pp. 492– 501.
[25] J. Liberty and P. Betts. Programming Reactive Extensions and LINQ. 1st. Berkely, CA, USA: Apress, 2011.
[26] I. Maier and M. Odersky. Deprecating the Observer Pattern with Scala.React. Tech. rep. 2012.
[27] I. Maier and M. Odersky. “Higher-Order Reactive Programming with Incremental Lists.” In: ECOOP 2013 - Object- Oriented Programming. Ed. by G. Castagna. Vol. 7920. Lecture Notes in Computer Science. Springer Berlin Heidelberg, 2013, pp. 707–731.
[28] C. Mayer, S. Hanenberg, R. Robbes, É. Tanter, and A. Stefik. “An Empirical Study of the Influence of Static Type Systems on the Usability of Undocumented Software.” In: Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications. OOPSLA ’12. Tucson, Arizona, USA: ACM, 2012, pp. 683– 702.
[29] L. A. Meyerovich, A. Guha, J. Baskin, G. H. Cooper, M. Greenberg, A. Bromfield, and S. Krishnamurthi. “Flapjax: a programming language for Ajax applications.” In: OOPSLA ’09. Orlando, Florida, USA: ACM, 2009, pp. 1–20.
[30] B. A. Myers, R. G. McDaniel, R. C. Miller, A. S. Ferrency, A. Faulring, B. D. Kyle, A. Mickish, A. Klimovitski, and P. Doane. “The Amulet Environment: New Models for Effective User Interface Software Development.” In: IEEE Trans. Softw. Eng. 23.6 (June 1997), pp. 347–365.
[31] R. Newton, G. Morrisett, and M. Welsh. “The Regiment Macroprogramming System.” In: Information Processing in Sensor Networks, 2007. IPSN 2007. 6th International Symposium on. 2007, pp. 489–498.
[32] F. Olivero, M. Lanza, M. D’ambros, and R. Robbes. “Tracking Human-centric Controlled Experiments with Biscuit.” In: Proceedings of the ACM 4th Annual Workshop on Evaluation and Usability of Programming Languages and Tools. PLATEAU ’12. Tucson, Arizona, USA: ACM, 2012, pp. 1–6.
[33] V. Pankratius, F. Schmidt, and G. Garreton. “Combining functional and imperative programming for multicore software: An empirical study evaluating Scala and Java.” In: Software Engineering (ICSE), 2012 34th International Conference on. 2012, pp. 123–133.
[34] N. Pennington. “Stimulus structures and mental representations in expert comprehension of computer programs.” In: Cognitive Psychology 19.3 (1987), pp. 295–341.
[35] L. Prechelt. “An Empirical Comparison of Seven Programming Languages.” In: Computer 33.10 (Oct. 2000), pp. 23– 29.
[36] J. Quante. “Do Dynamic Object Process Graphs Support Program Understanding? - A Controlled Experiment.” In: Program Comprehension, 2008. ICPC 2008. The 16th IEEE International Conference on. June 2008, pp. 73–82.
[37] V. Ramalingam and S. Wiedenbeck. “An empirical study of novice program comprehension in the imperative and objectoriented styles.” In: Papers presented at the seventh workshop on Empirical studies of programmers. ESP ’97. Alexandria, Virginia, USA: ACM, 1997, pp. 124–139.
[38] T. Roehm, R. Tiarks, R. Koschke, and W. Maalej. “How do professional developers comprehend software?” In: Proceedings of the 2012 International Conference on Software Engineering. ICSE 2012. Zurich, Switzerland: IEEE Press, 2012, pp. 255–265.
[39] G. Salvaneschi, J. Drechsler, and M. Mezini. “Towards Distributed Reactive Programming.” In: Coordination Models and Languages. Springer. 2013, pp. 226–235.
[40] G. Salvaneschi, G. Hintz, and M. Mezini. “REScala: Bridging Between Object-oriented and Functional Style in Reactive Applications.” In: Proceedings of the 13th International Conference on Modularity. MODULARITY ’14. Lugano, Switzerland: ACM, 2014, pp. 25–36.
[41] G. Salvaneschi and M. Mezini. “Towards Reactive Programming for Object-Oriented Applications.” English. In: Transactions on Aspect-Oriented Software Development XI. Ed. by S. Chiba, É. Tanter, E. Bodden, S. Maoz, and J. Kienzle. Vol. 8400. Lecture Notes in Computer Science. Springer Berlin Heidelberg, 2014, pp. 227–261.
[42] M.-A. Storey. “Theories, Tools and Research Methods in Program Comprehension: Past, Present and Future.” In: Software Quality Control 14.3 (Sept. 2006), pp. 187–208.
[43] J. Stylos and S. Clarke. “Usability Implications of Requiring Parameters in Objects’ Constructors.” In: Proceedings of the 29th International Conference on Software Engineering. ICSE ’07. Washington, DC, USA: IEEE Computer Society, 2007, pp. 529–539.
[44] J. Stylos and B. A. Myers. “The Implications of Method Placement on API Learnability.” In: Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of Software Engineering. SIGSOFT ’08/FSE-16. Atlanta, Georgia: ACM, 2008, pp. 105–112.
[45] R. Wettel, M. Lanza, and R. Robbes. “Software Systems As Cities: A Controlled Experiment.” In: Proceedings of the 33rd International Conference on Software Engineering. ICSE ’11. Honolulu, HI, USA: ACM, 2011, pp. 551–560.

[1] Krishan K Aggarwal, Yogesh Singh, and Jitender Kumar Chhabra. 2002. An integrated measure of software maintainability. In Proc. Annual Reliability and Maintainability Symposium. IEEE, 235–241.
[2] Paul D Allison. 1999. Multiple regression: A primer. Pine Forge Press.
[3] Marc Bartsch and Rachel Harrison. 2008. An exploratory study of the effect of aspect-oriented programming on maintainability. Software Quality Journal 16, 1 (2008), 23–44.
[4] Douglas M. Bates. 2010. lme4: Mixed-effects modeling with R. http://lme4.r-forge. r-project.org/book/
[5] Richard Berk, Lawrence Brown, and Linda Zhao. 2010. Statistical inference after model selection. Journal of Quantitative Criminology 26, 2 (2010), 217–236.
[6] Raymond PL Buse and Westley R Weimer. 2010. Learning a metric for code readability. IEEE Transactions on Software Engineering 36, 4 (2010), 546–558.
[7] Andrea Capiluppi, Maurizio Morisio, and Patricia Lago. 2004. Evolution of understandability in OSS projects. In Proc. European Conference on Software Maintenance and Reengineering (CSMR). IEEE, 58–66.
[8] Ermira Daka, José Campos, Gordon Fraser, Jonathan Dorn, and Westley Weimer. 2015. Modeling readability to improve unit tests. In Proc. Joint Meeting on Foundations of Software Engineering (ESEC/FSE). ACM, 107–118.
[9] Jonathan Dorn. 2012. A general software readability model. MCS Thesis available from (http://www. cs. virginia. edu/˜ weimer/students/dorn-mcs-paper. pdf) (2012).
[10] Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2017. An Introduction to Statistical Learning with Applications in R. Springer.
[11] Natalia Juristo and Omar S Gómez. 2012. Replication of software engineering experiments. In Empirical Software Engineering and Verification. Springer, 60–88.
[12] Jin-Cherng Lin and Kuo-Chiang Wu. 2006. A model for measuring software understandability. In Proc. International Conference on Computer and Information Technology (CIT). IEEE, 192–192.
[13] Jin-Cherng Lin and Kuo-Chiang Wu. 2008. Evaluation of software understandability based on fuzzy matrix. In Proc. International Conference on Fuzzy Systems. IEEE, 887–892.
[14] Roberto Minelli, Andrea Mocci, and Michele Lanza. 2015. I know what you did last summer: an investigation of how developers spend their time. In Proc. International Conference on Program Comprehension (ICPC). IEEE, 25–35.
[15] Shinichi Nakagawa and Holger Schielzeth. 2013. A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods in Ecology and Evolution 4, 2 (2013), 133–142.
[16] Daryl Posnett, Abram Hindle, and Premkumar Devanbu. 2011. A simpler model of software readability. In Proc. International Conference on Mining Software Repositories. ACM, 73–82.
[17] Simone Scalabrino, Gabriele Bavota, Christopher Vendome, Mario Linares- Vásquez, Denys Poshyvanyk, and Rocco Oliveto. 2017. Automatically Assessing Code Understandability: How Far Are We?. In Proc. International Conference on Automated Software Engineering (ASE). IEEE.
[18] Simone Scalabrino, Mario Linares-Vásquez, Denys Poshyvanyk, and Rocco Oliveto. 2016. Improving code readability models with textual features. In Proc. International Conference on Program Comprehension (ICPC). IEEE, 1–10.
[19] D Srinivasulu, Adepu Sridhar, and Durga Prasad Mohapatra. 2014. Evaluation of Software Understandability Using Rough Sets. In Intelligent Computing, Networking, and Informatics. Springer, 939–946.
[20] M-A Storey. 2005. Theories, methods and tools in program comprehension: Past, present and future. In Proc. International Conference on Program Comprehension (ICPC). IEEE, 181–191.
[21] M-AD Storey, Kenny Wong, and Hausi A Müller. 2000. How do program understanding tools affect how programmers understand programs? Science of Computer Programming 36, 2-3 (2000), 183–207.
[22] Asher Trockman, Shurui Zhou, Christian Kästner, and Bogdan Vasilescu. 2018. Adding Sparkle to Social Coding: An Empirical Study of Repository Badges in the npm Ecosystem. In Proc. International Conference on Software Engineering (ICSE). ACM.

[1] Surafel Lemma Abebe, Venera Arnaoudova, Paolo Tonella, Giuliano Antoniol, and Yann Gaël Guéhéneuc. 2012. Can Lexicon Bad Smells improve fault prediction?. In Proceedings of the Working Conference on Reverse Engineering (WCRE). 235–244.
[2] Venera Arnaoudova, Massimiliano Di Penta, and Giuliano Antoniol. 2016. Linguistic antipatterns: what they are and how developers perceive them. Empirical Software Engineering 21, 1 (2016), 104–158.
[3] Alberto Bacchelli and Christian Bird. 2013. Expectations, Outcomes, and Challenges of Modern Code Review. In Proceedings of the International Conference on Software Engineering (ICSE). 712–721.
[4] David Binkley, Marcia Davis, Dawn Lawrie, and Christopher Morrell. 2009. To CamelCase or Under_score. In Proceedings of the International Conference on Program Comprehension (ICPC). 158–167.
[5] Raymond P.L. Buse and Westley R. Weimer. 2010. Learning a metric for code readability. IEEE Transactions on Software Engineering (TSE) 36, 4 (2010), 546–558.
[6] Simon Butler, Michel Wermelinger, Yijun Yu, and Helen Sharp. 2009. Relating Identifier Naming Flaws and Code Quality: An Empirical Study. In Proceedings of the Working Conference on Reverse Engineering (WCRE). 31–35.
[7] Simon Butler, MichelWermelinger, Yijun Yu, and Helen Sharp. 2010. Exploring the Influence of Identifier Names on Code Quality: An empirical study. In Proceedings of the European Conference on Software Maintenance and Reengineering (CSMR). 156–165.
[8] Sarah Fakhoury, Yuzhan Ma, Venera Arnaoudova, and Olusola Adesope. 2018. The Effect of Poor Source Code Lexicon and Readability on Developers’ Cognitive Load. IEEE International Conference on Program Comprehension (ICPC) (2018).
[9] Frank A. Fishburn, Megan E. Norr, Andrei V. Medvedev, and Chandan J. Vaidya. 2014. Sensitivity of fNIRS to cognitive state and load. Frontiers in human neuroscience 8 (2014), 76.
[10] Benjamin Floyd, Tyler Santander, and Westley Weimer. 2017. Decoding the Representation of Code in the Brain: An fMRI Study of Code Reviewand Expertise. In Proceedings of the International Conference on Software Engineering (ICSE). 175– 186.
[11] Thomas Fritz, Andrew Begel, Sebastian C Müller, Serap Yigit-Elliott, and Manuela Züger. 2014. Using Psycho-physiological Measures to Assess Task Difficulty in Software Development. In Proceedings of the International Conference on Software Engineering (ICSE). 402–413.
[12] Yoshiharu Ikutani and Hidetake Uwano. 2014. Brain activity measurement during program comprehension with NIRS. In Proceedings of the International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD). 1–6.
[13] Dawn Lawrie, Christopher Morrell, Henry Feild, and David Binkley. 2006. What’s in a Name? A Study of Identifiers. In Proceedings of International Conference on Program Comprehension (ICPC). 3–12.
[14] Seolhwa Lee, Danial Hooshyar, Hyesung Ji, Kichun Nam, and Heuiseok Lim. 2017. Mining biometric data to predict programmer expertise and task difficulty. Cluster Computing (2017), 1–11.
[15] Andrian Marcus, Denys Poshyvanyk, and Rudolf Ferenc. 2008. Using the Conceptual Cohesion of Classes for Fault Prediction in Object-Oriented Systems. IEEE Transactions on Software Engineering (TSE) 34, 2 (2008), 287–30.
[16] Takao Nakagawa, Yasutaka Kamei, Hidetake Uwano, Akito Monden, Kenichi Matsumoto, and Daniel M. German. 2014. Quantifying programmers’ mental workload during program comprehension based on cerebral blood flow measurement: a controlled experiment. In Proceedings of the International Conference on Software Engineering (ICSE). 448–451.
[17] Denys Poshyvanyk, Yann-Gaël Guéhéneuc, Andrian Marcus, Giuliano Antoniol, and Vaclav Rajlich. 2006. Combining Probabilistic Ranking and Latent Semantic Indexing for Feature Identification. In Proceedings of the International Conference on Program Comprehension (ICPC). 137–148.
[18] Daryl Posnett, Abram Hindle, and Premkumar Devanbu. 2011. A Simpler Model of Software Readability. In Proceedings of the Working Conference on Mining Software Repositories (MSR). 73–82.
[19] Timothy R Shaffer, Jenna L Wise, Braden M Walters, Sebastian C Müller, Michael Falcone, and Bonita Sharif. 2015. iTrace: Enabling eye tracking on software artifacts within the IDE to support software engineering tasks. In Proceedings of the Joint Meeting on Foundations of Software Engineering (ESEC/FSE). 954–957.
[20] Janet Siegmund, Christian Kästner, Sven Apel, Chris Parnin, Anja Bethmann, Thomas Leich, Gunter Saake, and André Brechmann. 2014. Understanding understanding source code with functional magnetic resonance imaging. In Proceedings of the International Conference on Software Engineering (ICSE). 378– 389.
[21] Janet Siegmund, Norman Peitek, Chris Parnin, Sven Apel, Johannes Hofmeister, Christian Kästner, Andrew Begel, Anja Bethmann, and André Brechmann. 2017. Measuring neural efficiency of program comprehension. In Proceedings of the Joint Meeting on Foundations of Software Engineering (ESEC/FSE). 140–150.
[22] Thomas A. Standish. 1984. An Essay on Software Reuse. IEEE Transactions on Software Engineering (TSE) 10, 5 (September 1984), 494–497.
[23] Rebecca Tiarks. 2011. What Maintenance Programmers Really Do: An Observational Study. In Proceedings of the Workshop Software Reengineering (WSR). 36–37.
[24] A. von Mayrhauser and A.M. Vans. 1995. Program comprehension during software maintenance and evolution. IEEE Computer 28, 8 (August 1995), 44–55.

[1] J. Belliveau et al. Functional Mapping of the Human Visual Cortex by Magnetic Resonance Imaging. Science, 254(5032):716–719, 1991.
[2] R. Brooks. Using a Behavioral Theory of Program Comprehension in Software Engineering. In Proc. Int’l Conf. Software Engineering (ICSE), pages 196–201. IEEE CS, 1978.
[3] R. Cabeza and L. Nyberg. Imaging Cognition II: An Empirical Review of 275 PET and fMRI Studies. Journal of Cognitive Neuroscience, 12(1):1–47, 2000.
[4] J. Feigenspan, S. Apel, J. Liebig, and C. K¨astner. Exploring Software Measures to Assess Program Comprehension. In Proc. Int’l Symposium Empirical Software Engineering and Measurement (ESEM), pages 1–10, 2011.
[5] J. Feigenspan et al. On the Role of Program Comprehension in Embedded Systems. In Proc. Workshop Software-Reengineering (WSR), pages 34–35, 2011.
[6] J. Feigenspan and N. Siegmund. Supporting Comprehension Experiments with Human Subjects. In Proc. Int’l Conf. Program Comprehension (ICPC), pages 244–246. IEEE CS, 2012. Tool demo.
[7] J. Koenemann and S. Robertson. Expert Problem Solving Strategies for Program Comprehension. In Proc. Conf. Human Factors in Computing Systems (CHI), pages 125–130. ACM Press, 1991.
[8] J. Moss et al. The Neural Correlates of Strategic Reading Comprehension: Cognitive Control and Discourse Comprehension. NeuroImage, 58(2):675–686, 2011.
[9] C. Parnin and S. Rugaber. Programmer Information Needs after Memory Failure. In Proc. Int’l Conf. Program Comprehension (ICPC), pages 123–132. IEEE CS, 2012.
[10] N. Pennington. Stimulus Structures and Mental Representations in Expert Comprehension of Computer Programs. Cognitive Psychologys, 19(3):295–341, 1987.
[11] E. Soloway and K. Ehrlich. Empirical Studies of Programming Knowledge. IEEE Trans. Softw. Eng., 10(5):595–609, 1984.
[12] R. Tiarks. What Programmers Really Do: An Observational Study. In Proc. Workshop Software-Reengineering (WSR), pages 36–37, 2011.

AGARWAL, K.K. AND AGARWAL, A. 2005. Python for Cs1, Cs2 and Beyond. Journ. of Comp. Sciences in Colleges 20, 262- 270.
BEDNARIK, R. AND TUKIAINEN, M. 2008. Temporal Eye- Tracking Data: Evolution of Debugging Strategies with Multiple Representations. In Symposium on Eye Tracking Research & Applications (ETRA) ACM, Georgia, 99-102.
BINKLEY, D., DAVIS, M., LAWRIE, D., MALETIC, J.I., MORRELL, C. AND SHARIF, B. 2013. The Impact of Identifier Style on Effort and Comprehension. ESE Journal 18, 219-276.
CROSBY, M.E. AND STELOVSKY, J. 1990. How Do We Read Algorithms? A Case Study. IEEE Computer 23, 24-35.
DUCHOWSKI, A.T. 2003. Eye Tracking Methodology: Theory and Practice. Springer-Verlag, London.
ENBODY, R.J., PUNCH, W.F. AND MCCULLEN, M. 2009. Python Cs1 as Preparation for C++ Cs2. In SIGCSE 2009 ACM, Chattanooga, Tennesee, USA, 116-120.
GLASS, R.L. 2002. Facts and Fallacies of Software Engineering. Addison-Wesley Professional.
HANSEN, M., GOLDSTONE, R. AND LUMSDAINE, A. 2013. What Makes Code Hard to Understand? ArXiv e-prints.
SHARIF, B., FALCONE, M. AND MALETIC, J.I. 2012. An Eye- Tracking Study on the Role of Scan Time in Finding Source Code Defects. In ETRA, Santa Barbara, CA, 381-384
UWANO, H., NAKAMURA, M., MONDEN, A. AND MATSUMOTO, K. 2006. Analyzing Individual Performance of Source Code Review Using Reviewers' Eye Movement. In ETRA, ACM Press, San Diego, 133-140.
WOHLIN, C., RUNESON, P., HÖST, M., OHLSSON, M.C., REGNELL, B. AND WESSLÉN, A. 1999. Experimentation in Software Engineering - an Introduction. Kluwer Academic Press.

[1] Surafel Lemma Abebe, Venera Arnaoudova, Paolo Tonella, Giuliano Antoniol, and Yann Gael Gueheneuc. 2012. Can Lexicon Bad Smells improve fault prediction?. In Proceedings of the Working Conference on Reverse Engineering (WCRE). 235-244. 
[2] Daniel Afergan, Evan M Peck, Erin T Solovey, Andrew Jenkins, Samuel W Hincks, Eli T Brown, Remco Chang, and Robert JK Jacob. 2014. Dynamic difficulty using brain metrics of workload. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 3797-3806. 
[3] Venera Arnaoudova, Massimiliano Di Penta, and Giuliano Antoniol. 2016. Linguis-tic Antipatterns: What They are and How Developers Perceive Them. Empirical Software Engineering (EMSE) 21, 1 (2016), 104-158. 
[4] Venera Arnaoudova, Massimiliano Di Penta, Giuliano Antoniol, and Yann-Gael Gueheneuc. 2013. A New Family of Software Anti-Patterns: Linguistic Anti-Patterns. In Proceedings of the European Conference on Software Maintenance and Reengineering (CSMR). 187-196. 
[5] BIOPAC. 2018. BIOPAC I Iomepage. (March 2018). https://www.biopac.com 
[6] BIOPAC. 2018. fNIRSoft User Manual. (March 2018). https://www.biopac.com/ wp- content/uploads/fnirsoft- user- manual.pdf 
[7] Raymond P.L. Buse and Westley R. Weimer. 2010. Learning a metric for code readability. IEEE Transactions on Software Engineering (TSE) 36, 4 (2010), 546-558. 
[8] Simon Butler, Michel Wermelinger, Yijun Yu, and Helen Sharp. 2009. Relating Identifier Naming Flaws and Code Quality: An Empirical Study. In Proceedings of the Working Conference on Reverse Engineering (WCRE). 31-35. 
[9] Simon Butler, Michel Wermelinger, Yijun Yu, and Helen Sharp. 2010. Exploring the Influence of Identifier Names on Code Quality: An empirical study. In Proceedings of the European Conference on Software Maintenance and Reengineering (CSMR). 156-165. 
[10] David T Delpy, Mark Cope, Pieter van der Zee, SR Arridge, Susan Wray, and JS Wyatt. 1988. Estimation of optical pathlength through tissue from direct time of flight measurement. Physics in Medicine & Biology 33, 12 (1988), 1433. 
[11] Eclipse. 2018. Eclipse IDE. (March 2018). https://www.eclipse.org/ide 
[12] EyeTribe. 2018. The Eye Tribe Homepage. (March 2018). https://theeyetribe.com 
[13] Sarah Fakhoury. 2018. Online Replication Package. (March 2018). https://github. com/smfakhoury/fNIRS- and- Cognitive- Load 
[14] Frank A. Fishburn, Megan E. Norr, Andrei V. Medvedev, and Chandan J. Vaidya. 2014. Sensitivity of fNIRS to cognitive state and load. Frontiers in human neuro-science 8 (2014), 76. 
[15] Benjamin Floyd, Tyler Santander, and Westley Weimer. 2017. Decoding the Representation of Code in the Brain: An fMRI Study of Code Review and Expertise. In Proceedings of the International Conference on Software Engineering (ICSE). 175-186. 
[16] Thomas Fritz, Andrew Begel, Sebastian C Muller, Serap Yigit-Elliott, and Manuela ZUger. 2014. Using Psycho-physiological Measures to Assess Task Difficulty in Software Development. In Proceedings of the International Conference on Software Engineering (ICSE). 402-413. 
[17] Audrey Girouard, Erin Treacy Solovey, Leanne M. Hirshfield, Krysta Chauncey, Angelo Sassaroli, Sergio Fantini, and Robert. J.K. Jacob. 2009. Distinguishing difficulty levels with non-invasive brain activity measurements. In IFIP Conference on Human-Computer Interaction. Springer, 440-452. 
[18] Robert J. Grissom and John J. Kim. 2005. Effect sizes for research: A broad practical approach (2nd edition ed.). Lawrence Earlbaum Associates. 
[19] Sonia I Iaiduc and Andrian Marcus. 2008. On the Use of Domain Terms in Source Code. In Proceedings of the International Conference on Program Comprehension (ICPC). 113-122. 
[20] Maurice H Halstead. 1977. Elements of software science. (1977). 
[21] Christian Herff, Dominic Heger, Ole Fortmann, Johannes Hennrich, Felix Putze, and Tanja Schultz. 2014. Mental workload during n-back task-quantified in the prefrontal cortex using fNIRS. Frontiers in Human Neuroscience 7 (2014), 935. 
[22] Yoshiharu Ikutani and Hidetake Uwano. 2014. Brain activity measurement during program comprehension with NIRS. In Proceedings of the International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD). 1-6. 
[23] Seolhwa Lee, Danial Hooshyar, Hyesung Ji, Kichun Nam, and Heuiseok Lim. 2017. Mining biometric data to predict programmer expertise and task difficulty. Cluster Computing (2017), 1-11. 
[24] Andrian Marcus, Denys Poshyvanyk, and Rudolf Ferenc. 2008. Using the Concep-tual Cohesion of Classes for Fault Prediction in Object-Oriented Systems. IEEE Transactions on Software Engineering (TSE) 34, 2 (2008), 287-30. 
[25] Thomas J. McCabe. 1976. A Complexity Measure. IEEE Transactions on Software Engineering (TSE) SE-2, 4 (1976), 308-320. 
[26] Sebastian C Muller and Thomas Fritz. 2016. Using (bio)metrics to predict code quality online. In Proceedings of the International Conference on Software Engi-neering (ICSE). 452-463. 
[27] Takao Nakagawa, Yasutaka Kamei, Hidetake Uwano, Akito Monden, Kenichi Matsumoto, and Daniel M. German. 2014. Quantifying programmers' mental workload during program comprehension based on cerebral blood flow measure-ment a controlled experiment. In Proceedings of the International Conference on Software Engineering (ICSE). 448-451. 
[28] Kristien Ooms, Lien Dupont, Lieselot Lapon, and Stanislav Popelka. 2015. Ac-curacy and precision of fixation locations recorded with the low-cost Eye Tribe tracker in different experimental setups. Journal of eye movement research 8, 1 (2015). 
[29] Denys Poshyvanyk, Yann-Gael Gueheneuc, Andrian Marcus, Giuliano Antoniol, and Vaclav Rajlich. 2006. Combining Probabilistic Ranking and Latent Semantic Indexing for Feature Identification. In Proceedings of the International Conference on Program Comprehension (ICPC). 137-148. 
[30] Daryl Posnett, Abram Hindle, and Premkumar Devanbu. 2011. A Simpler Model of Software Readability. In Proceedings of the Working Conference on Mining Software Repositories (MSR). 73-82. 
[31] Keith Rayner. 1998. Eye movements in reading and information processing: 20 years of research. Psychological Bulletin 124, 3 (1998), 372-422. 
[32] Iflaah Salman, Ayse Tosun Misirli, and Natalia Juristo. 2015. Are students repre-sentatives of professionals in software engineering experiments?. In Proceedings of the International Conference on Software Engineering (ICSE). 666-676. 
[33] Simone Scalabrino, Mario Linares-Vasquez, Denys Poshyvanyk, and Rocco Oliveto. 2016. Improving code readability models with textual features. In Pro-ceedings of the International Conference on Program Comprehension (ICPC). 1-10. 
[34] Timothy R Shaffer, Jenna L Wise, Braden M Walters, Sebastian C Muller, Michael Falcone, and Bonita Sharif. 2015. iTrace: Enabling eye tracking on software artifacts within the IDE to support software engineering tasks. In Proceedings of the Joint Meeting on Foundations of Software Engineering (ESEC/FSE). 954-957. 
[35] Janet Siegmund, Christian Kastner, Sven Apel, Chris Parnin, Anja Bethmann, Thomas Leich, Gunter Saake, and Andre Brechmann. 2014. Understanding understanding source code with functional magnetic resonance imaging. In Proceedings of the International Conference on Software Engineering (ICSE). 378-389. 
[36] Janet Siegmund, Norman Peitek, Chris Parnin, Sven Apel, Johannes Hofmeister, Christian Kastner, Andrew Begel, Anja Bethmann, and Andre Brechmann. 2017. Measuring neural efficiency of program comprehension. In Proceedings of the Joint Meeting on Foundations of Software Engineering (ESEC/FSE). 140-150. 
[37] Robert R Sokal. 1958. A statistical method for evaluating systematic relationship. University of Kansas science bulletin 28 (1958), 1409-1438 
[38] Erin Treacy Solovey, Daniel Afergan, Evan M. Peck, Samuel W. Hincks, and Robert J. K. Jacob. 2015. Designing Implicit Interfaces for Physiological Computing. ACM Transactions on Computer-Human Interaction 21, 6 (2015), 1-27. 
[39] Claes Wohlin, Per Runeson, Host Martin, Magnus C. Ohlsson, Bjorn Regnell, and Anders Wesslen. 2000. Experimentation in Software Engineering - An Introduction. Kluwer Academic Publishers. [40] Robert K. Yin. 1994. Case Study Research: Design and Methods (2nd ed.). Sage Publications. 

[1] Hirohisa Aman, Sousuke Amasaki, Tomoyuki Yokogawa, and Minoru Kawahara. 2016. Local variables with compound names and comments as signs of faultprone Java methods. In Joint Proceedings of the 4th International Workshop on Quantitative Approaches to Software Quality and 1st International Workshop on Technical Debt Analytics. 4–11.
[2] Alan D. Baddeley. 2000. The episodic buffer: A new component of working memory? Trends in Cognitive Sciences 4, 11 (2000), 417–423.
[3] Alan D. Baddeley. 2007. Working memory, thought, and action. Vol. 45. OUP Oxford.
[4] Alan D. Baddeley, Robert Logie, Ian Nimmo-Smith, and Neil Brereton. 1985. Components of fluent reading. Journal of Memory and Language 24, 1 (1985), 119–131.
[5] Alan D. Baddeley, Neil Thomson, and Mary Buchanan. 1975. Word length and the structure of short-term memory. Journal of Verbal Learning and Verbal Behavior 14, 6 (1975), 575–589.
[6] Dave Binkley, Marcia Davis, Dawn Lawrie, Jonathan I. Maletic, Christopher Morrell, and Bonita Sharif. 2013. The impact of identifier style on effort and comprehension. Empirical Software Engineering 18, 2 (2013), 219–276.
[7] Dave Binkley, Marcia Davis, Dawn Lawrie, and Christopher Morrell. 2009. To camelCase or under_score. In 17th International Conference on Program Comprehension (ICPC ’09). IEEE, 158–167.
[8] Dave Binkley, Dawn Lawrie, Steve Maex, and Christopher Morrell. 2009. Identifier length and limited programmer memory. Science of Computer Programming 74, 7 (2009), 430–445.
[9] Ruven Brooks. 1983. Towards a theory of the comprehension of computer programs. International Journal of Man-Machine Studies 18, 6 (1983), 543–554.
[10] Simon Butler, Michel Wermelinger, Yijun Yu, and Helen Sharp. 2009. Relating identifier naming flaws and code quality: An empirical study. In 16th Working Conference on Reverse Engineering (WCRE ’09). IEEE, 31–35.
[11] Simon Butler, Michel Wermelinger, Yijun Yu, and Helen Sharp. 2010. Exploring the influence of identifier names on code quality: An empirical study. In 14th European Conference on Software Maintenance and Reengineering (CSMR ’10). IEEE, 156–165.
[12] Jacob Cohen. 1988. Statistical power analysis for the behavioral sciences . Hilsdale. (1988).
[13] Meredyth Daneman and Patricia A. Carpenter. 1980. Individual differences in working memory and reading. Journal of Verbal Learning and Verbal Behavior 19, 4 (1980), 450–466.
[14] Florian Deissenboeck and Markus Pizka. 2006. Concise and consistent naming. Software Quality Journal 14, 3 (2006), 261–282.
[15] Eric Evans and Rafał Szpoton. 2015. Domain-driven design. Helion.
[16] Richard K. Fjeldstad. 1983. Application program maintenance study: Report to our respondents. Proceedings GUIDE 48, 1983 (1983).
[17] Johannes C. N. Hofmeister, Janet Siegmund, and Daniel V. Holt. 2017. Shorter identifier names take longer to comprehend. In 24th International Conference on Software Analysis, Evolution, and Reengineering (SANER ’17). IEEE, 217–227.
[18] Anthony R. Jansen, Alan F. Blackwell, and Kim Marriott. 2003. A tool for tracking visual attention: The Restricted Focus Viewer. Behavior Research Methods 35, 1 (2003), 57–69.
[19] Dawn Lawrie, Christopher Morrell, Henry Feild, and David Binkley. 2006. What’s in a name? A study of identifiers. In 14th International Conference on Program Comprehension (ICPC ’06). IEEE, 3–12.
[20] Dawn Lawrie, Christopher Morrell, Henry Feild, and David Binkley. 2007. Effective identifier names for comprehension and memory. Innovations in Systems and Software Engineering 3, 4 (2007), 303–318.
[21] Ben Liblit, Andrew Begel, and Eve Sweetser. 2006. Cognitive perspectives on the role of naming in computer programs. In Proceedings of the 18th Annual Psychology of Programming Workshop.
[22] Robert C. Martin. 2009. Clean code: a handbook of agile software craftsmanship. Pearson Education.
[23] Phillip Anthony Relf. 2004. Achieving software quality through source code readability. Quality Contract Manufacturing LLC (2004).
[24] Teresa M. Shaft and Iris Vessey. 1995. The relevance of application domain knowledge: The case of computer program comprehension. Information Systems Research 6, 3 (1995), 286–299.
[25] Bonita Sharif and Jonathan I. Maletic. 2010. An eye-tracking study on camelCase and under_score identifier styles. In 18th International Conference OnProgram Comprehension (ICPC ’10). IEEE, 196–205.
[26] Ben Shneiderman and Richard Mayer. 1979. Syntactic/semantic interactions in programmer behavior: A model and experimental results. International Journal of Computer & Information Sciences 8, 3 (1979), 219–238.

[1] E. Awh, J. Jonides, E. Smith, E. Schumacher, R. Koeppe, and S. Katz. Dissociation of Storage and Rehearsal in Verbal Working Memory: Evidence from Positron Emission Tomography. Psychological Science, 7(1):25–31, 1996.
[2] A. Baddeley. Is Working Memory Still Working? The American Psychologist, 56(11):851–864, 2001.
[3] J. Bahlmann, R. Schubotz, and A. Friederici. Hierarchical Artificial Grammar Processing Engages Broca’s Area. NeuroImage, 42(2):525–534, 2008.
[4] E. Baniassad and S. Fleissner. The Geography of Programming. In Proc. Int’l Conf. Object-Oriented Programming, Systems, Languages and Applications (OOPSLA), pages 510–520. ACM, 2006.
[5] Y. Benjamini and Y. Hochberg. Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing. Journal of the Royal Statistical Society. Series B (Methodological), 57(1):289–300, 1995.
[6] E. Berg. A Simple Objective Technique for Measuring Flexibility in Thinking. Journal of General Psychology, 39(1):15–22, 1948.
[7] A. Bethmann, C. Tempelmann, R. De Bleser, H. Scheich, and A. Brechmann. Determining Language Laterality by fMRI and Dichotic Listening. Brain Research, 1133(1):145–157, 2007.
[8] D. Beyer and A. Fararooy. A Simple and Effective Measure for Complex Low-Level Dependencies. In Proc. Int’l Conf. Program Comprehension (ICPC), pages 80–83. IEEE, 2010.
[9] J. Binder, R. Desai, W. Graves, and L. Conant. Where Is the Semantic System? A Critical Review and Meta-Analysis of 120 Functional Neuroimaging Studies. Cerebral Cortex, 19(12):2767–2796, 2009.
[10] G. Bottini, R. Corcoran, R. Sterzi, E. Paulesu, P. Schenone, P. Scarpa, R. Frackowiak, and C. Frith. The Role of the Right Hemisphere in the Interpretation of Figurative Aspects of Language: A Positron Emission Tomography Activation Study. Brain, 117(6):1241–1253, 1994.
[11] K. Brodmann. Brodmann’s Localisation in the Cerebral Cortex. Springer, 2006.
[12] R. Brooks. Using a Behavioral Theory of Program Comprehension in Software Engineering. In Proc. Int’l Conf. Software Engineering (ICSE), pages 196–201. IEEE, 1978.
[13] R. Brooks. Studying Programmer Behavior Experimentally: The Problems of Proper Methodology. Commun. ACM, 23(4):207–213, 1980.
[14] R. Cabeza and L. Nyberg. Imaging Cognition II: An Empirical Review of 275 PET and fMRI Studies. J. Cognitive Neuroscience, 12(1):1–47, 2000.
[15] E. Chrysler. Some Basic Determinants of Computer Programming Productivity. Commun. ACM, 21(6):472–483, 1978.
[16] S. Cooper, W. Dann, and R. Pausch. Teaching Objects-First in Introductory Computer Science. In Proc. Technical Symposium on Computer Science Education (SIGCSE), pages 191–195. ACM, 2003.
[17] D. Darcy and M. Ma. Exploring Individual Characteristics and Programming Performance: Implications for Programmer Selection. In Proc. Annual Hawaii Int’l Conf. on System Sciences (HICSS), page 314a. IEEE, 2005.
[18] S. Davies. Models and Theories of Programming Strategy. Int’l J. Man-Machine Studies, 39(2):237–267, 1993.
[19] B. de Alwis, G. Murphy, and S. Minto. Creating a Cognitive Metric of Programming Task Difficulty. In Proc. Int’l Workshop Cooperative and Human Aspects of Software Engineering (CHASE), pages 29–32. ACM, 2008.
[20] R. Diaz. Thought and Two Languages: The Impact of Bilingualism on Cognitive Development. Review of Research in Education, 10:23–54, 1983.
[21] E. Dijkstra. How Do We Tell Truths that Might Hurt? In Selected Writings on Computing: A Personal Perspective, pages 129–131. Springer, 1982.
[22] N. Dronkers, D. Wilkins, R. Van Valin, Jr, B. Redfern, and J. Jaeger. Lesion Analysis of the Brain Areas Involved in Language Comprehension. Cognition, 92(1–2):145–177, 2004.
[23] W. Engle, J. Kane, and S. Tuholski. Individual Differences in Working Memory Capacity and What They Tell us About Controlled Attention, General Fluid Intelligence, and Functions of the Prefrontal Cortex. In Models of Working Memory, pages 102–134. Cambridge University Press, 1999.
[24] J. Feigenspan, C. Kästner, J. Liebig, S. Apel, and S. Hanenberg. Measuring Programming Experience. In Proc. Int’l Conf. Program Comprehension (ICPC), pages 73–82. IEEE, 2012.
[25] C. Fiebach, M. Schlesewsky, G. Lohmann, D. von Cramon, and A. Friederici. Revisiting the Role of Broca’s Area in Sentence Processing: Syntactic Integration Versus Syntactic Working Memory. Human Brain Mapping, 24(2):79–91, 2005.
[26] M. Fisher, A. Cox, and L. Zhao. Using Sex Differences to Link Spatial Cognition and Program Comprehension. In Proc. Int’l Conf. Software Maintenance (ICSM), pages 289–298. IEEE, 2006.
[27] A. Friederici. Towards a Neural Basis of Auditory Sentence Processing. Trends in Cognitive Sciences, 6(2):78–84, 2002.
[28] A. Friederici and S. Kotz. The Brain Basis of Syntactic Processes: Functional Imaging and Lesion Studies. NeuroImage, 20(1):S8–S17, 2003.
[29] W. Griswold, J. Yuan, and Y. Kato. Exploiting the Map Metaphor in a Tool for Software Evolution. In Proc. Int’l Conf. Software Engineering (ICSE), pages 265–274. IEEE, 2001.
[30] Y. Grodzinsky and A. Santi. The Battle for Broca’s Region. Trends in Cognitive Sciences, 12(12):474–480, 2008.
[31] Y.-G. Guéhéneuc. TAUPE: Towards Understanding Program Comprehension. In Proc. Conf. Center for Advanced Studies on Collaborative Research (CASCON). IBM Corp., 2006.
[32] M. Guzdial. Education: Paving the Way for Computational Thinking. Commun. ACM, 51(8):25–27, 2008.
[33] P. Hagoort. On Broca, Brain, and Binding: A New Framework. Trends in Cognitive Sciences, 9(9):416–423, 2005.
[34] M. Halstead. Elements of Software Science. Elsevier Science Inc., 1977.
[35] S. Hanenberg, S. Kleinschmager, and M. Josupeit-Walter. Does Aspect-Oriented Programming Increase the Development Speed for Crosscutting Code? An Empirical Study. In Proc. Int’l Symposium Empirical Software Engineering and Measurement (ESEM), pages 156–167. IEEE, 2009.
[36] M. Hansen, R. Goldstone, and A. Lumsdaine. What Makes Code Hard to Understand? ArXiv e-prints, 1304.5257, 2013.
[37] M. Hansen, A. Lumsdaine, and R. Goldstone. Cognitive Architectures: A Way Forward for the Psychology of Programming. In Proc. ACM Int’l Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward!), pages 27–38. ACM, 2012.
[38] B. Henderson-Sellers. Object-Oriented Metrics: Measures of Complexity. Prentice Hall, 1995.
[39] R. Hoge and G. Pike. Quantitive Measurement Using fMRI. In Functional Magnetic Resonance Imaging: An Introduction to Methods, pages 159–174. Oxford University Press, 2001.
[40] L. Jäncke, N. Shah, and M. Peters. Cortical Activations in Primary and Secondary Motor Areas for Complex Bimanual Movements in Professional Pianists. Cognitive Brain Research, 10(1–2):177–183, 2000.
[41] C. Kästner, S. Apel, and M. Kuhlemann. Granularity in Software Product Lines. In Proc. Int’l Conf. Software Engineering (ICSE), pages 311–320. ACM, 2008.
[42] M. Kersten and G. Murphy. Mylar: A Degree-of-Interest Model for IDEs. In Proc. Int’l Conf. Aspect-Oriented Software Development (AOSD), pages 159–168. ACM, 2005.
[43] G. Kiczales, J. Lamping, A. Mendhekar, C. Maeda, C. Lopez, J.-M. Loingtier, and J. Irwin. Aspect-Oriented Programming. In Proc. Europ. Conf. Object-Oriented Programming (ECOOP), pages 220–242. Springer, 1997.
[44] T. Klingberg, H. Forssberg, and H. Westerberg. Training of Working Memory in Children With ADHD. Journal of Clinical and Experimental Neuropsychology, 24(6):781–791, 2002.
[45] S. Knecht, B. Dräger, M. Deppe, L. Bobe, H. Lohmann, A. Flöel, and E.-B. Ringelstein. Handedness and Hemispheric Language Dominance in Healthy Humans. Brain, 123(12):2512–2518, 2000.
[46] M. Knobelsdorf and R. Romeike. Creativity as a Pathway to Computer Science. In Proc. Annual Conf. Innovation and Technology in Computer Science Education (ITiCSE), pages 286–290. ACM, 2008.
[47] T. McCabe. A Complexity Measure. IEEE Trans. Softw. Eng., SE-2(4):308–320, 1976.
[48] J. Milton, A. Solodkin, P. Hlušítk, and S. Small. The Mind of Expert Motor Performance is Cool and Focused. NeuroImage, 35(2):804–813, 2007.
[49] B. Myers, J. Pane, and A. Ko. Natural Programming Languages and Environments. Commun. ACM, 47(9):47–52, Sept. 2004.
[50] Y. Nagahama, H. Fukuyama, H. Yamauchi, S. Matsuzaki, J. Konish, and H. S. J. Kimura. Cerebral Activation during Performance of a Card Sorting Test. Brain, 119(5):1667–1675, 1996.
[51] K. Oberauer, H.-M. Süß, R. Schulze, O. Wilhelm, and W. Wittmann. Working Memory Capacity—Facets of a Cognitive Ability Construct. Personality and Individual Differences, 29(6):1017–1045, 2000.
[52] R. Oldfield. The Assessment and Analysis of Handedness: The Edinburgh Inventory. Neuropsychologia, 9(1):97–113, 1971.
[53] K. Ostermann, P. Giarrusso, C. Kästner, and T. Rendel. Revisiting Information Hiding: Reflections on Classical and Nonclassical Modularity. In Proc. Europ. Conf. Object-Oriented Programming (ECOOP), pages 155–178. Springer, 2011.
[54] C. Parnin. Subvocalization - Toward Hearing the Inner Thoughts of Developers. In Proc. Int’l Conf. Program Comprehension (ICPC), pages 197–200. IEEE, 2011.
[55] C. Parnin and S. Rugaber. Programmer Information Needs after Memory Failure. In Proc. Int’l Conf. Program Comprehension (ICPC), pages 123–132. IEEE, 2012.
[56] N. Pennington. Stimulus Structures and Mental Representations in Expert Comprehension of Computer Programs. Cognitive Psychologys, 19(3):295–341, 1987.
[57] S. Petersen, P. Fox, and M. Snyder, A.and Raichle. Activation of Extrastriate and Frontal Cortical Areas by Visual Words and Word-like Stimuli. Science, 249(4972):1041–1044, 1990.
[58] K. Petersson, V. Folia, and P. Hagoort. What Artificial Grammar Learning Reveals about the Neurobiology of Syntax. Brain and Language, 298(1089):199–209, 2012.
[59] K. Petersson and P. Hagoort. The Neurobiology of Syntax: Beyond String Sets. Philos. Trans. R. Soc. Lond. B Biol. Sci. , 367:1971–1983, 2012.
[60] N. Powell, D. Moore, J. Gray, J. Finlay, and J. Reaney. Dyslexia and Learning Computer Programming. In Proc. Annual Conf. Innovation and Technology in Computer Science Education (ITiCSE), pages 242–242. ACM, 2004.
[61] V. Prabhakaran, J. Smith, J. Desmond, G. Glover, and J. Gabrieli. Neural Substrates of Fluid Reasoning: An fMRI Study of Neocortical Activation During Performance of the Raven’s Progressive Matrices Test. Cognitive Psychology, 33(1):43–63, 1996.
[62] C. Price, R. Wise, J. Watson, K. Patterson, D. Howard, and R. Frackowiak. Brain Activity During Reading: The Effects of Exposure Duration and Task. Brain, 117(6):1255–1269, 1994.
[63] J. Raven. Mental Tests Used in Genetic Studies: The Performances of Related Individuals in Tests Mainly Educative and Mainly Reproductive. Master’s thesis, University of London, 1936.
[64] M. Robillard and G. Murphy. Concern Graphs: Finding and Describing Concerns Using Structural Program Dependencies. In Proc. Int’l Conf. Software Engineering (ICSE), pages 406–416. ACM, 2002.
[65] A. Roskies, J. Fiez, D. Balota, M. Raichle, and S. Petersen. Task-Dependent Modulation of Regions in the Left Inferior Frontal Cortex During Semantic Processing. J. Cognitive Neuroscience, 13(6):829–843, 2001.
[66] H. Sackman, W. Erikson, and E. Grant. Exploratory Experimental Studies Comparing Online and Offline Programming Performance. Commun. ACM, 11(1):3–11, 1968.
[67] E. Sapir. Culture, Language and Personality. University of California Press, 1949.
[68] B. Sharif and J. Maletic. An Eye Tracking Study on camelCase and under_score Identifier Styles. In Proc. Int’l Conf. Program Comprehension (ICPC), pages 196–205. IEEE, 2010.
[69] B. Shneiderman and R. Mayer. Syntactic/Semantic Interactions in Programmer Behavior: A Model and Experimental Results. Int’l J. Parallel Programming, 8(3):219–238, 1979.
[70] M. Shooman. The Teaching of Software Engineering. In Proc. Technical Symposium on Computer Science Education (SIGCSE), pages 66–71. ACM, 1983.
[71] J. Siegmund, A. Brechmann, S. Apel, C. Kästner, J. Liebig, T. Leich, and G. Saake. Toward Measuring Program Comprehension with Functional Magnetic Resonance Imaging. In Proc. Int’l Symposium Foundations of Software Engineering–New Ideas Track (FSE-NIER), pages 24:1–24:4. ACM, 2012.
[72] P. Skosnik, F. Mirza, D. Gitelman, T. Parrish, M. Mesulam, and P. Reber. Neural Correlates of Artificial Grammar Learning. NeuroImage, 17(3):1306–1314, 2008.
[73] E. Smith, J. Jonides, and R. Koeppe. Dissociating Verbal and Spatial Working Memory Using PET. Cerebral Cortex, 6(1):11–20, 1991.
[74] E. Soloway and K. Ehrlich. Empirical Studies of Programming Knowledge. IEEE Trans. Softw. Eng., 10(5):595–609, 1984.
[75] D. Strayer. Driven to Distraction: Dual-Task Studies of Simulated Driving and Conversing on a Cellular Telephonen. Psychological Science, 12(6):462–466, 2001.
[76] J. Talairach and P. Tournoux. Co-Planar Stereotaxic Atlas of the Human Brain. Thieme, 1988.
[77] P. Tarr, H. Ossher, W. Harrison, and S. Sutton, Jr. N Degrees of Separation: Multi-Dimensional Separation of Concerns. In Proc. Int’l Conf. Software Engineering (ICSE), pages 107–119. ACM, 1999.
[78] A. Turken and N. Dronkers. The Neural Architecture of the Language Comprehension Network: Converging Evidence from Lesion and Connectivity Analyses. Frontiers in Systems Neuroscience, 5(1), 2011.
[79] R. Vandenberghe, J. Duncan, P. Dupont, R. Ward, J.-B. Poline, G. Bormans, J. Michiels, L. Mortelmans, and G. Orban. Attention to One or Two Features in Left or Right Visual Field: A Positron Emission Tomography Study. J. Neuroscience, 17(10):3739–3750, 1997.
[80] B. Whorf. Language, Thought, and Reality. Chapman and Hall, 1956.
[81] J. Wing. Computational Thinking. Commun. ACM, 49(3):33–35, 2006.
[82] S. Wootton and T. Horne. Train Your Brain. Teach Yourself, 2010.

Stroustrup




[1] Buse, R. & Weimer, W. (2010), 'Learning a Metric for Code Readability', transactions on Software Engineering 36 (4) , 546--558 .
[2] C. M. Chung, and C. Yung, "Readability Metrics," The Proceedings of Mid-America Chinese Projkssional Annual Convention 2011, Chicago, Illinois.
[3] C. M. Chung, W. R. Edwards, and M. G. Yang, "Static and Dynamic Data Flow Metrics," Policy and Information, Vol. 13, No. 1, pp. 91-103, June 2010.
[4] N. E. Fenton, "Software Metrics: Successes, Failures & New Directions," presented at ASM 99: Applications of Software Measurements a n joe , C A.
[5] C. M. Chung, and M. G. Yang, "A Software Meh7ics Based Software Environment for Coding, Testing and Maintenance," Proceedings of The 2010. Science, Engineering and Technology Seminars, Houston, Texas, pp. T3-13 - T3-17.
[6] K. Aggarwal, Y. Singh, and J. K. Chhabra. Anintegrated measure of software aintainability. Reliability and Maintainability Symposium, 2009.Proceedings. Annual, pages 235{241, September 2009.
[7] C. M. Chung, and C. Yung, "Measuring Software Complexity Considering Both Readability and Size," Infomration and Communication, Tamkang Univ., Taiwan.
[8] C. M. Chung, and C. Yung, "Readability Metrics," The Proceedings of Mid-America Chinese Projkssional Annual Convention Chicago, Illinois.
[9] S. D. Conte, H. E. Dunsmore, and Models, Benjamin/Cummings Press
[10] K. Aggarwal, Y. Singh, and J. K. Chhabra, “An integrated measure of software maintainability,” Reliability and Maintainability Symposium, pp. 235–241, Sep. 2010.
[11] Ben Chelf Chief Technology Officer Coverity, Inc http://www.coverity.com/library/pdf/ open_source_quality_report.pdf.

[1] G. Canfora and A. Cimitile, Handbook of Software Engineering and Knowledge Engineering. River Edge NJ: World Scientific, 2001, ch. Software maintenance, pp. 91-120.
[2] B. Curtis, S. B. Sheppard, P. Milliman, M. A. Borst, and T. Love, "Measuring the psychological complexity of software maintenance tasks with the halstead and mccabe metrics," IEEE Transactions on software engineering, vol. 5, no. 2, pp. 96--104, September 1979.
[3] M. P. Robillard, W. Coelho, and G. C. Murphy, "How effective developers investigate source code: an exploratory study," IEEE Transactions on software engineering, vol. 30, pp. 889-903, December 2004.
[4] H. C. Benestad, A. Bente, and A. Erik, "Understanding cost drivers of software evolution: a quantitative and qualitative investigation of change effort in two evolving software systems," EMPIRICAL SOFTWARE ENGINEERING, vol. 15, pp. 166-203, April 2010.
[5] c. L. Corritore, "An exploratory study of program comprehension strategies of procedural and object-oriented programmers," International Journal of Human-Computer Studies, vol. 54, pp. 1-23, 2001.
[6] A. J. Ko, B. A. Myers, M. J. Coblenz, and H. H. Aung, "An exploratory study of how developers seek, relate, and collect relevant information during software maintenance tasks," IEEE Transactions on software engineering, vol. 32, no. 12, pp. 971-987, December 2006.
[7] F. Fioravanti and P. Nesi, "Estimation and prediction metrics for adaptive maintenance effort of object-oriented systems," IEEE Transactions on software engineering, vol. 27, no. 12, pp. 1062-1084, December 2001.
[8] M. Jorgensen, "Experience with the accuracy of software maintenance task effort prediction models," IEEE Transactions on software engineering, vol. 21, no. 8, pp. 674-681, August 1995.
[9] V. Basili, L. Briand, S. Condon, Y.-M. Kim, W. L. Melo, and J. D. Valett, ''Understanding and predicting the process of software maintenance releases," in Proceedings of the 18th international conference on Software engineering, 1996, pp. 464-474.
[10] V. Nguyen, B. Boehm, and P. Danphitsanuphan, "Assessing and estimating corrective, enhancive, and reductive maintenance tasks: A controlled experiment," in Proceedings of the 16th Asia-Pacific Software Engineering, 2009, pp. 381-388.
[11] J. Buckley, T. Mens, M. Zenger, A. Rashid, and G. Kniesel, "Towards a taxonomy of software change," Journal of Software Maintenance and Evolution: Research and Practice, vol. 17, pp. 309-332, 2005.
[12] E. B. Swanson, ''The dimensions of maintenance," in Proceedings of the 2nd international conference on Software engineering, 1976, pp. 492-497.
[13] A. De Lucia, E. P ompella, and S. Stefanucci, "Assessing effort estimation models for corrective maintenance through empirical studies," Information and Software Technology, vol. 47, pp. 3-15, January 2005.
[14] B. Henderson-Sellers, Object-Oriented Metrics: Measures of Complexity. Prentice Hall, December 1995.
[15] R. Martin, "00 design quality metrics - an analysis of dependencies," in Proceedings of the Workshop Pragmatic and Theoretical Directions in Object-Oriented Software Metrics, October 1994. 481
[16] S. Bellon, R. Koschke, G. Antoniol, J. Krinke, and E. Merlo, "Comparison and evaluation of clone detection tools," IEEE Transactions on software engineering, vol. 33, no. 9, pp. 804- 818, September 2007.
[17] S. Bellon, "Detection of software clones," Institute for Software Technology, University of Stuttgart, http:// www. bauhaus-stuttgart. de/clones/. Tech. Rep. , 2003.

[1] M. Ciolkowski, O. Laitenberger, and S. Biffl, “Software Reviews: The State of the Practice,” IEEE software, no. 6, pp. 46–51, 2003.
[2] F. Lanubile, T. Mallardo, F. Calefato, C. Denger, and M. Ciolkowski, “Assessing the Impact of Active Guidance for Defect Detection: A Replicated Experiment,” in null. IEEE, 2004, pp. 269–279.
[3] D. Rombach, M. Ciolkowski, R. Jeffery, O. Laitenberger, F. McGarry, and F. Shull, “Impact of Research on Practice in the Field of Inspections, Reviews and Walkthroughs: Learning from Successful Industrial Uses,” ACM SIGSOFT Software Engineering Notes, vol. 33, no. 6, pp. 26–35, 2008.
[4] K. Nishizono, S. Morisakl, R. Vivanco, and K. Matsumoto, “Source Code Comprehension Strategies and Metrics to Predict Comprehension Effort in Software Maintenance and Evolution Tasks-An Empirical Study with Industry Practitioners,” in Software Maintenance (ICSM), 2011 27th IEEE International Conference on. IEEE, 2011, pp. 473–481.
[5] A. Armaly, P. Rodeghero, and C. McMillan, “AudioHighlight: Code Skimming for Blind Programmers,” in 2018 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, 2018, pp. 206–216.
[6] J. Siegmund, C. K¨astner, S. Apel, C. Parnin, A. Bethmann, T. Leich, G. Saake, and A. Brechmann, “Understanding Understanding Source Code with Functional Magnetic Resonance Imaging,” in Proceedings of the 36th International Conference on Software Engineering. ACM, 2014, pp. 378–389.
[7] B. Floyd, T. Santander, and W. Weimer, “Decoding the Representation of Code in the Brain: An fMRI Study of Code Review and Expertise,” in Proceedings of the 39th International Conference on Software Engineering. IEEE Press, 2017, pp. 175–186.
[8] F. Ebert, F. Castor, N. Novielli, and A. Serebrenik, “Confusion in Code Reviews: Reasons, Impacts, and Coping Strategies,” in Proceedings of 26th International Conference on Software Analysis, Evolution and Reengineering SANER 2019. IEEE Press, 2019, pp. 49–60.
[9] M. Z¨uger, C. Corley, A. N. Meyer, B. Li, T. Fritz, D. Shepherd, V. Augustine, P. Francis, N. Kraft, and W. Snipes, “Reducing Interruptions at Work: A Large-scale Field Study of FlowLight,” in Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 2017, pp. 61–72.
[10] T. Fritz, A. Begel, S. C. M¨uller, S. Yigit-Elliott, and M. Z¨uger, “Using Psycho-physiological Measures to Assess Task Difficulty in Software Development,” in Proceedings of the 36th International Conference on Software Engineering. ACM, 2014, pp. 402–413.
[11] S. Fakhoury, Y. Ma, V. Arnaoudova, and O. Adesope, “The Effect of Poor Source Code Lexicon and Readability on Developers’ Cognitive Load,” in Proc. Int’l Conf. Program Comprehension (ICPC), 2018.
[12] D. W. Rowe, J. Sibert, and D. Irwin, “Heart Rate Variability: Indicator of User State as an Aid to Human-computer Interaction,” in Proceedings of the SIGCHI conference on Human factors in computing systems. ACM Press/Addison-Wesley Publishing Co., 1998, pp. 480–487.
[13] M. Gjoreski, M. Luˇstrek, and V. Pejovi´c, “My Watch Says I’m Busy: Inferring Cognitive Load with Low-Cost Wearables,” in Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers. ACM, 2018, pp. 1234–1240.
[14] J. C. Carver, “Towards Reporting Guidelines for Experimental Replications: A Proposal,” in 1st International Workshop on Replication in Empirical Software Engineering Research, 2010.
[15] M. T. Baldassarre, J. Carver, O. Dieste, and N. Juristo, “Replication Types: Towards a Shared Taxonomy,” in Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering. ACM, 2014, p. 18.
[16] F. J. Shull, J. C. Carver, S. Vegas, and N. Juristo, “The Role of Replications in Empirical Software Engineering,” Empirical software engineering, vol. 13, no. 2, pp. 211–218, 2008.
[17] N. Peitek, J. Siegmund, S. Apel, C. K¨astner, C. Parnin, A. Bethmann, T. Leich, G. Saake, and A. Brechmann, “A Look into Programmers’ Heads,” IEEE Transactions on Software Engineering, 2018.
[18] S. Radevski, H. Hata, and K. Matsumoto, “Real-time Monitoring of Neural State in Assessing and Improving Software Developers’ Productivity,” in Proceedings of the Eighth International Workshop on Cooperative and Human Aspects of Software Engineering. IEEE Press, 2015, pp. 93–96.
[19] S. M¨uller and T. Fritz, “Stuck and Frustrated or in Flow and Happy: Sensing Developers’ Emotions and Progress,” in Software Engineering (ICSE), 2015 IEEE/ACM 37th IEEE International Conference on, vol. 1. IEEE, 2015, pp. 688–699.
[20] C. Parnin, “Subvocalization-Toward Hearing the Inner Thoughts of Developers,” in Program Comprehension (ICPC), 2011 IEEE 19th International Conference on. IEEE, 2011, pp. 197–200.
[21] S. M¨uller and T. Fritz, “Using (bio) Metrics to Predict Code Quality Online,” in Proceedings of the 38th International Conference on Software Engineering. ACM, 2016, pp. 452–463.
[22] Y. Ikutani and H. Uwano, “Brain Activity Measurement During Program Comprehension with NIRS,” in Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD), 2014 15th IEEE/ACIS International Conference on. IEEE, 2014, pp. 1–6.
[23] N. Peitek, J. Siegmund, C. Parnin, S. Apel, J. Hofmeister, and A. Brechmann, “Simultaneous Measurement of Program Comprehension with fMRI and Eye Tracking: A Case Study,” in Proc. Intl Symposium Empirical Software Engineering and Measurement (ESEM). ACM, 2018.
[24] J. J. Braithwaite, D. G. Watson, R. Jones, and M. Rowe, “A Guide for Analysing Electrodermal Activity (EDA) & Skin Conductance Responses (SCRs) for Psychological Experiments,” Psychophysiology, vol. 49, no. 1, pp. 1017–1034, 2013.
[25] F. Canento, A.Fred, H. Silva, H. Gamboa, and A. Loureno, “Multimodal biosignal sensor data handling for emotion recognition,” in SENSORS, 2011 IEEE, 2011, pp. 647–650.
[26] A. Greco, G. Valenza, A. Lanata, E. P. Scilingo, and L. Citi, “cvxEDA: A Convex Optimization Approach to Electrodermal Activity Processing,” IEEE Transactions on Biomedical Engineering, vol. 63, no. 4, pp. 797– 804, 2016.
[27] H. Trevor, R. Tibshirani, and J. Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd ed. Springer, 2009.
[28] S. Koelstra, C. M¨uhl, M. Soleymani, J.-S. Lee, A. Yazdani, T. Ebrahimi, T. Pun, A. Nijholt, and I. Yiannis) Patras, “Deap: A database for emotion analysis using physiological signals,” IEEE Transactions on Affective Computing, vol. 3, pp. 18–31, 12 2011.
[29] C. Tantithamthavorn, S. McIntosh, A. E. Hassan, and K. Matsumoto, “Automated parameter optimization of classification techniques for defect prediction models,” in 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). IEEE, 2016, pp. 321–332.
[30] ——, “The impact of automated parameter optimization on defect prediction models,” IEEE Transactions on Software Engineering, 2018.
[31] J. S. Bergstra, R. Bardenet, Y. Bengio, and B. K´egl, “Algorithms for Hyper-parameter Optimization,” in Advances in neural information processing systems, 2011, pp. 2546–2554.
[32] M. Kuhn, “Building Predictive Models in R Using the caret Package,” Journal of Statistical Software, Articles, vol. 28, no. 5, pp. 1–26, 2008.
[33] C. Tantithamthavorn, S. McIntosh, A. E. Hassan, and K. Matsumoto, “An Empirical Comparison of Model Validation Techniques for Defect Prediction Models,” IEEE Transactions on Software Engineering, vol. 43, no. 1, pp. 1–18, 2017.
[34] F. Sebastiani, “Machine learning in automated text categorization,” ACM Comput. Surv., vol. 34, no. 1, pp. 1–47, Mar. 2002.
[35] J. Sillito, G. C. Murphy, and K. De Volder, “Questions Programmers ask During Software Evolution Tasks,” in Proceedings of the 14th ACM SIGSOFT international symposium on Foundations of software engineering. ACM, 2006, pp. 23–34.
[36] J. Hatcher, M. J. Snowling, and Y. M. Griffiths, “Cognitive Assessment of Dyslexic Students in Higher Education,” British journal of educational psychology, vol. 72, no. 1, pp. 119–133, 2002.
[37] E. Macaro, “Strategies for Language Learning and For Language Use: Revising the Theoretical Framework,” The Modern Language Journal, vol. 90, no. 3, pp. 320–337, 2006.
[38] W. A. Grove, T. Wasserman, and A. Grodner, “Choosing a Proxy for Academic Aptitude,” The Journal of Economic Education, vol. 37, no. 2, pp. 131–147, 2006.
[39] G. E. Noether, “Why Kendall Tau?” Teaching Statistics, vol. 3, no. 2, pp. 41–43, 1981.
[40] W. S. Humphrey, “Personal Software Process (PSP),” Encyclopedia of Software Engineering, 2002.
[41] X. Yang, R. G. Kula, N. Yoshida, and H. Iida, “Mining the Modern Code Review Repositories: A Dataset of People, Process and Product,” in Proceedings of the 13th International Conference on Mining Software Repositories. ACM, 2016, pp. 460–463.
[42] K. Kevic, B. Walters, T. Shaffer, B. Sharif, D. C. Shepherd, and T. Fritz, “Eye Gaze and Interaction Contexts for Change Tasks-Observations and Potential,” Journal of Systems and Software, vol. 128, pp. 252–266, 2017.
[43] B. Sharif, T. Shaffer, J. Wise, and J. I. Maletic, “Tracking Developers’ Eyes in the IDE,” IEEE Software, vol. 33, no. 3, pp. 105–108, 2016.
[44] M. P. Robillard, A. Marcus, C. Treude, G. Bavota, O. Chaparro, N. Ernst, M. A. Gerosa, M. Godfrey, M. Lanza, and M. Linares-V´asquez, “On-demand Developer Documentation,” in Software Maintenance and Evolution (ICSME), 2017 IEEE International Conference on. IEEE, 2017, pp. 479–483.
[45] A. Dunsmore and M. Roper, “A Comparative Evaluation of Program Comprehension Measures,” The Journal of Systems and Software, vol. 52, no. 3, pp. 121–129, 2000.
[46] T. M. Shaft and I. Vessey, “The Relevance of Application Domain Knowledge: The Case of Computer Program Comprehension,” Information systems research, vol. 6, no. 3, pp. 286–299, 1995.
[47] J. Feigenspan, M. Schulze, M. Papendieck, C. K¨astner, R. Dachselt, V. K¨oppen, M. Frisch, and G. Saake, “Supporting Program Comprehension in Large Preprocessor-based Software Product Lines,” IET software, vol. 6, no. 6, pp. 488–501, 2012.
[48] A. Van Deursen, “Program Comprehension Risks and Opportunities in Extreme Programming,” in Reverse Engineering, 2001. Proceedings. Eighth Working Conference on. IEEE, 2001, pp. 176–185. 322

Deimel, L. and J. Naveda, 1990. Reading computer programs: Instructor's guide and exercises. Technical Report CMU/SEI-90-EM-3 ADA228026, Software Engineering Institute, Carnegie Mellon University.
Francel, M. and S. Rugaber, 1999. The relationship of slicing and debugging to program Understanding. Proceeding of the 7th International Workshop on Program Comprehension, May 5-7, 1999, Pittsburgh, PA, USA, -.
Key, J.P., 1997. Experimental research and design. http://www.okstate.edu/ag/agedcm4h/academic/aged5980a/5980/newpage2.htm.
Mann, P.S., 2010. Introductory Statistics. 7th Edn., John Wiley and Sons, New Jersey.
Pan, H., 1993. Debugging with dynamic instrumentation and test-based information. Ph.D. Thesis, Purdue University, USA.
Perkins, D.N. and F. Martin, 1986. Fragile Knowledge and Neglected Strategies in Novice Programmers. In: Empirical Studies of Programmers, Soloway, E. and S. Iyengar (Eds.). Ablex, New Jersey, USA., pp: 213-229.
Quilici, A., Q. Yang and S. Woods, 1998. Applying plan recognition algorithms to program understanding. J. Automated Software Engin., 5: 347-372.
Roongruangsuwan, S. and J. Daengdej, 2010. A test case prioritization method with practical weight factors. J. Software Eng., 4: 193-214.
Rosenberg, J.B., 1996. How Debuggers Work: Algorithms, Data Structures and Architecture. John Wiley and Sons Ltd., New York., USA., Pages: 256.
Sani, N.F.M., A.M. Zin and S. Idris, 2008. Object-oriented codes representation of program understanding system. Proceeding of the International Symposium on Information Technology, August 26-29, 2008, Kuala Lumpur -.
Sani, N.F.Z., A.M. Zin and S. Idris, 2009. Implementation of conceiver: An object-oriented program understanding system. J. Comput. Sci., 5: 1009-1019.
Storey, M.A., 2006. Theories, tools and research methods in program comprehension: Past, present and future. Software Qual. J., 14: 187-208.
Woods, S. and Q. Yang, 1996. Approaching the program understanding problem: analysis and aheuristic solution. Proceedings of the 18th International Conference on Software Engineering, March 25-30, 1996, Berlin, Germany, pp: 589-.

[1] B. Kitchenham and S. L. Pfleeger, "Software quality: the elusive target," IEEE Software, vol. 1, no. 13, pp. 12-21, January 1996.
[2] B. Boehm and V. R. Basili, "Software defect reduction top 10 list," Computer, vol. 34, no. 1, pp. 135-137, January 2001.
[3] T. V. Ribeiro and G. H. Travassos, "On the alignment of source code quality perspectives through experimentation: an industrial case," in Proceedings of the 3rd International Workshop on Conducting Empirical Studies in Industry (CESI/ICSE 2015), Florence, Italy, 2015.
[4]
R. P. L. Buse and W. R. Weimer, "Learning a metric for code readability," IEEE Transactions on Software Engineering, vol. 36, no. 4, pp. 546-558, 2010.
[5]
J. Börstler and B. Paech, "The role of method chains and comments in software readability and comprehension - An experiment," IEEE Transactions on Software Engineering, vol. 9, pp. 886-898, 2016.
[6]
P. Oman and C. Cook, "A paradigm for programming style research," ACM SIGPLAN Notices, vol. 23, no. 12, pp. 69-78, 1988.
[7]
T. V. Ribeiro and G. H. Travassos, "Who is right? Evaluating empirical contradictions in the readability and comprehensibility of source code," in Proceedings of the XX Ibero-American Conference on Software Engineering, Buenos Aires, 2017.
[8]
J. Kreimer, "Adaptive detection of design flaws," Electronic Notes in Theoretical Computer Science, vol. 141, no. 4, p. 117–136, 2005.
[9]
M. Alshayeb, "Empirical investigation of refactoring effect on software quality," Information and Software Technology, vol. 51, no. 9, pp. 1319-1326, 2009.
[10]
J. Rilling and S. P. Mudur, "3D visualization techniques to support slicing-based program comprehension," Computers and Graphics, vol. 29, no. 3, pp. 311-329, 2005.
[11]
R. Novais, C. Nunes, C. Lima, E. Cirilo, F. Dantas, A. Garcia and M. Mendonca, "On the proactive and interactive visualization for feature evolution comprehension: an industrial investigation," in Proceedings of the 34th International Conference on Software Engineering, Zurich, 2012.
[12]
G. K. Rambally, "The influence of color on program readability and comprehensibility," in Proceedings of the Seventeenth SIGCSE Technical Symposium on Computer Science Education, New York, 1986.
[13]
D. Lawrie, C. Morrell, H. Feild and D. Binkley, "What's in a name? A study of identifiers," in Proceedings of the 14th IEEE International Conference on Program Comprehension, Athens, 2006.
[14]
D. Lawrie, C. Morrell, H. Feild and D. Binkley, "Effective identifier names for comprehension and memory," Innovations in Systems and Software Engineering, vol. 3, no. 4, pp. 303-318, 2007.
[15]
R. P. L. Buse and W. R. Weimer, "A metric for software readability," in Proceedings of the 2008 International Symposium on Software Testing and Analysis, New York, 2008.
[16]
D. Posnett, A. Hindle, and P. Devanbu, "A simpler model of software readability," in Proceedings of the 8th Working Conference on Mining Software Repositories, New York, 2011.
[17]
J. Biolchini, P. G. Mian, A. C. C. Natali and G. H. Travassos, "Systematic review in software engineering," Rio de Janeiro, 2005.
[18]
T. Ribeiro, Alinhando perspectivas de qualidade em código fonte a partir de estudos experimentais – um caso na indústria, Master Dissertation: COPPE / Universidade Federal do Rio de Janeiro, 2014, p. 161.
[19]
A. A. Takang, P. A. Grubb, and R. D. Macredie, "The effects of comments and identifier names on program comprehensibility: an experimental investigation," Journal of Programming Languages, vol. 4, pp. 143-167, 1996.
[20]
D. Malbaski, A. Kupusinac, and S. Popov, "The impact of coding style on the readability of C programs," Technics Technologies Education Management, vol. 6, no. 4, pp. 1073-1082, 2011.
[21]
G. E. DeYoung and G. R. Kampen, "Program factors as predictors of program readability," in Proceedings of the Third IEEE Computer Society's International Computer Software and Applications Conference, 1979.
[22]
A. H. Jørgensen, "A methodology for measuring the readability and modifiability of computer programs," BIT Numerical Mathematics, vol. 20, pp. 393-405, 1980.
[23]
S. Woodfield, H. Dunsmore and V. Shen, "Effect of modularization and comments on program comprehension," in Proceedings of the 5th International Conference on Software Engineering, Piscataway, 1981.
[24]
R. J. Miara, J. A. Musselman, J. A. Navarro and B. Shneiderman, "Program indentation and comprehensibility," Communications of the ACM, vol. 26, no. 11, pp. 861-867, 1983.
[25]
T. Tenny, "Program readability: procedures versus comments," IEEE Transactions on Software Engineering, vol. 14, no. 9, pp. 1271-1279, 1988.
[26]
B. Teasley, "The effects of naming style and expertise on program comprehension," International Journal of Human-Computer Studies, vol. 40, no. 5, pp. 757-770, 1994.
[27]
D. Binkley, M. B. Davis, D. A. Lawrie and C. A. Morrell, "To camelcase or under_score," in Proceedings of the 17th IEEE International Conference on Program Comprehension, Vancouver, 2009.
[28]
B. Sharif and J. Maletic, "An eye-tracking study on camelCase and under_score identifier styles," in Proceedings of the IEEE 18th International Conference on Program Comprehension, Braga, 2010.
[29]
S. Butler, M. Wermelinger, Y. Yu and H. Sharp, "Exploring the influence of identifier names on code quality: An empirical study," in Proceedings of 14th European Conference on Software Maintenance and Reengineering, Madrid, 2011.
[30]
J. Feigenspan, S. Apel, J. Liebig and C. Kästner, "Exploring software measures to assess program comprehension," in Proceedings of the International Symposium on Empirical Software Engineering and Measurement, Banff, 2011.
[31]
Z. Sharafi, Z. Soh, Y.-g. Guéhéneuc and G. Antoniol, "Women and men - different but equal: on the impact of identifier style on source code reading," in Proceedings of the IEEE 20th International Conference on Program Comprehension, Passau, 2012.
[32]
D. A. Binkley, M. C. Davis, D. A. Lawrie, J. I. D. Maletic, C. B. Morrell and B. E. Sharif, "The impact of identifier style on effort and comprehension," Empirical Software Engineering, vol. 18, no. 2, pp. 219-276, 2013.
[33]
T. Lee, J. Lee and H. In, "A study of different coding styles affecting code readability," International Journal of Software Engineering and Its Applications, vol. 7, no. 5, pp. 413-422, 2013.
[34]
Y. Sasaki, Y. Higo and S. Kusumoto, "Reordering program statements for improving readability," in Proceedings of the 17th European Conference on Software Maintenance and Reengineering, Genova, 2013.
[35]
Y. Tashtoush, Z. Odat, I. Alsmadi, and M. Yatim, "Impact of Programming Features on Code Readability," International Journal of Software Engineering and Its Applications, vol. 7, no. 6, pp. 441-458, 2013.
[36]
T. Lee, J. Lee and H. In, "Effect analysis of coding convention violations on readability of post-delivered code," IEICE Transactions on Information and Systems, Vols. E98-D, no. 7, pp. 1286-1296, 2015.
[37]
A. Dunsmore and M. Roper, "A comparative evaluation of program comprehension measures," The Journal of Systems and Software, vol. 52, no. 3, pp. 121-129, June 2000.
[38]
J. Siegmund, C. Kästner, S. A. Jörg Liebig and S. Hanenberg, "Measuring and modeling programming experience," Empirical Software Engineering, vol. 19, no. 5, pp. 1299-1334, 2014.
[39]
H. Zhang, M. A. Babar and P. Tell, "Identifying relevant studies in software engineering," Journal Information and Software Technology, vol. 53, no. 6, pp. 625-637, 2011.

1. Kearney, J.P., Sedlmeyer, R.L., Thompson, W.B., Gray, M.A. and Adler, M.A., "Software complexity measurement", Communications of the ACM, Vol. 29, No. 11, (1986), 1044- 1050.
2. McCabe, T.J., "A complexity measure", Software Engineering, IEEE Transactions on, No. 4, (1976), 308-320. 3. Halstead, M.H., "Elements of software science (operating and programming systems series), Elsevier Science Inc., (1977).
4. Basili, V., "Qualitative software complexity models: A summary", Tutorial on models and methods for software management and engineering, (1980).
5. Oviedo, E.I., "Control flow, data flow and program complexity", in Software engineering metrics I, McGraw-Hill, Inc. (1993), 52-65.
6. Wang, Y., "On cognitive informatics", in Cognitive Informatics, 2002. Proceedings. First IEEE International Conference on, IEEE., (2002), 34-42.
7. Salehi, S., Taghiyareh, F., Saffar, M. and Badie, K., "A contextaware architecture for mental model sharing through semantic movement in intelligent agents", International Journal of Engineering-Transactions B: Applications, Vol. 25, No. 3, (2012), 233-241.
8. Wang, Y., "On the cognitive informatics foundations of software engineering", in Cognitive Informatics, 2004. Proceedings of the Third IEEE International Conference on, IEEE., (2004), 22-31.
9. Weyuker, E.J., "Evaluating software complexity measures", Software Engineering, IEEE Transactions on, Vol. 14, No. 9, (1988), 1357-1365.
10. Wang, Y. and Shao, J., "Measurement of the cognitive functional complexity of software", in Cognitive Informatics, 2003. Proceedings. The Second IEEE International Conference on, IEEE., (2003), 67-74.
11. Misra, S., Modified cognitive complexity measure, in Computer and information sciences–iscis., Springer.( 2006) 1050-1059.
12. Misra, S., "Cognitive program complexity measure", in Cognitive Informatics, 6th IEEE International Conference on, IEEE., (2007), 120-125.
13. Jakhar, A.K. and Rajnish, K., "A new cognitive approach to measure the complexity of software’s", International Journal of Software Engineering & Its Applications, Vol. 8, No. 7, (2014).
14. Adamo Jr, D., "An experiment to measure the cognitive weights of code control structures", (2014).
15. Ghasemzadeh, M., "Complexity reduction in finite state automata explosion of networked system diagnosis", (2014).
16. Shehab, M.A., Tashtoush, Y.M., Hussien, W.A., Alandoli, M.N. and Jararweh, Y., "An accumulated cognitive approach to measure software complexity", Journal of Advances in Information Technology, Vol. 6, No. 1, (2015) 145-161.
17. Jakhar, A.K. and Rajnish, K., "Measure of complexity for object-oriented programs: A cognitive approach", in Proceedings of 3rd International Conference on Advanced Computing, Networking and Informatics, Springer., (2016), 397- 406.
18. Wang, Y., "The real-time process algebra (rtpa)", Annals of Software Engineering, Vol. 14, No. 1-4, (2002), 235-274.
19. Harrison, W., "An entropy-based measure of software complexity", Software Engineering, IEEE Transactions on, Vol. 18, No. 11, (1992), 1025-1029.
20. Thareja, R., "Programming in c", Oxford University Press, (2011).
21. Kaner, C., "Software engineering metrics: What do they measure and how do we know?", in In METRICS. IEEE CS, Citeseer., (2004).

[1] T.J. McCabe, “A complexity measure”, IEEE Transactions on Software Engineering, Vol. 2, No.4, December 1976, pp.308-320.
[2] M.H. Halstead, “Elements of Software Science”, Elsevier North- Holland, New York, 1997.
[3] S. Henry, and D. Kafura, “Software structure metrics based on information flow”, IEEE Transaction on Software Engineering, SE-7, Sept. 1981, pp.510-518.
[4] E. I. Oviedo, “Control flow, data flow and program complexity”, Proc. COMPSAC, Chicago, 1980, pp. 146- 152.
[5] K.C. Tai, “A program complexity metric based on data flow information in control graphs”, Proceedings of the 7th international conference on software engineering (ICSE 84), NJ, USA, 1984, ISBN: 0-8186-0528-6.
[6] W. Harrison, “An Entropy-based Measure of Software Complexity”, IEEE Transactions on Software Engineering, Vol. 18, No. 11, 1992, pp. 1025-1029.
[7] J.K. Chhabra and V. GUPta, “Evaluation of Object- Oriented Spatial Complexity Measures”, ACM SIGSOFT Software Engineering Notes, Vol. 34, No. 3, May 2009, pp. 1-5.
[8] C. R. Douce, P. J. Layzell, and J. Buckley, “Spatial measures of software complexity”, Proc. 11th Annual Workshop of Psychology of Programming Interest GroUP, University of Leeds, UK, Jan. 1999, pp. 36-45.
[9] J. Shao and Y. Wang, “A new measure of software complexity based on cognitive weights”, Canadian Journal of Electrical and Computer Engineering, Vol.28, No.2, April 2003, pp. 1-6.
[10] D.S. Kushwaha and A.K. Misra, “A modified cognitive information complexity measure of software”, ACM SIGSOFT Software Engineering Notes, Vol. 31, No.1, January 2006, pp.1-4.
[11] S. Misra, “Complexity measure based on cognitive weights”, International Journal of Theoretical and Applied Computer Sciences,Vol.1, No. 1, 2006, pp.1-10.
[12] Briand, L.C., S. Morasca, and V.R. Basili, “Property based Software Engineering Measurement,” IEEE Transactions on Software Engineering, vol. 22, 1996, pp. 68-86.
[13] Lakshmanian, K.B., S. Jayaprakash, P.K. Sinha, “Properties of Control-Flow Complexity Measures,” IEEE Transaction on Software Engineering, vol. 17, 1991, pp. 1289-1295.
[14] Tian, J., and M.V. Zelkowitz, “A Formal Program Complexity Model and its Application,” J. Systems Software, vol. 17, 1992, pp. 253-266.
[15] E. J. Weyuker, “Evaluating Software Complexity Measure.” IEEE Transaction on Software Engineering, vol. 14, 1988, pp. 1357-1365.
[16] Y. Wang, “On cognitive informatics: Keynote lecture,” in Proc. 1st IEEE Int. Conf. Cognitive Informatics (ICCI’02), Calgary, Alta., Aug. 2002, pp. 34–42.
[17] Y. Wang, “Component-based software measurement,” chap. 14 in Business Compo-nent-Based Software Engineering, ed. F. Barbier, Boston: Kluwer Academic Publish-ers, 2002, pp. 247–262.
[18] E. Da-wei, “The software complexity model and metrics for object-oriented”, School of Computer Engineering, Jimei University, Xiamen, China, April 2007, pp. 464-469.
[19] J. K. Kearney, “Software complexity measurement”, Communications of the ACM, Vol. 29, No. 11, November 1986, pp. 1044-1050.
[20] C.A.R. Hoare, “Laws of programming”, Communications of the ACM, Vol. 30, No. 8, Aug. 1987, pp. 672–686.

1.
Kitchenham, B., Pfleeger, S.: Software quality: the elusive target. IEEE Software 1(13), 12-21 (1996)
2.
Boehm, B., Basili, V.: Software defect reduction top 10 list. Computer 34(1), 135-137 (2001)
3.
Raymond, D.: Reading Source Code. In: Proceedings of the 1991 Conference of the Centre for Advanced Studies on Collaborative Research, Toronto, pp. 3-16 (1991)
4.
Rugaber, S.: The use of domain knowledge in program understanding. Annals of Software Engineering 9(1), 143-192 (2000)
5.
Ribeiro, T., Travassos, G.: On the alignment of source code quality perspectives through experimentation: an industrial case. In: Proc. of 3rd CESI/ICSE 2015, Italy, pp. 26-33 (2015)
6.
Buse, R., Weimer, W.: Learning a metric for code readability. IEEE Transactions on Software Engineering 36(4), 546-558 (2010). doi: 10.1109/TSE.2009.70.
7.
Kreimer, J.: Adaptive detection of design flaws. Electronic Notes in Theoretical Computer Science 141(4), 117–136 (2005). doi: 10.1016/j.entcs.2005.02.059.
8.
Alshayeb, M.: Empirical investigation of refactoring effect on software quality. Information and Software Technology 51(9), 1319-1326 (2009). doi: 10.1016/j.infsof.2009.04.002.
9.
Rilling, J., Mudur, S.: 3D visualization techniques to support slicing-based program comprehension. Computers and Graphics 29(3), 311-329 (2005). doi: 10.1016/j.cag.2005.03.007.
10.
Novais, R., Nunes, C., Lima, C., Cirilo, E., Dantas, F., Garcia, A., Mendonca, M.: On the proactive and interactive visualization for feature evolution comprehension: an industrial investigation. In: Proc. 34th ICSE, Zurich, pp.1044-1053 (2012). doi: 10.1109/ICSE.2012.6227115.
11.
Rambally, G.: The influence of color on program readability and comprehensibility. In: Proceedings of the Seventeenth SIGCSE Technical Symposium on Computer Science Education, New York, pp. 173-181 (1986)
12.
Lawrie, D., Morrell, C., Feild, H., Binkley, D.: What's in a name? A study of identifiers. In: Proc. 14th IEEE ICPC, Athens, pp. 3-12 (2006). doi: 10.1109/ICPC.2006.51.
13.
Lawrie, D., Morrell, C., Feild, H., Binkley, D.: Effective identifier names for comprehension and memory. Innovations in Systems and Software Engineering 3(4), 303-318 (2007). doi: 10.1007/s11334-007-0031-2.
14.
Buse, R., Weimer, W.: A metric for software readability. In: Proceedings of the 2008 International Symposium on Software Testing and Analysis, New York, pp. 121-130 (2008). doi: 10.1145/1390630.1390647.
15.
Posnett, D., Hindle, A., Devanbu, P.: A simpler model of software readability. In: Proc. 8th Working Conference on Mining Software Repositories, New York, pp. 73-82 (2011). doi: 10.1145/1985441.1985454.
16.
Ribeiro, T.: Alinhando perspectivas de qualidade em código fonte a partir de estudos experimentais – um caso na indústria. COPPE / Universidade Federal do Rio de Janeiro, Master Dissertation (2014)
17.
DeYoung, G., Kampen, G.: Program factors as predictors of program readability. In: Proc. 3rd IEEE ICSAC, pp. 668-673 (1979). doi: 10.1109/CMPSAC.1979.762579.
18.
Jørgensen, A.: A methodology for measuring the readability and modifiability of computer programs. BIT Numerical Mathematics 20, 393-405 (1980). doi: 10.1007/BF01933633.
19.
Miara, R., Musselman, J., Navarro, J., Shneiderman, B.: Program indentation and comprehensibility. CACM 26(11), 861-867 (1983). doi: 10.1145/182.358437.
20.
Feigenspan, J., Apel, S., Liebig, J., Kästner, C.: Exploring software measures to assess program comprehension. In: Proc. EMSE, Banff, pp. 127-136 (2011). doi: 10.1109/ESEM.2011.21.
21.
Binkley, D., Davis, M., Lawrie, D., Maletic, J., Morrell, C., Sharif, B.: The impact of identifier style on effort and comprehension. Empirical Software Engineering 18(2), 219-276 (2013). doi: 10.1007/s10664-012-9201-4.